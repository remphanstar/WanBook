{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remphanstar/WanBook/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 1 - WAN2GP Setup Introduction + Enhanced Platform Detection\n",
        "\n",
        "import sys\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import os\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if 'google.colab' not in sys.modules:\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"WAN2GP Setup Introduction + Enhanced Platform Detection\")\n",
        "\n",
        "def detect_platform():\n",
        "    \"\"\"Enhanced platform detection with comprehensive indicators\"\"\"\n",
        "\n",
        "    # Lightning AI detection - multiple indicators for reliability\n",
        "    lightning_indicators = [\n",
        "        'lightning' in str(sys.executable).lower(),\n",
        "        'teamspace-studios' in os.getcwd(),\n",
        "        'LIGHTNING_CLOUD_SPACE_HOST' in os.environ,\n",
        "        'LIGHTNING_CLOUD_SPACE_ID' in os.environ,\n",
        "        'commands/python' in str(sys.executable),\n",
        "        '/home/zeus/miniconda3/envs/cloudspace' in str(sys.executable),\n",
        "        os.path.exists('/teamspace'),\n",
        "        os.path.exists('/commands')\n",
        "    ]\n",
        "\n",
        "    # Google Colab detection\n",
        "    colab_indicators = [\n",
        "        'google.colab' in sys.modules,\n",
        "        '/content' in os.getcwd()\n",
        "    ]\n",
        "\n",
        "    # Vast.AI detection\n",
        "    vast_indicators = [\n",
        "        'VAST_CONTAINERLABEL' in os.environ,\n",
        "        '/workspace' in os.getcwd(),\n",
        "        'vast' in os.environ.get('HOSTNAME', '').lower()\n",
        "    ]\n",
        "\n",
        "    if any(lightning_indicators):\n",
        "        return \"Lightning AI\"\n",
        "    elif any(colab_indicators):\n",
        "        return \"Google Colab\"\n",
        "    elif any(vast_indicators):\n",
        "        return \"Vast.AI/Generic\"\n",
        "    else:\n",
        "        return \"Vast.AI/Generic\"\n",
        "\n",
        "def get_platform_commands(platform):\n",
        "    \"\"\"Get platform-specific pip and python commands\"\"\"\n",
        "    if platform == \"Lightning AI\":\n",
        "        return \"pip\", \"python\", False  # pip_cmd, python_cmd, use_venv\n",
        "    elif platform == \"Google Colab\":\n",
        "        return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "    else:  # Vast.AI/Generic\n",
        "        return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "# Detect current platform\n",
        "current_platform = detect_platform()\n",
        "pip_cmd, python_cmd, use_venv = get_platform_commands(current_platform)\n",
        "\n",
        "# Display platform information\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; margin: 10px 0; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "    <h1>üöÄ Wan2GP Full Setup Notebook</h1>\n",
        "    <p>A cross-platform Jupyter notebook (Colab / Lightning AI / Vast.ai) that installs Wan2GP, common LoRA packs, and optional performance extras (FlashAttention 2, SageAttention, xFormers). It accelerates all downloads with <strong>aria2c</strong> for maximum speed.</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 8px; border: 1px solid #dee2e6; margin: 15px 0;\">\n",
        "    <div style=\"background-color: #007bff; color: white; padding: 15px; border-radius: 5px; text-align: center; margin-bottom: 20px;\">\n",
        "        <h3 style=\"margin: 0; color: white;\">üîç Platform Detection Results</h3>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Currently Running on: <strong style=\"color: #28a745; background-color: white; padding: 2px 6px; border-radius: 3px;\">{current_platform}</strong></p>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Virtual Environment: <strong>{\"Yes\" if use_venv else \"No (Lightning AI)\"}</strong></p>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Pip Command: <strong>{pip_cmd}</strong></p>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Python Command: <strong>{python_cmd}</strong></p>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "print(\"üîç Platform Detection Debug Info:\")\n",
        "print(f\"   - Detected Platform: {current_platform}\")\n",
        "print(f\"   - Python Executable: {sys.executable}\")\n",
        "print(f\"   - Current Working Directory: {os.getcwd()}\")\n",
        "print(f\"   - Google Colab Check: {'google.colab' in sys.modules}\")\n",
        "print(f\"   - Lightning Environment Variables: {[key for key in os.environ.keys() if 'LIGHTNING' in key]}\")\n",
        "print(f\"   - Virtual Environment Usage: {use_venv}\")\n",
        "print(f\"   - Pip Command: {pip_cmd}\")\n",
        "print(f\"   - Python Command: {python_cmd}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q7hLV1Oz-aBD",
        "outputId": "62b9295d-8840-440a-fb84-71968a8896fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; margin: 10px 0; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "    <h1>üöÄ Wan2GP Full Setup Notebook</h1>\n",
              "    <p>A cross-platform Jupyter notebook (Colab / Lightning AI / Vast.ai) that installs Wan2GP, common LoRA packs, and optional performance extras (FlashAttention 2, SageAttention, xFormers). It accelerates all downloads with <strong>aria2c</strong> for maximum speed.</p>\n",
              "</div>\n",
              "\n",
              "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 8px; border: 1px solid #dee2e6; margin: 15px 0;\">\n",
              "    <div style=\"background-color: #007bff; color: white; padding: 15px; border-radius: 5px; text-align: center; margin-bottom: 20px;\">\n",
              "        <h3 style=\"margin: 0; color: white;\">üîç Platform Detection Results</h3>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Currently Running on: <strong style=\"color: #28a745; background-color: white; padding: 2px 6px; border-radius: 3px;\">Google Colab</strong></p>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Virtual Environment: <strong>Yes</strong></p>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Pip Command: <strong>.venv/bin/pip</strong></p>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Python Command: <strong>.venv/bin/python</strong></p>\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Platform Detection Debug Info:\n",
            "   - Detected Platform: Google Colab\n",
            "   - Python Executable: /usr/bin/python3\n",
            "   - Current Working Directory: /content\n",
            "   - Google Colab Check: True\n",
            "   - Lightning Environment Variables: []\n",
            "   - Virtual Environment Usage: True\n",
            "   - Pip Command: .venv/bin/pip\n",
            "   - Python Command: .venv/bin/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 2 - Complete System + Python Environment Setup (Cross-Platform v3.0)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if 'google.colab' not in sys.modules:\n",
        "        from IPython.display import display, Markdown\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"Complete System + Python Environment Setup\")\n",
        "\n",
        "class CompleteEnvironmentSetup:\n",
        "    def __init__(self):\n",
        "        # Use global platform configuration from Cell 1\n",
        "        try:\n",
        "            self.current_platform = current_platform\n",
        "            self.pip_cmd = pip_cmd\n",
        "            self.python_cmd = python_cmd\n",
        "            self.use_venv = use_venv\n",
        "        except NameError:\n",
        "            print(\"‚ö†Ô∏è  Platform detection variables not found. Using fallback detection.\")\n",
        "            self.detect_platform_fallback()\n",
        "\n",
        "        self.setup_phases = [\n",
        "            (\"System Packages\", self.install_system_packages),\n",
        "            (\"Repository Clone\", self.clone_repository),\n",
        "            (\"Virtual Environment\", self.setup_virtual_environment),\n",
        "            (\"PyTorch Installation\", self.install_pytorch),\n",
        "            (\"Requirements\", self.install_requirements),\n",
        "            (\"Environment Verification\", self.verify_complete_setup)\n",
        "        ]\n",
        "\n",
        "        self.current_phase = 0\n",
        "        self.total_phases = len(self.setup_phases)\n",
        "\n",
        "    def detect_platform_fallback(self):\n",
        "        \"\"\"Fallback platform detection if Cell 1 wasn't run\"\"\"\n",
        "        if 'google.colab' in sys.modules:\n",
        "            self.current_platform = \"Google Colab\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "        elif any(['lightning' in str(sys.executable).lower(), 'teamspace' in os.getcwd()]):\n",
        "            self.current_platform = \"Lightning AI\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \"pip\", \"python\", False\n",
        "        else:\n",
        "            self.current_platform = \"Generic\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "    def update_progress(self, phase_name, status=\"in_progress\"):\n",
        "        \"\"\"Update setup progress with visual indicators\"\"\"\n",
        "        progress_percent = (self.current_phase / self.total_phases) * 100\n",
        "        status_icons = {\n",
        "            \"in_progress\": \"üîÑ\",\n",
        "            \"success\": \"‚úÖ\",\n",
        "            \"failed\": \"‚ùå\"\n",
        "        }\n",
        "\n",
        "        print(f\"\\n[{self.current_phase + 1}/{self.total_phases}] {status_icons[status]} {phase_name}\")\n",
        "        print(f\"Progress: {progress_percent:.1f}% | Platform: {self.current_platform}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "    def run_command_safely(self, command, description, timeout=300):\n",
        "        \"\"\"Execute command with comprehensive error handling\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=timeout\n",
        "            )\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(f\"‚úÖ {description} completed successfully\")\n",
        "                return True, result.stdout\n",
        "            else:\n",
        "                print(f\"‚ùå {description} failed (exit code {result.returncode})\")\n",
        "                if result.stderr:\n",
        "                    print(f\"   Error: {result.stderr.strip()[:200]}\")\n",
        "                return False, result.stderr\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"‚è∞ {description} timed out after {timeout}s\")\n",
        "            return False, f\"Timeout after {timeout}s\"\n",
        "        except Exception as e:\n",
        "            print(f\"üí• {description} crashed: {e}\")\n",
        "            return False, str(e)\n",
        "\n",
        "    def install_system_packages(self):\n",
        "        \"\"\"Install system packages - same for all platforms\"\"\"\n",
        "        print(\"üîß Installing system packages...\")\n",
        "\n",
        "        if not shutil.which('apt-get'):\n",
        "            print(\"üìã apt-get not found. Skipping system package installation.\")\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            print(\"üì¶ Updating package lists...\")\n",
        "            subprocess.run(['sudo', 'apt-get', 'update', '-qq'], check=True, timeout=60)\n",
        "\n",
        "            print(\"üîß Installing aria2, git, build-essential, and wget...\")\n",
        "            subprocess.run(['sudo', 'apt-get', 'install', '-y', 'aria2', 'git', 'build-essential', 'wget'], check=True, timeout=180)\n",
        "\n",
        "            print(\"‚úÖ System packages installed successfully\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚ùå System package installation failed: {e}\")\n",
        "            return False\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"‚è∞ System package installation timed out\")\n",
        "            return False\n",
        "\n",
        "    def clone_repository(self):\n",
        "        \"\"\"Clone WAN2GP repository\"\"\"\n",
        "        REPO_DIR = \"Wan2GP\"\n",
        "        REPO_URL = \"https://github.com/deepbeepmeep/Wan2GP.git\"\n",
        "\n",
        "        print(\"üìÇ Setting up WAN2GP repository...\")\n",
        "\n",
        "        if not os.path.exists(REPO_DIR):\n",
        "            print(f\"üì• Cloning repository from {REPO_URL}...\")\n",
        "            try:\n",
        "                subprocess.run(['git', 'clone', '--depth', '1', REPO_URL], check=True, timeout=120)\n",
        "                print(\"‚úÖ Repository cloned successfully\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"‚ùå Failed to clone repository: {e}\")\n",
        "                return False\n",
        "            except subprocess.TimeoutExpired:\n",
        "                print(\"‚è∞ Repository clone timed out\")\n",
        "                return False\n",
        "        else:\n",
        "            print(f\"‚úÖ Directory '{REPO_DIR}' already exists\")\n",
        "\n",
        "        try:\n",
        "            os.chdir(REPO_DIR)\n",
        "            print(f\"üìÅ Changed to directory: {os.getcwd()}\")\n",
        "            return True\n",
        "        except FileNotFoundError:\n",
        "            print(f\"‚ùå Directory '{REPO_DIR}' not found\")\n",
        "            return False\n",
        "\n",
        "    def setup_virtual_environment(self):\n",
        "        \"\"\"Create virtual environment ONLY if not on Lightning AI\"\"\"\n",
        "        if not self.use_venv:\n",
        "            print(\"‚ö° Lightning AI detected - using system environment (no venv)\")\n",
        "            return True\n",
        "\n",
        "        print(\"üêç Setting up virtual environment...\")\n",
        "\n",
        "        # Check if venv already exists\n",
        "        if os.path.exists('.venv/bin/python'):\n",
        "            print(\"‚úÖ Virtual environment already exists and appears functional\")\n",
        "            return True\n",
        "\n",
        "        print(\"üî® Creating virtual environment...\")\n",
        "\n",
        "        # Try multiple methods for virtual environment creation\n",
        "        venv_methods = [\n",
        "            ([sys.executable, '-m', 'venv', '--system-site-packages', '.venv'], \"venv with system packages\"),\n",
        "            ([sys.executable, '-m', 'venv', '.venv'], \"standard venv\"),\n",
        "            ([sys.executable, '-m', 'virtualenv', '.venv'], \"virtualenv package\")\n",
        "        ]\n",
        "\n",
        "        for command, method_name in venv_methods:\n",
        "            print(f\"üîÑ Trying: {method_name}\")\n",
        "            success, _ = self.run_command_safely(command, f\"Virtual environment creation ({method_name})\", timeout=60)\n",
        "            if success:\n",
        "                print(\"‚úÖ Virtual environment created successfully\")\n",
        "                return True\n",
        "\n",
        "        print(\"‚ùå All virtual environment creation methods failed\")\n",
        "        return False\n",
        "\n",
        "    def install_pytorch(self):\n",
        "        \"\"\"Install PyTorch with platform-specific optimizations\"\"\"\n",
        "        print(\"üî• Installing PyTorch...\")\n",
        "\n",
        "        # Step 1: Upgrade pip\n",
        "        print(\"üì¶ Upgrading pip...\")\n",
        "        self.run_command_safely([self.pip_cmd, 'install', '--upgrade', 'pip'], \"Pip upgrade\", timeout=60)\n",
        "\n",
        "        # Step 2: Platform-specific PyTorch installation\n",
        "        if self.current_platform == \"Lightning AI\":\n",
        "            print(\"‚ö° Lightning AI PyTorch installation\")\n",
        "            # Check if compatible PyTorch already exists\n",
        "            check_success, output = self.run_command_safely([\n",
        "                self.python_cmd, '-c', 'import torch; print(f\"Existing PyTorch: {torch.__version__}\")'\n",
        "            ], \"Checking existing PyTorch\", timeout=15)\n",
        "\n",
        "            if check_success and \"2.6\" in output:\n",
        "                print(\"‚úÖ Compatible PyTorch already installed\")\n",
        "                return True\n",
        "            else:\n",
        "                print(\"üîÑ Installing PyTorch on Lightning AI...\")\n",
        "                success, _ = self.run_command_safely([\n",
        "                    self.pip_cmd, 'install', '--upgrade',\n",
        "                    'torch==2.6.0', 'torchvision', 'torchaudio',\n",
        "                    '--index-url', 'https://download.pytorch.org/whl/cu124'\n",
        "                ], \"PyTorch installation (Lightning AI)\", timeout=600)\n",
        "                return success\n",
        "        else:\n",
        "            # Colab/Vast/Generic installation\n",
        "            print(\"üî• Installing PyTorch 2.6.0 with CUDA 12.4...\")\n",
        "            success, _ = self.run_command_safely([\n",
        "                self.pip_cmd, 'install',\n",
        "                'torch==2.6.0', 'torchvision', 'torchaudio',\n",
        "                '--index-url', 'https://download.pytorch.org/whl/cu124',\n",
        "                '--no-cache-dir'\n",
        "            ], \"PyTorch installation\", timeout=600)\n",
        "            return success\n",
        "\n",
        "    def install_requirements(self):\n",
        "        \"\"\"Install requirements.txt dependencies\"\"\"\n",
        "        print(\"üìã Installing requirements...\")\n",
        "\n",
        "        if os.path.exists('requirements.txt'):\n",
        "            success, _ = self.run_command_safely([\n",
        "                self.pip_cmd, 'install', '-r', 'requirements.txt'\n",
        "            ], \"Requirements installation\", timeout=300)\n",
        "\n",
        "            if success:\n",
        "                print(\"‚úÖ Requirements installed successfully\")\n",
        "                return True\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Some requirements failed - installing critical packages individually\")\n",
        "\n",
        "                # Fallback: install critical packages\n",
        "                critical_packages = [\n",
        "                    \"gradio>=4.0.0\", \"transformers\", \"accelerate\", \"diffusers\",\n",
        "                    \"opencv-python\", \"Pillow\", \"numpy\", \"scipy\"\n",
        "                ]\n",
        "\n",
        "                for package in critical_packages:\n",
        "                    cmd = [self.pip_cmd, 'install', package]\n",
        "                    success, _ = self.run_command_safely(cmd, f\"Installing {package}\", timeout=60)\n",
        "                    if success:\n",
        "                        print(f\"‚úÖ {package}\")\n",
        "                    else:\n",
        "                        print(f\"‚ö†Ô∏è {package} failed\")\n",
        "\n",
        "                return True\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è requirements.txt not found - skipping\")\n",
        "            return True\n",
        "\n",
        "    def verify_complete_setup(self):\n",
        "        \"\"\"Verify the complete environment setup\"\"\"\n",
        "        print(\"üß™ Verifying complete setup...\")\n",
        "\n",
        "        verification_tests = [\n",
        "            ('Python Environment', f'{self.python_cmd} -c \"import sys; print(f\\\\\"Python OK: {{sys.version}}\\\\\")\"'),\n",
        "            ('PyTorch Import', f'{self.python_cmd} -c \"import torch; print(f\\\\\"PyTorch: {{torch.__version__}}\\\\\")\"'),\n",
        "            ('CUDA Availability', f'{self.python_cmd} -c \"import torch; print(f\\\\\"CUDA: {{torch.cuda.is_available()}}\\\\\")\"'),\n",
        "            ('Core Dependencies', f'{self.python_cmd} -c \"import gradio, transformers; print(\\\\\"Core deps OK\\\\\")\"')\n",
        "        ]\n",
        "\n",
        "        passed_tests = 0\n",
        "        for test_name, test_command in verification_tests:\n",
        "            try:\n",
        "                result = subprocess.run(test_command, shell=True, capture_output=True, text=True, timeout=15)\n",
        "                if result.returncode == 0:\n",
        "                    print(f\"‚úÖ {test_name}: {result.stdout.strip()}\")\n",
        "                    passed_tests += 1\n",
        "                else:\n",
        "                    print(f\"‚ùå {test_name}: Failed\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå {test_name}: Error - {e}\")\n",
        "\n",
        "        success_rate = passed_tests / len(verification_tests)\n",
        "        if success_rate >= 0.75:  # 75% success rate acceptable\n",
        "            print(f\"‚úÖ Environment verification passed ({passed_tests}/{len(verification_tests)} tests)\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå Environment verification failed ({passed_tests}/{len(verification_tests)} tests)\")\n",
        "            return False\n",
        "\n",
        "    def run_complete_setup(self):\n",
        "        \"\"\"Execute all setup phases in sequence\"\"\"\n",
        "        print(\"üöÄ WAN2GP Complete System + Python Environment Setup\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Platform: {self.current_platform}\")\n",
        "        print(f\"Virtual Environment: {'Yes' if self.use_venv else 'No (Lightning AI)'}\")\n",
        "        print(f\"Pip Command: {self.pip_cmd}\")\n",
        "        print(f\"Python Command: {self.python_cmd}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        overall_start_time = time.time()\n",
        "\n",
        "        for phase_name, phase_function in self.setup_phases:\n",
        "            self.update_progress(phase_name, \"in_progress\")\n",
        "            phase_start_time = time.time()\n",
        "\n",
        "            try:\n",
        "                success = phase_function()\n",
        "                phase_duration = time.time() - phase_start_time\n",
        "\n",
        "                if success:\n",
        "                    self.update_progress(phase_name, \"success\")\n",
        "                    print(f\"‚è±Ô∏è {phase_name} completed in {phase_duration:.1f}s\")\n",
        "                else:\n",
        "                    self.update_progress(phase_name, \"failed\")\n",
        "                    print(f\"üí• Setup failed at: {phase_name}\")\n",
        "                    return False\n",
        "            except Exception as e:\n",
        "                phase_duration = time.time() - phase_start_time\n",
        "                self.update_progress(phase_name, \"failed\")\n",
        "                print(f\"üí• Exception in {phase_name}: {e}\")\n",
        "                return False\n",
        "\n",
        "            self.current_phase += 1\n",
        "\n",
        "        total_duration = time.time() - overall_start_time\n",
        "\n",
        "        print(\"\\nüéØ Complete Environment Setup Finished!\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"‚úÖ Final Configuration:\")\n",
        "        print(f\"   - Platform: {self.current_platform}\")\n",
        "        print(f\"   - Pip Executable: {self.pip_cmd}\")\n",
        "        print(f\"   - Python Executable: {self.python_cmd}\")\n",
        "        print(f\"   - Virtual Environment: {'Yes' if self.use_venv else 'No (Lightning AI)'}\")\n",
        "        print(f\"   - Total Setup Time: {total_duration:.1f} seconds\")\n",
        "\n",
        "        if self.current_platform == \"Lightning AI\":\n",
        "            print(\"‚ö° Lightning AI Compliance: ‚úÖ No venv usage\")\n",
        "\n",
        "        print(\"\\nüìã Ready for performance optimizations and LoRA downloads!\")\n",
        "        return True\n",
        "\n",
        "# Execute the complete setup\n",
        "setup_manager = CompleteEnvironmentSetup()\n",
        "setup_success = setup_manager.run_complete_setup()\n",
        "\n",
        "if not setup_success:\n",
        "    print(\"\\nüîÑ Setup Issues - Platform-Specific Troubleshooting:\")\n",
        "    if setup_manager.current_platform == \"Lightning AI\":\n",
        "        print(\"‚ö° Lightning AI: Check system package availability\")\n",
        "    elif setup_manager.current_platform == \"Google Colab\":\n",
        "        print(\"üì± Colab: Restart runtime and re-run all cells\")\n",
        "    else:\n",
        "        print(\"üîÑ Generic: Check system permissions and network connectivity\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Wc1mj9zi_ExM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab0d0de-8a96-47c4-d116-1e5fbe9cf5b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ WAN2GP Complete System + Python Environment Setup\n",
            "======================================================================\n",
            "Platform: Google Colab\n",
            "Virtual Environment: Yes\n",
            "Pip Command: .venv/bin/pip\n",
            "Python Command: .venv/bin/python\n",
            "======================================================================\n",
            "\n",
            "[1/6] üîÑ System Packages\n",
            "Progress: 0.0% | Platform: Google Colab\n",
            "============================================================\n",
            "üîß Installing system packages...\n",
            "üì¶ Updating package lists...\n",
            "üîß Installing aria2, git, build-essential, and wget...\n",
            "‚úÖ System packages installed successfully\n",
            "\n",
            "[1/6] ‚úÖ System Packages\n",
            "Progress: 0.0% | Platform: Google Colab\n",
            "============================================================\n",
            "‚è±Ô∏è System Packages completed in 20.9s\n",
            "\n",
            "[2/6] üîÑ Repository Clone\n",
            "Progress: 16.7% | Platform: Google Colab\n",
            "============================================================\n",
            "üìÇ Setting up WAN2GP repository...\n",
            "üì• Cloning repository from https://github.com/deepbeepmeep/Wan2GP.git...\n",
            "‚úÖ Repository cloned successfully\n",
            "üìÅ Changed to directory: /content/Wan2GP\n",
            "\n",
            "[2/6] ‚úÖ Repository Clone\n",
            "Progress: 16.7% | Platform: Google Colab\n",
            "============================================================\n",
            "‚è±Ô∏è Repository Clone completed in 1.1s\n",
            "\n",
            "[3/6] üîÑ Virtual Environment\n",
            "Progress: 33.3% | Platform: Google Colab\n",
            "============================================================\n",
            "üêç Setting up virtual environment...\n",
            "üî® Creating virtual environment...\n",
            "üîÑ Trying: venv with system packages\n",
            "‚ùå Virtual environment creation (venv with system packages) failed (exit code 1)\n",
            "   Error: Error: Command '['/content/Wan2GP/.venv/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n",
            "üîÑ Trying: standard venv\n",
            "‚ùå Virtual environment creation (standard venv) failed (exit code 1)\n",
            "   Error: Error: Command '['/content/Wan2GP/.venv/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n",
            "üîÑ Trying: virtualenv package\n",
            "‚ùå Virtual environment creation (virtualenv package) failed (exit code 1)\n",
            "   Error: /usr/bin/python3: No module named virtualenv\n",
            "‚ùå All virtual environment creation methods failed\n",
            "\n",
            "[3/6] ‚ùå Virtual Environment\n",
            "Progress: 33.3% | Platform: Google Colab\n",
            "============================================================\n",
            "üí• Setup failed at: Virtual Environment\n",
            "\n",
            "üîÑ Setup Issues - Platform-Specific Troubleshooting:\n",
            "üì± Colab: Restart runtime and re-run all cells\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 3 - Performance Optimizations + LoRA Downloads (Cross-Platform v5.0)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if 'google.colab' not in sys.modules:\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"Performance Optimizations + LoRA Downloads\")\n",
        "\n",
        "class PerformanceAndLoRAManager:\n",
        "    def __init__(self):\n",
        "        # Use global platform configuration\n",
        "        try:\n",
        "            self.current_platform = current_platform\n",
        "            self.pip_cmd = pip_cmd\n",
        "            self.python_cmd = python_cmd\n",
        "            self.use_venv = use_venv\n",
        "        except NameError:\n",
        "            print(\"‚ö†Ô∏è Platform detection not found. Using fallback.\")\n",
        "            if 'google.colab' in sys.modules:\n",
        "                self.current_platform = \"Google Colab\"\n",
        "                self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "            else:\n",
        "                self.current_platform = \"Lightning AI\"\n",
        "                self.pip_cmd, self.python_cmd, self.use_venv = \"pip\", \"python\", False\n",
        "\n",
        "        self.hf_auth = HuggingFaceAuth()\n",
        "        self.download_stats = {'total': 0, 'success': 0, 'failed': 0}\n",
        "\n",
        "        # Performance packages configuration\n",
        "        self.performance_packages = {\n",
        "            \"FlashAttention\": {\n",
        "                \"strategies\": [\n",
        "                    {\n",
        "                        \"name\": \"Direct install (fast)\",\n",
        "                        \"command\": [\"pip\", \"install\", \"flash-attn==2.6.3\", \"--no-cache-dir\"],\n",
        "                        \"timeout\": 180\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"Alternative version\",\n",
        "                        \"command\": [\"pip\", \"install\", \"flash-attn==2.7.2.post1\", \"--no-cache-dir\"],\n",
        "                        \"timeout\": 600\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "            \"SageAttention\": {\n",
        "                \"strategies\": [\n",
        "                    {\n",
        "                        \"name\": \"Stable version\",\n",
        "                        \"command\": [\"pip\", \"install\", \"sageattention==1.0.6\", \"--no-cache-dir\"],\n",
        "                        \"timeout\": 120\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"Latest version\",\n",
        "                        \"command\": [\"pip\", \"install\", \"sageattention==2.1.1\", \"--no-cache-dir\"],\n",
        "                        \"timeout\": 180\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "            \"xFormers\": {\n",
        "                \"strategies\": [\n",
        "                    {\n",
        "                        \"name\": \"Latest stable\",\n",
        "                        \"command\": [\"pip\", \"install\", \"xformers\", \"--no-cache-dir\"],\n",
        "                        \"timeout\": 120\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"Specific version\",\n",
        "                        \"command\": [\"pip\", \"install\", \"xformers==0.0.28.post1\", \"--no-cache-dir\"],\n",
        "                        \"timeout\": 180\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Official LoRA collection\n",
        "        self.official_loras = {\n",
        "            'Safe-Forcing lightx2v': {\n",
        "                'url': 'https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_T2V_14B_lightx2v_cfg_step_distill_lora_rank32.safetensors',\n",
        "                'filename': 'Wan21_T2V_14B_lightx2v_cfg_step_distill_lora_rank32.safetensors',\n",
        "                'directory': 'loras',\n",
        "                'category': 'acceleration',\n",
        "                'description': '2-8 steps generation, 2x speed improvement',\n",
        "                'size_mb': 89,\n",
        "                'requires_auth': True\n",
        "            },\n",
        "            'CausVid': {\n",
        "                'url': 'https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_CausVid_14B_T2V_lora_rank32.safetensors',\n",
        "                'filename': 'Wan21_CausVid_14B_T2V_lora_rank32.safetensors',\n",
        "                'directory': 'loras',\n",
        "                'category': 'acceleration',\n",
        "                'description': '4-12 steps generation, 2x speed improvement',\n",
        "                'size_mb': 89,\n",
        "                'requires_auth': True\n",
        "            },\n",
        "            'AccVid T2V': {\n",
        "                'url': 'https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_AccVid_T2V_14B_lora_rank32_fp16.safetensors',\n",
        "                'filename': 'Wan21_AccVid_T2V_14B_lora_rank32_fp16.safetensors',\n",
        "                'directory': 'loras',\n",
        "                'category': 'acceleration',\n",
        "                'description': '2x speed improvement, CFG=1',\n",
        "                'size_mb': 44,\n",
        "                'requires_auth': True\n",
        "            },\n",
        "            'AccVid I2V': {\n",
        "                'url': 'https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_AccVid_I2V_480P_14B_lora_rank32_fp16.safetensors',\n",
        "                'filename': 'Wan21_AccVid_I2V_480P_14B_lora_rank32_fp16.safetensors',\n",
        "                'directory': 'loras/i2v',\n",
        "                'category': 'image-to-video',\n",
        "                'description': 'Image-to-video acceleration',\n",
        "                'size_mb': 44,\n",
        "                'requires_auth': True\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def run_command_with_timeout(self, command, timeout_seconds=300, description=\"Installation\"):\n",
        "        \"\"\"Run command with timeout and progress monitoring\"\"\"\n",
        "        print(f\"üîÑ Starting: {description}\")\n",
        "        print(f\"‚è±Ô∏è Timeout: {timeout_seconds} seconds\")\n",
        "\n",
        "        try:\n",
        "            process = subprocess.Popen(\n",
        "                command,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                universal_newlines=True\n",
        "            )\n",
        "\n",
        "            start_time = time.time()\n",
        "            dots_printed = 0\n",
        "\n",
        "            while process.poll() is None:\n",
        "                elapsed = time.time() - start_time\n",
        "\n",
        "                if int(elapsed) % 5 == 0 and int(elapsed) > dots_printed * 5:\n",
        "                    print(\".\", end=\"\", flush=True)\n",
        "                    dots_printed += 1\n",
        "\n",
        "                if elapsed > timeout_seconds:\n",
        "                    print(f\"\\n‚è∞ TIMEOUT after {timeout_seconds}s\")\n",
        "                    process.terminate()\n",
        "                    time.sleep(2)\n",
        "                    if process.poll() is None:\n",
        "                        process.kill()\n",
        "                    return False, f\"Timeout after {timeout_seconds} seconds\"\n",
        "\n",
        "                time.sleep(1)\n",
        "\n",
        "            stdout, stderr = process.communicate()\n",
        "            return_code = process.returncode\n",
        "\n",
        "            print()  # New line after dots\n",
        "\n",
        "            if return_code == 0:\n",
        "                print(f\"‚úÖ {description} completed successfully\")\n",
        "                return True, \"Success\"\n",
        "            else:\n",
        "                print(f\"‚ùå {description} failed (exit code {return_code})\")\n",
        "                if stderr:\n",
        "                    print(f\"   Error: {stderr.strip()[:200]}\")\n",
        "                return False, f\"Failed with exit code {return_code}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nüí• {description} crashed: {str(e)}\")\n",
        "            return False, f\"Exception: {str(e)}\"\n",
        "\n",
        "    def install_performance_packages(self):\n",
        "        \"\"\"Install all performance optimization packages\"\"\"\n",
        "        print(\"üî• Installing Performance Optimizations\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Platform: {self.current_platform}\")\n",
        "        print(f\"Using pip: {self.pip_cmd}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        installation_results = {}\n",
        "        total_start_time = time.time()\n",
        "\n",
        "        for package_name, package_config in self.performance_packages.items():\n",
        "            print(f\"\\nüöÄ Installing {package_name}...\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            package_start_time = time.time()\n",
        "            success = False\n",
        "\n",
        "            for i, strategy in enumerate(package_config[\"strategies\"], 1):\n",
        "                strategy_name = strategy[\"name\"]\n",
        "                command = [self.pip_cmd] + strategy[\"command\"][1:]  # Replace pip with detected pip\n",
        "                timeout = strategy.get(\"timeout\", 300)\n",
        "\n",
        "                print(f\"\\n[{i}/{len(package_config['strategies'])}] Trying: {strategy_name}\")\n",
        "\n",
        "                install_success, message = self.run_command_with_timeout(\n",
        "                    command,\n",
        "                    timeout_seconds=timeout,\n",
        "                    description=f\"{package_name} via {strategy_name}\"\n",
        "                )\n",
        "\n",
        "                if install_success:\n",
        "                    print(f\"‚úÖ {package_name} installed successfully\")\n",
        "                    success = True\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"‚ùå {strategy_name} failed: {message}\")\n",
        "                    if i < len(package_config[\"strategies\"]):\n",
        "                        print(\"üîÑ Trying next strategy...\")\n",
        "\n",
        "            package_duration = time.time() - package_start_time\n",
        "            installation_results[package_name] = {\n",
        "                \"success\": success,\n",
        "                \"duration\": package_duration\n",
        "            }\n",
        "\n",
        "            if not success:\n",
        "                print(f\"‚ö†Ô∏è {package_name} installation failed - will use fallback\")\n",
        "\n",
        "        # Display performance installation summary\n",
        "        total_duration = time.time() - total_start_time\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"üìä Performance Installation Summary:\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        successful_packages = 0\n",
        "        for package, result in installation_results.items():\n",
        "            status_icon = \"‚úÖ\" if result[\"success\"] else \"‚ùå\"\n",
        "            duration = result[\"duration\"]\n",
        "            print(f\"{status_icon} {package}: {'SUCCESS' if result['success'] else 'FAILED'} ({duration:.1f}s)\")\n",
        "            if result[\"success\"]:\n",
        "                successful_packages += 1\n",
        "\n",
        "        print(f\"\\nüéØ Performance Results: {successful_packages}/{len(installation_results)} packages installed\")\n",
        "        print(f\"‚è±Ô∏è Total time: {total_duration:.1f} seconds\")\n",
        "\n",
        "        return successful_packages > 0  # Success if at least one package installed\n",
        "\n",
        "    def install_download_dependencies(self):\n",
        "        \"\"\"Install dependencies for LoRA downloads\"\"\"\n",
        "        print(\"\\nüì¶ Installing download dependencies...\")\n",
        "\n",
        "        dependencies = ['requests', 'aria2p']\n",
        "        for dep in dependencies:\n",
        "            try:\n",
        "                result = subprocess.run([\n",
        "                    self.pip_cmd, 'install', dep, '--no-cache-dir'\n",
        "                ], capture_output=True, text=True, timeout=60)\n",
        "\n",
        "                if result.returncode == 0:\n",
        "                    print(f\"‚úÖ {dep} installed successfully\")\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è {dep} installation failed (non-critical)\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error installing {dep}: {e}\")\n",
        "\n",
        "    def create_lora_directories(self):\n",
        "        \"\"\"Create necessary LoRA directories\"\"\"\n",
        "        directories = ['loras', 'loras/i2v', 'loras/hunyuan', 'loras/ltxv']\n",
        "        for directory in directories:\n",
        "            Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"üìÅ Created directory: {directory}\")\n",
        "\n",
        "    def download_with_aria2c(self, url, filename, auth_token=None):\n",
        "        \"\"\"Download using aria2c with authentication\"\"\"\n",
        "        try:\n",
        "            cmd = ['aria2c', '--max-connection-per-server=16', '--split=16', '--min-split-size=1M']\n",
        "\n",
        "            if auth_token:\n",
        "                cmd.extend(['--header', f'Authorization: Bearer {auth_token}'])\n",
        "\n",
        "            cmd.extend(['-o', filename, url])\n",
        "\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
        "            return result.returncode == 0\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    def download_with_requests(self, url, filename, auth_token=None):\n",
        "        \"\"\"Fallback download using requests\"\"\"\n",
        "        try:\n",
        "            headers = {}\n",
        "            if auth_token:\n",
        "                headers['Authorization'] = f'Bearer {auth_token}'\n",
        "\n",
        "            response = requests.get(url, headers=headers, stream=True, timeout=30)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "            downloaded = 0\n",
        "\n",
        "            with open(filename, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "                        downloaded += len(chunk)\n",
        "                        if total_size > 0:\n",
        "                            progress = (downloaded / total_size) * 100\n",
        "                            print(f\"\\rüì• Progress: {progress:.1f}%\", end='', flush=True)\n",
        "\n",
        "            print(f\"\\n‚úÖ Downloaded: {os.path.basename(filename)}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Download failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def download_lora(self, lora_name, lora_info):\n",
        "        \"\"\"Download a single LoRA with fallback methods\"\"\"\n",
        "        url = lora_info['url']\n",
        "        directory = lora_info['directory']\n",
        "        filename = lora_info['filename']\n",
        "        requires_auth = lora_info.get('requires_auth', False)\n",
        "\n",
        "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "        filepath = os.path.join(directory, filename)\n",
        "\n",
        "        if os.path.exists(filepath):\n",
        "            print(f\"‚úÖ {filename} already exists, skipping download\")\n",
        "            return True\n",
        "\n",
        "        auth_token = self.hf_auth.token if requires_auth and self.hf_auth.authenticated else None\n",
        "\n",
        "        print(f\"üì• Downloading: {filename}\")\n",
        "\n",
        "        if self.download_with_aria2c(filepath, url, auth_token):\n",
        "            return True\n",
        "\n",
        "        print(\"üîÑ aria2c failed, trying requests...\")\n",
        "        return self.download_with_requests(url, filepath, auth_token)\n",
        "\n",
        "    def setup_lora_interface(self):\n",
        "        \"\"\"Set up the interactive LoRA download interface\"\"\"\n",
        "\n",
        "        # Authentication section\n",
        "        auth_html = HTML(f\"\"\"\n",
        "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; margin: 15px 0;\">\n",
        "            <h3>üîê HuggingFace Authentication</h3>\n",
        "            <div style=\"background: rgba(255,255,255,0.1); padding: 10px; border-radius: 6px; margin: 10px 0;\">\n",
        "                <strong>Platform:</strong> {self.current_platform}<br>\n",
        "                <strong>Pip Command:</strong> {self.pip_cmd}<br>\n",
        "                <strong>Virtual Environment:</strong> {'Yes' if self.use_venv else 'No (Lightning AI)'}\n",
        "            </div>\n",
        "            <p>All official LoRAs require HuggingFace authentication. Get your token from:\n",
        "            <a href=\"https://huggingface.co/settings/tokens\" target=\"_blank\" style=\"color: #ffeb3b;\">HuggingFace Settings</a></p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Authentication widgets\n",
        "        token_input = widgets.Password(\n",
        "            placeholder='Enter your HuggingFace token here...',\n",
        "            description='HF Token:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        auth_button = widgets.Button(description='üîê Authenticate', button_style='success')\n",
        "        clear_auth_button = widgets.Button(description='üö´ Clear Auth', button_style='danger')\n",
        "        auth_status = widgets.HTML(value=\"<span style='color: #dc3545; font-weight: bold;'>üî¥ Not authenticated</span>\")\n",
        "\n",
        "        def authenticate_hf(b):\n",
        "            if token_input.value:\n",
        "                if self.hf_auth.set_token(token_input.value):\n",
        "                    auth_status.value = \"<span style='color: #28a745; font-weight: bold;'>‚úÖ Authenticated</span>\"\n",
        "                    print(\"üîê HuggingFace authentication successful\")\n",
        "                else:\n",
        "                    auth_status.value = \"<span style='color: #dc3545; font-weight: bold;'>‚ùå Authentication failed</span>\"\n",
        "            else:\n",
        "                auth_status.value = \"<span style='color: #dc3545; font-weight: bold;'>‚ùå No token provided</span>\"\n",
        "\n",
        "        def clear_auth(b):\n",
        "            self.hf_auth.token = None\n",
        "            self.hf_auth.authenticated = False\n",
        "            token_input.value = \"\"\n",
        "            auth_status.value = \"<span style='color: #dc3545; font-weight: bold;'>üî¥ Not authenticated</span>\"\n",
        "            print(\"üö´ Authentication cleared\")\n",
        "\n",
        "        auth_button.on_click(authenticate_hf)\n",
        "        clear_auth_button.on_click(clear_auth)\n",
        "\n",
        "        # LoRA selection interface\n",
        "        categories = {}\n",
        "        for name, info in self.official_loras.items():\n",
        "            category = info['category']\n",
        "            if category not in categories:\n",
        "                categories[category] = []\n",
        "            categories[category].append((name, info))\n",
        "\n",
        "        lora_checkboxes = {}\n",
        "        category_widgets = []\n",
        "\n",
        "        for category, loras in categories.items():\n",
        "            category_header = widgets.HTML(\n",
        "                value=f'<div style=\"background: linear-gradient(90deg, #28a745, #20c997); color: white; padding: 12px 20px; border-radius: 8px; margin: 20px 0 10px 0; font-weight: bold; font-size: 16px;\">üìÇ {category.upper()} LoRAs</div>'\n",
        "            )\n",
        "            category_widgets.append(category_header)\n",
        "\n",
        "            for name, info in loras:\n",
        "                checkbox = widgets.Checkbox(\n",
        "                    value=False,\n",
        "                    description=f\"{name} - {info['description']} ({info['size_mb']}MB)\",\n",
        "                    style={'description_width': 'initial'},\n",
        "                    layout=widgets.Layout(width='700px', margin='2px 0')\n",
        "                )\n",
        "                lora_checkboxes[name] = checkbox\n",
        "                category_widgets.append(checkbox)\n",
        "\n",
        "        # Control buttons\n",
        "        select_all_button = widgets.Button(description='‚òëÔ∏è Select All LoRAs', button_style='info')\n",
        "        clear_all_button = widgets.Button(description='‚òê Clear All Selections', button_style='warning')\n",
        "        download_button = widgets.Button(description='üì• Download Selected LoRAs', button_style='success')\n",
        "\n",
        "        progress_bar = widgets.IntProgress(value=0, min=0, max=100, description='Progress:')\n",
        "        output_area = widgets.Output()\n",
        "\n",
        "        def select_all_loras(b):\n",
        "            for checkbox in lora_checkboxes.values():\n",
        "                checkbox.value = True\n",
        "\n",
        "        def clear_all_loras(b):\n",
        "            for checkbox in lora_checkboxes.values():\n",
        "                checkbox.value = False\n",
        "\n",
        "        def download_selected_loras(b):\n",
        "            with output_area:\n",
        "                output_area.clear_output()\n",
        "                selected_loras = [name for name, checkbox in lora_checkboxes.items() if checkbox.value]\n",
        "\n",
        "                if not selected_loras:\n",
        "                    print(\"‚ÑπÔ∏è No LoRAs selected for download\")\n",
        "                    return\n",
        "\n",
        "                auth_required = any(self.official_loras[name].get('requires_auth', False) for name in selected_loras)\n",
        "                if auth_required and not self.hf_auth.authenticated:\n",
        "                    print(\"‚ùå Some selected LoRAs require HuggingFace authentication\")\n",
        "                    return\n",
        "\n",
        "                print(f\"üöÄ Starting download of {len(selected_loras)} LoRA(s)\")\n",
        "                print(f\"üìã Platform: {self.current_platform}\")\n",
        "                print(\"=\" * 50)\n",
        "\n",
        "                self.create_lora_directories()\n",
        "                progress_bar.max = len(selected_loras)\n",
        "                self.download_stats = {'total': len(selected_loras), 'success': 0, 'failed': 0}\n",
        "\n",
        "                for i, lora_name in enumerate(selected_loras, 1):\n",
        "                    print(f\"\\nüì¶ [{i}/{len(selected_loras)}] {lora_name}\")\n",
        "                    print(\"-\" * 40)\n",
        "\n",
        "                    lora_info = self.official_loras[lora_name]\n",
        "                    if self.download_lora(lora_name, lora_info):\n",
        "                        self.download_stats['success'] += 1\n",
        "                        print(f\"‚úÖ {lora_name} completed successfully\")\n",
        "                    else:\n",
        "                        self.download_stats['failed'] += 1\n",
        "                        print(f\"‚ùå {lora_name} failed to download\")\n",
        "\n",
        "                    progress_bar.value = i\n",
        "\n",
        "                stats = self.download_stats\n",
        "                print(\"\\n\" + \"=\" * 50)\n",
        "                print(\"üìä Download Summary:\")\n",
        "                print(f\"   Total: {stats['total']}\")\n",
        "                print(f\"   Success: {stats['success']} ‚úÖ\")\n",
        "                print(f\"   Failed: {stats['failed']} ‚ùå\")\n",
        "\n",
        "        select_all_button.on_click(select_all_loras)\n",
        "        clear_all_button.on_click(clear_all_loras)\n",
        "        download_button.on_click(download_selected_loras)\n",
        "\n",
        "        # Display interface\n",
        "        display(auth_html)\n",
        "        display(widgets.HBox([token_input, auth_button, clear_auth_button]))\n",
        "        display(auth_status)\n",
        "        display(widgets.HTML(\"<br>\"))\n",
        "        display(widgets.HBox([select_all_button, clear_all_button, download_button]))\n",
        "        display(progress_bar)\n",
        "\n",
        "        for widget in category_widgets:\n",
        "            display(widget)\n",
        "\n",
        "        display(widgets.HTML(\"<br>\"))\n",
        "        display(output_area)\n",
        "\n",
        "    def run_complete_performance_and_lora_setup(self):\n",
        "        \"\"\"Execute complete performance and LoRA setup\"\"\"\n",
        "        print(\"üî• WAN2GP Performance Optimizations + LoRA Downloads\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Platform: {self.current_platform}\")\n",
        "        print(f\"Using pip: {self.pip_cmd}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Phase 1: Install performance packages\n",
        "        performance_success = self.install_performance_packages()\n",
        "\n",
        "        # Phase 2: Set up LoRA downloads\n",
        "        print(\"\\nüì¶ Setting up LoRA download system...\")\n",
        "        self.install_download_dependencies()\n",
        "\n",
        "        # Phase 3: Display interactive LoRA interface\n",
        "        print(\"\\nüé® Interactive LoRA Download Interface\")\n",
        "        print(\"=\" * 50)\n",
        "        self.setup_lora_interface()\n",
        "\n",
        "        print(f\"\\n‚ú® Performance + LoRA Setup Complete!\")\n",
        "        print(f\"üìã Platform: {self.current_platform}\")\n",
        "        print(f\"üîß Performance packages: {'Some installed' if performance_success else 'Failed - will use fallback'}\")\n",
        "        print(\"üîÑ Ready for WAN2GP launch!\")\n",
        "\n",
        "        return True\n",
        "\n",
        "# Authentication helper class\n",
        "class HuggingFaceAuth:\n",
        "    def __init__(self):\n",
        "        self.token = None\n",
        "        self.authenticated = False\n",
        "\n",
        "    def set_token(self, token):\n",
        "        if token and token.strip():\n",
        "            self.token = token.strip()\n",
        "            self.authenticated = True\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "# Execute the complete performance and LoRA setup\n",
        "manager = PerformanceAndLoRAManager()\n",
        "setup_success = manager.run_complete_performance_and_lora_setup()\n"
      ],
      "metadata": {
        "id": "yP38IfT3_Gy9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c0d4f1a0eed749e3b90d4615c6d5ce56",
            "c973a012f3814a4d8ba009a158b608d0",
            "bd23376cdd344017a4f892dc34cd5207",
            "bf4662c2448c4ed18a819e7b9bc01e20",
            "17727f9759d74b3f969e1c801229ca7d",
            "11c97b5235a24b21a479c44221636c16",
            "34b377ce972745b8a6230da4f76fec76",
            "19b200f6d734471e94c510e672166565",
            "ba682407f14648e796fb11635b3b2e52",
            "52774508a33943e58705553dee14adda",
            "81d9f8e1415b4a72898bf9caa1757870",
            "efcf4c82a99b4d50bc1f655b20e92912",
            "b91a7a8040e94189bc7f3ab1823f865f",
            "c9270e28e2a34096bef343a9626ed87c",
            "954107bc6f774536a0fc8dee4e7cc6cb",
            "606be75fe82e4451b758b4ed55531a23",
            "1512f08d8ff24637ac87f3f50f07b561",
            "3c4c93e35a394ad1b3dfe515ca57d768",
            "352b514653b44f79a9a9e74576512908",
            "b88aa9ef9e5f446a8a5597fdd090d8cd",
            "7bdf2d4625dc4be48a5edc8d7efcd2d7",
            "4f59c028917145019508ffe33f6caa65",
            "33bc1b5985cd4b2492df363f4b0475d8",
            "a81f8a7e5ebd44b5964402c484ee7602",
            "bac99f5916c24e7d9fd707be1960c435",
            "803a0770938944cb80948db75838ef4e",
            "db4078f0c1ac4338a5fe5da1ad59d63b",
            "bdf2aaf3b8f4452a9b882f901bf1d4bd",
            "2ab302be476245db8b46b9ec917b9bcf",
            "5ae3f3c7068045df8d6b7625436465a6",
            "eaa1e11fe84f494bb718c7b92b81262a",
            "cc68c29aadcf496f8cb48269d76ce00c",
            "328e0ccf73134ee890d8a386a83f5b35",
            "efcf02e17249493f8705be717b9b417a",
            "657f73988f6b464aac5f3b5f7d224d28",
            "a407691a8d414b0d9c51172daf8739f3",
            "acc923a14c91448b812b7edae1a1cd42",
            "cd49eb2518ef4843bc80225065677e21",
            "a8dfc4c7637949128bab7e6d7ac800fa",
            "76ebe70230254e68a7475ac231191c51",
            "188ba320ab4047c995135f3ea44fc18b",
            "e030992eda8448b7b62a7194ad678b75",
            "e94dab324d584070b29986f63b687b46",
            "94700edb2cc14b6d96701674d464a2a4",
            "c1bb26c8182e42218c0b2f8cd80256d8",
            "8efe086f5a2f485f9f14811d92c74aec",
            "33e3879bc96c4df29150866ca73809ac",
            "983401f454a6432bb6328da304cfe6de",
            "e6fea0d1300f42158985baeecd8f310a",
            "93ba6a86c9ef42d09ab9e5147a9b774d",
            "77f76c3ec5134d00a8f52cc47995c20a",
            "a88037e664194958b1adca097fc4814d",
            "16b91894a4ad434fa1bd6829195a3ee6",
            "75054a1ab1c64bb5a1bf54ac9582afe9"
          ]
        },
        "outputId": "71893597-37b5-4988-a8a0-6b083d4c31b5",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî• WAN2GP Performance Optimizations + LoRA Downloads\n",
            "======================================================================\n",
            "Platform: Google Colab\n",
            "Using pip: .venv/bin/pip\n",
            "======================================================================\n",
            "üî• Installing Performance Optimizations\n",
            "============================================================\n",
            "Platform: Google Colab\n",
            "Using pip: .venv/bin/pip\n",
            "============================================================\n",
            "\n",
            "üöÄ Installing FlashAttention...\n",
            "----------------------------------------\n",
            "\n",
            "[1/2] Trying: Direct install (fast)\n",
            "üîÑ Starting: FlashAttention via Direct install (fast)\n",
            "‚è±Ô∏è Timeout: 180 seconds\n",
            "\n",
            "üí• FlashAttention via Direct install (fast) crashed: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ùå Direct install (fast) failed: Exception: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "üîÑ Trying next strategy...\n",
            "\n",
            "[2/2] Trying: Alternative version\n",
            "üîÑ Starting: FlashAttention via Alternative version\n",
            "‚è±Ô∏è Timeout: 600 seconds\n",
            "\n",
            "üí• FlashAttention via Alternative version crashed: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ùå Alternative version failed: Exception: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ö†Ô∏è FlashAttention installation failed - will use fallback\n",
            "\n",
            "üöÄ Installing SageAttention...\n",
            "----------------------------------------\n",
            "\n",
            "[1/2] Trying: Stable version\n",
            "üîÑ Starting: SageAttention via Stable version\n",
            "‚è±Ô∏è Timeout: 120 seconds\n",
            "\n",
            "üí• SageAttention via Stable version crashed: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ùå Stable version failed: Exception: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "üîÑ Trying next strategy...\n",
            "\n",
            "[2/2] Trying: Latest version\n",
            "üîÑ Starting: SageAttention via Latest version\n",
            "‚è±Ô∏è Timeout: 180 seconds\n",
            "\n",
            "üí• SageAttention via Latest version crashed: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ùå Latest version failed: Exception: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ö†Ô∏è SageAttention installation failed - will use fallback\n",
            "\n",
            "üöÄ Installing xFormers...\n",
            "----------------------------------------\n",
            "\n",
            "[1/2] Trying: Latest stable\n",
            "üîÑ Starting: xFormers via Latest stable\n",
            "‚è±Ô∏è Timeout: 120 seconds\n",
            "\n",
            "üí• xFormers via Latest stable crashed: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ùå Latest stable failed: Exception: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "üîÑ Trying next strategy...\n",
            "\n",
            "[2/2] Trying: Specific version\n",
            "üîÑ Starting: xFormers via Specific version\n",
            "‚è±Ô∏è Timeout: 180 seconds\n",
            "\n",
            "üí• xFormers via Specific version crashed: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ùå Specific version failed: Exception: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ö†Ô∏è xFormers installation failed - will use fallback\n",
            "\n",
            "============================================================\n",
            "üìä Performance Installation Summary:\n",
            "============================================================\n",
            "‚ùå FlashAttention: FAILED (0.0s)\n",
            "‚ùå SageAttention: FAILED (0.0s)\n",
            "‚ùå xFormers: FAILED (0.0s)\n",
            "\n",
            "üéØ Performance Results: 0/3 packages installed\n",
            "‚è±Ô∏è Total time: 0.0 seconds\n",
            "\n",
            "üì¶ Setting up LoRA download system...\n",
            "\n",
            "üì¶ Installing download dependencies...\n",
            "‚ö†Ô∏è Error installing requests: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "‚ö†Ô∏è Error installing aria2p: [Errno 2] No such file or directory: '.venv/bin/pip'\n",
            "\n",
            "üé® Interactive LoRA Download Interface\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; margin: 15px 0;\">\n",
              "            <h3>üîê HuggingFace Authentication</h3>\n",
              "            <div style=\"background: rgba(255,255,255,0.1); padding: 10px; border-radius: 6px; margin: 10px 0;\">\n",
              "                <strong>Platform:</strong> Google Colab<br>\n",
              "                <strong>Pip Command:</strong> .venv/bin/pip<br>\n",
              "                <strong>Virtual Environment:</strong> Yes\n",
              "            </div>\n",
              "            <p>All official LoRAs require HuggingFace authentication. Get your token from:\n",
              "            <a href=\"https://huggingface.co/settings/tokens\" target=\"_blank\" style=\"color: #ffeb3b;\">HuggingFace Settings</a></p>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Password(description='HF Token:', layout=Layout(width='400px'), placeholder='Enter your Hugging‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0d4f1a0eed749e3b90d4615c6d5ce56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value=\"<span style='color: #dc3545; font-weight: bold;'>üî¥ Not authenticated</span>\")"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efcf4c82a99b4d50bc1f655b20e92912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<br>')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "954107bc6f774536a0fc8dee4e7cc6cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(button_style='info', description='‚òëÔ∏è Select All LoRAs', style=ButtonStyle()), Button(but‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c4c93e35a394ad1b3dfe515ca57d768"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntProgress(value=0, description='Progress:')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ab302be476245db8b46b9ec917b9bcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<div style=\"background: linear-gradient(90deg, #28a745, #20c997); color: white; padding: 12px 20px‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc68c29aadcf496f8cb48269d76ce00c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Checkbox(value=False, description='Safe-Forcing lightx2v - 2-8 steps generation, 2x speed improvement (89MB)',‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "657f73988f6b464aac5f3b5f7d224d28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Checkbox(value=False, description='CausVid - 4-12 steps generation, 2x speed improvement (89MB)', layout=Layou‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd49eb2518ef4843bc80225065677e21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Checkbox(value=False, description='AccVid T2V - 2x speed improvement, CFG=1 (44MB)', layout=Layout(margin='2px‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "188ba320ab4047c995135f3ea44fc18b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<div style=\"background: linear-gradient(90deg, #28a745, #20c997); color: white; padding: 12px 20px‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94700edb2cc14b6d96701674d464a2a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Checkbox(value=False, description='AccVid I2V - Image-to-video acceleration (44MB)', layout=Layout(margin='2px‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33e3879bc96c4df29150866ca73809ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<br>')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93ba6a86c9ef42d09ab9e5147a9b774d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16b91894a4ad434fa1bd6829195a3ee6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® Performance + LoRA Setup Complete!\n",
            "üìã Platform: Google Colab\n",
            "üîß Performance packages: Failed - will use fallback\n",
            "üîÑ Ready for WAN2GP launch!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 4 - WAN2GP Launch (Cross-Platform Final v6.0)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if 'google.colab' not in sys.modules:\n",
        "        from IPython.display import display, Markdown\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"WAN2GP Launch (Cross-Platform Final)\")\n",
        "\n",
        "class CrossPlatformWAN2GPLauncher:\n",
        "    def __init__(self):\n",
        "        # Use global platform configuration\n",
        "        try:\n",
        "            self.current_platform = current_platform\n",
        "            self.pip_cmd = pip_cmd\n",
        "            self.python_cmd = python_cmd\n",
        "            self.use_venv = use_venv\n",
        "        except NameError:\n",
        "            print(\"‚ö†Ô∏è Platform detection not found. Using fallback.\")\n",
        "            if 'google.colab' in sys.modules:\n",
        "                self.current_platform = \"Google Colab\"\n",
        "                self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "            else:\n",
        "                self.current_platform = \"Lightning AI\"\n",
        "                self.pip_cmd, self.python_cmd, self.use_venv = \"pip\", \"python\", False\n",
        "\n",
        "        self.process = None\n",
        "        self.launch_success = False\n",
        "\n",
        "    def verify_environment(self):\n",
        "        \"\"\"Verify the environment setup\"\"\"\n",
        "        print(f\"\\nüîç Verifying Environment Setup\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"üìã Platform: {self.current_platform}\")\n",
        "        print(f\"üìã Python Command: {self.python_cmd}\")\n",
        "        print(f\"üìã Pip Command: {self.pip_cmd}\")\n",
        "        print(f\"üìã Virtual Environment: {'Yes' if self.use_venv else 'No (Lightning AI)'}\")\n",
        "\n",
        "        # Verify Python executable exists\n",
        "        if self.use_venv and not os.path.exists(self.python_cmd):\n",
        "            print(f\"‚ùå Virtual environment Python not found: {self.python_cmd}\")\n",
        "            return False\n",
        "\n",
        "        # Test basic Python functionality\n",
        "        try:\n",
        "            result = subprocess.run([\n",
        "                self.python_cmd, '-c', 'import sys; print(f\"Python: {sys.version}\"); print(f\"Executable: {sys.executable}\")'\n",
        "            ], capture_output=True, text=True, timeout=15)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(\"‚úÖ Python Environment Verified:\")\n",
        "                for line in result.stdout.strip().split('\\n'):\n",
        "                    if line.strip():\n",
        "                        print(f\"   {line}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå Python verification failed: {result.stderr}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Python verification error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def verify_pytorch(self):\n",
        "        \"\"\"Verify PyTorch installation\"\"\"\n",
        "        print(f\"\\nüî• PyTorch Verification\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        pytorch_test = '''\n",
        "import torch\n",
        "import sys\n",
        "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"‚úÖ uint16 support: {hasattr(torch, 'uint16')}\")\n",
        "print(f\"‚úÖ uint32 support: {hasattr(torch, 'uint32')}\")\n",
        "print(f\"‚úÖ Python executable: {sys.executable}\")\n",
        "'''\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run([\n",
        "                self.python_cmd, '-c', pytorch_test\n",
        "            ], capture_output=True, text=True, timeout=30)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(\"üìã PyTorch Status:\")\n",
        "                for line in result.stdout.strip().split('\\n'):\n",
        "                    if line.strip():\n",
        "                        print(f\"   {line}\")\n",
        "\n",
        "                # Check for correct PyTorch version\n",
        "                if \"2.6.0\" in result.stdout:\n",
        "                    print(\"\\n‚úÖ Correct PyTorch version 2.6.0 detected\")\n",
        "                    return True\n",
        "                else:\n",
        "                    print(\"\\n‚ö†Ô∏è PyTorch version mismatch detected\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(f\"‚ùå PyTorch verification failed: {result.stderr}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå PyTorch verification error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def test_wan2gp_imports(self):\n",
        "        \"\"\"Test WAN2GP imports\"\"\"\n",
        "        print(f\"\\nüß™ Testing WAN2GP Imports\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        import_test = '''\n",
        "import os\n",
        "os.environ[\"MPLBACKEND\"] = \"Agg\"  # Set safe matplotlib backend\n",
        "\n",
        "try:\n",
        "    from mmgp import offload, safetensors2, profile_type\n",
        "    print(\"‚úÖ WAN2GP core modules imported successfully\")\n",
        "    print(\"‚úÖ mmgp.offload: Available\")\n",
        "    print(\"‚úÖ mmgp.safetensors2: Available\")\n",
        "    print(\"‚úÖ mmgp.profile_type: Available\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå WAN2GP import error: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "print(\"‚úÖ All WAN2GP imports successful - ready to launch\")\n",
        "'''\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run([\n",
        "                self.python_cmd, '-c', import_test\n",
        "            ], capture_output=True, text=True, timeout=60)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(\"üìã Import Test Results:\")\n",
        "                for line in result.stdout.strip().split('\\n'):\n",
        "                    if line.strip():\n",
        "                        print(f\"   {line}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå WAN2GP import test failed:\")\n",
        "                for line in result.stderr.strip().split('\\n'):\n",
        "                    if line.strip():\n",
        "                        print(f\"   {line}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Import test error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def launch_wan2gp(self):\n",
        "        \"\"\"Launch WAN2GP with platform-specific configuration\"\"\"\n",
        "        print(f\"\\nüöÄ Launching WAN2GP on {self.current_platform}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Platform-specific launch configuration\n",
        "        base_cmd = [self.python_cmd, \"wgp.py\"]\n",
        "\n",
        "        launch_args = [\n",
        "            \"--i2v\",\n",
        "            \"--port\", \"7860\",\n",
        "            \"--server-name\", \"127.0.0.1\",\n",
        "            \"--share\",\n",
        "            \"--attention\", \"sdpa\",  # Most compatible\n",
        "            \"--profile\", \"4\",       # Memory efficient\n",
        "            \"--verbose\", \"1\"\n",
        "        ]\n",
        "\n",
        "        # Platform-specific optimizations\n",
        "        if self.current_platform == \"Lightning AI\":\n",
        "            print(\"‚ö° Lightning AI configuration applied\")\n",
        "        elif self.current_platform == \"Google Colab\":\n",
        "            launch_args.extend([\"--lora-dir\", \"/content/Wan2GP/loras\"])\n",
        "            print(\"üì± Google Colab configuration applied\")\n",
        "\n",
        "        launch_cmd = base_cmd + launch_args\n",
        "\n",
        "        print(f\"üìã Launch Command: {' '.join(launch_cmd)}\")\n",
        "        print(f\"üîó Server Port: 7860\")\n",
        "        print(f\"üêç Python: {self.python_cmd}\")\n",
        "        print(f\"üìã Platform: {self.current_platform}\")\n",
        "\n",
        "        # Set environment for clean launch\n",
        "        launch_env = os.environ.copy()\n",
        "        launch_env[\"MPLBACKEND\"] = \"Agg\"\n",
        "\n",
        "        if self.current_platform == \"Google Colab\":\n",
        "            print(\"\\nüì± Google Colab Access Instructions:\")\n",
        "            print(\"   1. Look for 'Running on public URL: https://...' in output below\")\n",
        "            print(\"   2. Click the public URL to access WAN2GP interface\")\n",
        "        elif self.current_platform == \"Lightning AI\":\n",
        "            print(\"\\n‚ö° Lightning AI Access Instructions:\")\n",
        "            print(\"   1. Look for 'Running on local URL: http://...' in output below\")\n",
        "            print(\"   2. Use Lightning AI's port forwarding for external access\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"üîÑ Starting WAN2GP server...\")\n",
        "        print(\"üí° This may take 1-3 minutes for initial model loading\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        try:\n",
        "            self.process = subprocess.Popen(\n",
        "                launch_cmd,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.STDOUT,\n",
        "                universal_newlines=True,\n",
        "                bufsize=1,\n",
        "                cwd=os.getcwd(),\n",
        "                env=launch_env\n",
        "            )\n",
        "\n",
        "            startup_timeout = 180\n",
        "            start_time = time.time()\n",
        "\n",
        "            while True:\n",
        "                if self.process.poll() is not None:\n",
        "                    return_code = self.process.returncode\n",
        "                    if return_code != 0:\n",
        "                        print(f\"\\n‚ùå WAN2GP process exited with error code: {return_code}\")\n",
        "                        return False\n",
        "                    else:\n",
        "                        print(f\"\\n‚úÖ WAN2GP process completed successfully\")\n",
        "                        return True\n",
        "\n",
        "                elapsed = time.time() - start_time\n",
        "                if elapsed > startup_timeout:\n",
        "                    print(f\"\\n‚è∞ Startup timeout reached ({startup_timeout}s)\")\n",
        "                    return True\n",
        "\n",
        "                try:\n",
        "                    line = self.process.stdout.readline()\n",
        "                    if line:\n",
        "                        line = line.rstrip()\n",
        "                        print(line)\n",
        "\n",
        "                        if \"Running on public URL:\" in line or \"Running on local URL:\" in line:\n",
        "                            print(\"\\nüéâ WAN2GP server started successfully!\")\n",
        "                            print(\"üåê Use the URLs above to access the interface\")\n",
        "                            self.launch_success = True\n",
        "                            return True\n",
        "\n",
        "                        if \"CUDA out of memory\" in line:\n",
        "                            print(\"\\nüí• CUDA memory error - try smaller model\")\n",
        "                            return False\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Output reading error: {e}\")\n",
        "                    break\n",
        "\n",
        "                time.sleep(0.1)\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nüí• Launch failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def run_complete_launch(self):\n",
        "        \"\"\"Execute complete launch sequence\"\"\"\n",
        "        print(\"üîß WAN2GP Complete Launch Sequence\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Step 1: Environment verification\n",
        "        if not self.verify_environment():\n",
        "            print(\"\\nüí• Environment verification failed\")\n",
        "            return False\n",
        "\n",
        "        # Step 2: PyTorch verification\n",
        "        if not self.verify_pytorch():\n",
        "            print(\"\\nüí• PyTorch verification failed\")\n",
        "            return False\n",
        "\n",
        "        # Step 3: WAN2GP imports\n",
        "        if not self.test_wan2gp_imports():\n",
        "            print(\"\\nüí• WAN2GP import test failed\")\n",
        "            return False\n",
        "\n",
        "        # Step 4: Launch WAN2GP\n",
        "        launch_success = self.launch_wan2gp()\n",
        "\n",
        "        if launch_success:\n",
        "            print(f\"\\nüéØ WAN2GP Launch Complete!\")\n",
        "            print(\"=\" * 60)\n",
        "            print(\"‚úÖ Status: Successfully launched\")\n",
        "            print(f\"‚úÖ Platform: {self.current_platform}\")\n",
        "            print(f\"‚úÖ Environment: {'Virtual Environment' if self.use_venv else 'System (Lightning AI)'}\")\n",
        "            print(\"‚úÖ Server: Running on port 7860\")\n",
        "\n",
        "            if self.current_platform == \"Google Colab\":\n",
        "                print(\"\\nüì± Next Steps:\")\n",
        "                print(\"   ‚Ä¢ Click the public URL above to access WAN2GP\")\n",
        "                print(\"   ‚Ä¢ Start with Wan 2.1 T2V 1.3B model for testing\")\n",
        "            elif self.current_platform == \"Lightning AI\":\n",
        "                print(\"\\n‚ö° Next Steps:\")\n",
        "                print(\"   ‚Ä¢ Use Lightning AI port forwarding for external access\")\n",
        "                print(\"   ‚Ä¢ System environment used as required\")\n",
        "\n",
        "            return True\n",
        "        else:\n",
        "            print(\"\\nüí• WAN2GP launch failed\")\n",
        "            return False\n",
        "\n",
        "# Create launcher and display platform info\n",
        "launcher = CrossPlatformWAN2GPLauncher()\n",
        "\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; margin: 15px 0;\">\n",
        "    <h3 style=\"margin: 0 0 15px 0;\">üöÄ WAN2GP Cross-Platform Launcher</h3>\n",
        "    <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px;\">\n",
        "        <p style=\"margin: 0 0 10px 0;\"><strong>Platform:</strong> {launcher.current_platform}</p>\n",
        "        <p style=\"margin: 0 0 10px 0;\"><strong>Environment:</strong> {'Virtual Environment' if launcher.use_venv else 'System (Lightning AI compliant)'}</p>\n",
        "        <p style=\"margin: 0 0 10px 0;\"><strong>Python:</strong> {launcher.python_cmd}</p>\n",
        "        <p style=\"margin: 0;\"><strong>Configuration:</strong> Cross-platform optimized with automatic platform detection</p>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "# Execute launch sequence\n",
        "success = launcher.run_complete_launch()\n",
        "\n",
        "if success:\n",
        "    display(HTML(\"\"\"\n",
        "    <div style=\"background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
        "        <h4 style=\"margin: 0 0 10px 0;\">‚úÖ WAN2GP Successfully Launched!</h4>\n",
        "        <p style=\"margin: 0;\">The WAN2GP video generation interface is now running with proper cross-platform configuration.</p>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "else:\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"background-color: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
        "        <h4 style=\"margin: 0 0 10px 0;\">‚ö†Ô∏è Launch Failed</h4>\n",
        "        <p style=\"margin: 0 0 10px 0;\">Platform: {launcher.current_platform}</p>\n",
        "        <p style=\"margin: 0;\">Please check the error output above and try the emergency launch command:</p>\n",
        "        <code style=\"background: #f1f1f1; padding: 5px; border-radius: 3px; display: block; margin: 5px 0;\">\n",
        "        {launcher.python_cmd} wgp.py --attention sdpa --profile 4\n",
        "        </code>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "print(\"\\n‚ú® Cross-platform Cell 4 execution complete!\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GU-zDsAW_MwT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "de8fc8b3-9fe4-4039-a22c-5918165bc7ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; margin: 15px 0;\">\n",
              "    <h3 style=\"margin: 0 0 15px 0;\">üöÄ WAN2GP Cross-Platform Launcher</h3>\n",
              "    <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px;\">\n",
              "        <p style=\"margin: 0 0 10px 0;\"><strong>Platform:</strong> Google Colab</p>\n",
              "        <p style=\"margin: 0 0 10px 0;\"><strong>Environment:</strong> Virtual Environment</p>\n",
              "        <p style=\"margin: 0 0 10px 0;\"><strong>Python:</strong> .venv/bin/python</p>\n",
              "        <p style=\"margin: 0;\"><strong>Configuration:</strong> Cross-platform optimized with automatic platform detection</p>\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß WAN2GP Complete Launch Sequence\n",
            "============================================================\n",
            "\n",
            "üîç Verifying Environment Setup\n",
            "==================================================\n",
            "üìã Platform: Google Colab\n",
            "üìã Python Command: .venv/bin/python\n",
            "üìã Pip Command: .venv/bin/pip\n",
            "üìã Virtual Environment: Yes\n",
            "‚úÖ Python Environment Verified:\n",
            "   Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "   Executable: /content/Wan2GP/.venv/bin/python\n",
            "\n",
            "üî• PyTorch Verification\n",
            "------------------------------\n",
            "‚ùå PyTorch verification failed: Traceback (most recent call last):\n",
            "  File \"<string>\", line 2, in <module>\n",
            "ModuleNotFoundError: No module named 'torch'\n",
            "\n",
            "\n",
            "üí• PyTorch verification failed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
              "        <h4 style=\"margin: 0 0 10px 0;\">‚ö†Ô∏è Launch Failed</h4>\n",
              "        <p style=\"margin: 0 0 10px 0;\">Platform: Google Colab</p>\n",
              "        <p style=\"margin: 0;\">Please check the error output above and try the emergency launch command:</p>\n",
              "        <code style=\"background: #f1f1f1; padding: 5px; border-radius: 3px; display: block; margin: 5px 0;\">\n",
              "        .venv/bin/python wgp.py --attention sdpa --profile 4\n",
              "        </code>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® Cross-platform Cell 4 execution complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (1) - WAN2GP Comprehensive Diagnostic and Auto-Repair System (Latest v6.2 Compatible)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import importlib.util\n",
        "\n",
        "class WAN2GPDiagnosticAndRepair:\n",
        "    def __init__(self):\n",
        "        self.platform = self.detect_platform()\n",
        "        self.pip_cmd, self.python_cmd, self.use_venv = self.get_platform_commands()\n",
        "        self.issues_found = []\n",
        "        self.repairs_applied = []\n",
        "        self.gpu_info = {}\n",
        "\n",
        "    def detect_platform(self):\n",
        "        \"\"\"Enhanced platform detection with comprehensive indicators\"\"\"\n",
        "        # Lightning AI detection - multiple indicators for reliability\n",
        "        lightning_indicators = [\n",
        "            \"lightning\" in str(sys.executable).lower(),\n",
        "            \"teamspace-studios\" in os.getcwd(),\n",
        "            \"LIGHTNING_CLOUDSPACE_HOST\" in os.environ,\n",
        "            \"LIGHTNING_CLOUDSPACE_ID\" in os.environ,\n",
        "            \"/commands/python\" in str(sys.executable),\n",
        "            \"/home/zeus/miniconda3/envs/cloudspace\" in str(sys.executable),\n",
        "            os.path.exists(\"/teamspace\"),\n",
        "            os.path.exists(\"/commands\")\n",
        "        ]\n",
        "\n",
        "        # Google Colab detection\n",
        "        colab_indicators = [\n",
        "            \"google.colab\" in sys.modules,\n",
        "            \"/content\" in os.getcwd()\n",
        "        ]\n",
        "\n",
        "        # Vast.AI detection\n",
        "        vast_indicators = [\n",
        "            \"VAST_CONTAINER_LABEL\" in os.environ,\n",
        "            \"/workspace\" in os.getcwd(),\n",
        "            \"vast\" in os.environ.get(\"HOSTNAME\", \"\").lower()\n",
        "        ]\n",
        "\n",
        "        if any(lightning_indicators):\n",
        "            return \"Lightning AI\"\n",
        "        elif any(colab_indicators):\n",
        "            return \"Google Colab\"\n",
        "        elif any(vast_indicators):\n",
        "            return \"Vast.AI/Generic\"\n",
        "        else:\n",
        "            return \"Vast.AI/Generic\"\n",
        "\n",
        "    def get_platform_commands(self):\n",
        "        \"\"\"Get platform-specific pip and python commands\"\"\"\n",
        "        if self.platform == \"Lightning AI\":\n",
        "            return \"pip\", \"python\", False  # (pip_cmd, python_cmd, use_venv)\n",
        "        elif self.platform == \"Google Colab\":\n",
        "            return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "        else:  # Vast.AI/Generic\n",
        "            return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "    def run_command_safely(self, command, description, timeout=60):\n",
        "        \"\"\"Execute command with comprehensive error handling\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                command, capture_output=True, text=True, timeout=timeout, shell=isinstance(command, str)\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                return True, result.stdout\n",
        "            else:\n",
        "                return False, result.stderr\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, f\"Timeout after {timeout}s\"\n",
        "        except Exception as e:\n",
        "            return False, str(e)\n",
        "\n",
        "    def check_gpu_compatibility(self):\n",
        "        \"\"\"Comprehensive GPU detection and compatibility check\"\"\"\n",
        "        print(\"üîç Checking GPU compatibility...\")\n",
        "\n",
        "        # Check NVIDIA GPU presence\n",
        "        success, output = self.run_command_safely(\"nvidia-smi\", \"GPU Detection\")\n",
        "        if not success:\n",
        "            self.issues_found.append(\"No NVIDIA GPU detected or nvidia-smi not available\")\n",
        "            return False\n",
        "\n",
        "        # Parse GPU info\n",
        "        try:\n",
        "            # Extract GPU name and VRAM from nvidia-smi output\n",
        "            lines = output.split('\\n')\n",
        "            for line in lines:\n",
        "                if 'RTX' in line or 'GTX' in line or 'Tesla' in line or 'A100' in line:\n",
        "                    gpu_name = line.split('|')[1].strip() if '|' in line else \"Unknown GPU\"\n",
        "                    self.gpu_info['name'] = gpu_name\n",
        "                    break\n",
        "\n",
        "            # Check VRAM\n",
        "            for line in lines:\n",
        "                if 'MiB' in line and '/' in line:\n",
        "                    vram_info = [part for part in line.split() if 'MiB' in part]\n",
        "                    if len(vram_info) >= 2:\n",
        "                        total_vram = int(vram_info[-1].replace('MiB', ''))\n",
        "                        self.gpu_info['vram_mb'] = total_vram\n",
        "                        self.gpu_info['vram_gb'] = total_vram / 1024\n",
        "                        break\n",
        "\n",
        "            print(f\"‚úÖ GPU detected: {self.gpu_info.get('name', 'Unknown')}\")\n",
        "            print(f\"‚úÖ VRAM: {self.gpu_info.get('vram_gb', 0):.1f}GB\")\n",
        "\n",
        "            # Check VRAM adequacy\n",
        "            vram_gb = self.gpu_info.get('vram_gb', 0)\n",
        "            if vram_gb < 6:\n",
        "                self.issues_found.append(f\"Low VRAM detected ({vram_gb:.1f}GB). Minimum 6GB recommended.\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.issues_found.append(f\"GPU info parsing failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def check_cuda_pytorch_compatibility(self):\n",
        "        \"\"\"Check CUDA and PyTorch compatibility\"\"\"\n",
        "        print(\"üîç Checking CUDA and PyTorch compatibility...\")\n",
        "\n",
        "        # Check CUDA version\n",
        "        success, cuda_output = self.run_command_safely(\"nvcc --version\", \"CUDA Version Check\")\n",
        "        if not success:\n",
        "            success, cuda_output = self.run_command_safely(\"nvidia-smi\", \"CUDA Runtime Check\")\n",
        "\n",
        "        # Check PyTorch installation\n",
        "        try:\n",
        "            import torch\n",
        "            pytorch_version = torch.__version__\n",
        "            cuda_available = torch.cuda.is_available()\n",
        "\n",
        "            print(f\"‚úÖ PyTorch version: {pytorch_version}\")\n",
        "            print(f\"‚úÖ CUDA available in PyTorch: {cuda_available}\")\n",
        "\n",
        "            if not cuda_available:\n",
        "                self.issues_found.append(\"PyTorch cannot detect CUDA\")\n",
        "                return False\n",
        "\n",
        "            # Check for version compatibility\n",
        "            if \"50\" in self.gpu_info.get('name', '') and not pytorch_version.startswith('2.7'):\n",
        "                self.issues_found.append(\"RTX 50XX series requires PyTorch 2.7.0 or newer\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except ImportError:\n",
        "            self.issues_found.append(\"PyTorch not installed\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            self.issues_found.append(f\"PyTorch check failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def check_python_version(self):\n",
        "        \"\"\"Check Python version compatibility\"\"\"\n",
        "        print(\"üîç Checking Python version...\")\n",
        "\n",
        "        python_version = sys.version_info\n",
        "        version_string = f\"{python_version.major}.{python_version.minor}.{python_version.micro}\"\n",
        "        print(f\"‚úÖ Python version: {version_string}\")\n",
        "\n",
        "        if python_version.major != 3 or python_version.minor != 10:\n",
        "            self.issues_found.append(f\"Python {version_string} detected. Python 3.10.9 recommended for best compatibility.\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def check_wan2gp_installation(self):\n",
        "        \"\"\"Check WAN2GP installation and repository\"\"\"\n",
        "        print(\"üîç Checking WAN2GP installation...\")\n",
        "\n",
        "        wan2gp_paths = [\"Wan2GP\", \"wan2gp\", \"WAN2GP\", \"../Wan2GP\", \"../wan2gp\"]\n",
        "        wan2gp_found = False\n",
        "\n",
        "        for path in wan2gp_paths:\n",
        "            if os.path.exists(path):\n",
        "                wan2gp_found = True\n",
        "                wgp_py_path = os.path.join(path, \"wgp.py\")\n",
        "                if os.path.exists(wgp_py_path):\n",
        "                    print(f\"‚úÖ WAN2GP found at: {path}\")\n",
        "                    return True\n",
        "                break\n",
        "\n",
        "        if not wan2gp_found:\n",
        "            self.issues_found.append(\"WAN2GP repository not found\")\n",
        "            return False\n",
        "\n",
        "        self.issues_found.append(\"WAN2GP repository found but wgp.py missing\")\n",
        "        return False\n",
        "\n",
        "    def check_dependencies(self):\n",
        "        \"\"\"Check critical dependencies\"\"\"\n",
        "        print(\"üîç Checking critical dependencies...\")\n",
        "\n",
        "        critical_deps = {\n",
        "            'torch': 'PyTorch',\n",
        "            'torchvision': 'TorchVision',\n",
        "            'gradio': 'Gradio',\n",
        "            'transformers': 'Transformers',\n",
        "            'accelerate': 'Accelerate',\n",
        "            'diffusers': 'Diffusers'\n",
        "        }\n",
        "\n",
        "        missing_deps = []\n",
        "        for dep, name in critical_deps.items():\n",
        "            try:\n",
        "                importlib.import_module(dep)\n",
        "                print(f\"‚úÖ {name} installed\")\n",
        "            except ImportError:\n",
        "                missing_deps.append(dep)\n",
        "                print(f\"‚ùå {name} missing\")\n",
        "\n",
        "        if missing_deps:\n",
        "            self.issues_found.append(f\"Missing dependencies: {', '.join(missing_deps)}\")\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def check_attention_mechanisms(self):\n",
        "        \"\"\"Check available attention mechanisms\"\"\"\n",
        "        print(\"üîç Checking attention mechanisms...\")\n",
        "\n",
        "        attention_status = {}\n",
        "\n",
        "        # Check Triton\n",
        "        try:\n",
        "            import triton\n",
        "            attention_status['triton'] = f\"‚úÖ Triton {triton.__version__}\"\n",
        "        except ImportError:\n",
        "            attention_status['triton'] = \"‚ùå Triton not available\"\n",
        "\n",
        "        # Check SageAttention\n",
        "        try:\n",
        "            import sageattention\n",
        "            attention_status['sage'] = \"‚úÖ SageAttention available\"\n",
        "        except ImportError:\n",
        "            attention_status['sage'] = \"‚ùå SageAttention not available\"\n",
        "\n",
        "        # Check Flash Attention\n",
        "        try:\n",
        "            import flash_attn\n",
        "            attention_status['flash'] = \"‚úÖ Flash Attention available\"\n",
        "        except ImportError:\n",
        "            attention_status['flash'] = \"‚ùå Flash Attention not available\"\n",
        "\n",
        "        for mech, status in attention_status.items():\n",
        "            print(f\"  {status}\")\n",
        "\n",
        "        # Recommend fallback if advanced attention not available\n",
        "        if all(\"‚ùå\" in status for status in attention_status.values()):\n",
        "            self.issues_found.append(\"No advanced attention mechanisms available. Will use SDPA fallback.\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def check_memory_and_performance(self):\n",
        "        \"\"\"Check memory and performance configuration\"\"\"\n",
        "        print(\"üîç Checking memory and performance...\")\n",
        "\n",
        "        # Check available system RAM\n",
        "        try:\n",
        "            import psutil\n",
        "            ram_gb = psutil.virtual_memory().total / (1024**3)\n",
        "            print(f\"‚úÖ System RAM: {ram_gb:.1f}GB\")\n",
        "\n",
        "            if ram_gb < 16:\n",
        "                self.issues_found.append(f\"Low system RAM ({ram_gb:.1f}GB). 16GB+ recommended for best performance.\")\n",
        "        except ImportError:\n",
        "            print(\"‚ö†Ô∏è Cannot check system RAM (psutil not available)\")\n",
        "\n",
        "        # Check disk space\n",
        "        try:\n",
        "            disk_usage = shutil.disk_usage(os.getcwd())\n",
        "            free_gb = disk_usage.free / (1024**3)\n",
        "            print(f\"‚úÖ Free disk space: {free_gb:.1f}GB\")\n",
        "\n",
        "            if free_gb < 20:\n",
        "                self.issues_found.append(f\"Low disk space ({free_gb:.1f}GB). 20GB+ recommended.\")\n",
        "        except Exception:\n",
        "            print(\"‚ö†Ô∏è Cannot check disk space\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def auto_repair_pytorch(self):\n",
        "        \"\"\"Auto-repair PyTorch installation\"\"\"\n",
        "        print(\"üîß Attempting PyTorch repair...\")\n",
        "\n",
        "        # Determine correct PyTorch version based on GPU\n",
        "        if \"50\" in self.gpu_info.get('name', ''):\n",
        "            # RTX 50XX series\n",
        "            pytorch_cmd = [\n",
        "                self.pip_cmd, \"install\", \"--upgrade\",\n",
        "                \"torch==2.7.0\", \"torchvision\", \"torchaudio\",\n",
        "                \"--index-url\", \"https://download.pytorch.org/whl/test/cu128\"\n",
        "            ]\n",
        "        else:\n",
        "            # RTX 10XX-40XX series\n",
        "            pytorch_cmd = [\n",
        "                self.pip_cmd, \"install\", \"--upgrade\",\n",
        "                \"torch==2.6.0\", \"torchvision\", \"torchaudio\",\n",
        "                \"--index-url\", \"https://download.pytorch.org/whl/test/cu124\"\n",
        "            ]\n",
        "\n",
        "        success, output = self.run_command_safely(pytorch_cmd, \"PyTorch Installation\", timeout=300)\n",
        "        if success:\n",
        "            self.repairs_applied.append(\"PyTorch installation repaired\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå PyTorch repair failed: {output}\")\n",
        "            return False\n",
        "\n",
        "    def auto_repair_dependencies(self):\n",
        "        \"\"\"Auto-repair missing dependencies\"\"\"\n",
        "        print(\"üîß Installing missing dependencies...\")\n",
        "\n",
        "        # Install core requirements\n",
        "        requirements_cmd = [self.pip_cmd, \"install\", \"-r\", \"requirements.txt\"]\n",
        "        success, output = self.run_command_safely(requirements_cmd, \"Dependencies Installation\", timeout=300)\n",
        "\n",
        "        if success:\n",
        "            self.repairs_applied.append(\"Dependencies installed\")\n",
        "            return True\n",
        "        else:\n",
        "            # Fallback: install critical packages individually\n",
        "            critical_packages = [\n",
        "                \"gradio>=4.0.0\", \"transformers\", \"accelerate\", \"diffusers\",\n",
        "                \"opencv-python\", \"Pillow\", \"numpy\", \"scipy\"\n",
        "            ]\n",
        "\n",
        "            for package in critical_packages:\n",
        "                cmd = [self.pip_cmd, \"install\", package]\n",
        "                success, _ = self.run_command_safely(cmd, f\"Installing {package}\", timeout=60)\n",
        "                if success:\n",
        "                    print(f\"‚úÖ Installed {package}\")\n",
        "\n",
        "            self.repairs_applied.append(\"Critical dependencies installed individually\")\n",
        "            return True\n",
        "\n",
        "    def auto_repair_wan2gp_repo(self):\n",
        "        \"\"\"Auto-repair WAN2GP repository\"\"\"\n",
        "        print(\"üîß Cloning WAN2GP repository...\")\n",
        "\n",
        "        repo_url = \"https://github.com/deepbeepmeep/Wan2GP.git\"\n",
        "        clone_cmd = [\"git\", \"clone\", \"--depth\", \"1\", repo_url]\n",
        "\n",
        "        success, output = self.run_command_safely(clone_cmd, \"Repository Clone\", timeout=120)\n",
        "        if success:\n",
        "            self.repairs_applied.append(\"WAN2GP repository cloned\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå Repository clone failed: {output}\")\n",
        "            return False\n",
        "\n",
        "    def auto_repair_attention_mechanisms(self):\n",
        "        \"\"\"Auto-repair attention mechanisms\"\"\"\n",
        "        print(\"üîß Installing performance optimizations...\")\n",
        "\n",
        "        repairs = []\n",
        "\n",
        "        # Install Triton for Windows\n",
        "        if os.name == 'nt':  # Windows\n",
        "            triton_cmd = [self.pip_cmd, \"install\", \"triton-windows\"]\n",
        "            success, _ = self.run_command_safely(triton_cmd, \"Triton Installation\", timeout=120)\n",
        "            if success:\n",
        "                repairs.append(\"Triton (Windows)\")\n",
        "\n",
        "        # Install SageAttention\n",
        "        sage_cmd = [self.pip_cmd, \"install\", \"sageattention>=1.0.6\"]\n",
        "        success, _ = self.run_command_safely(sage_cmd, \"SageAttention Installation\", timeout=120)\n",
        "        if success:\n",
        "            repairs.append(\"SageAttention\")\n",
        "\n",
        "        if repairs:\n",
        "            self.repairs_applied.append(f\"Installed: {', '.join(repairs)}\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def generate_optimized_launch_commands(self):\n",
        "        \"\"\"Generate optimized launch commands based on hardware\"\"\"\n",
        "        print(\"\\nüöÄ Generating optimized launch commands...\")\n",
        "\n",
        "        vram_gb = self.gpu_info.get('vram_gb', 8)\n",
        "        gpu_name = self.gpu_info.get('name', 'Unknown')\n",
        "\n",
        "        commands = {}\n",
        "\n",
        "        # Base command components\n",
        "        base_cmd = \"python wgp.py\"\n",
        "\n",
        "        if vram_gb < 8:\n",
        "            # Low VRAM setup\n",
        "            commands['Low VRAM (6-8GB)'] = f\"{base_cmd} --t2v-1-3B --attention sdpa --profile 4 --teacache 1.5\"\n",
        "        elif vram_gb < 12:\n",
        "            # Medium VRAM setup\n",
        "            commands['Medium VRAM (8-12GB)'] = f\"{base_cmd} --t2v-14B --attention sage --profile 4 --teacache 2.0\"\n",
        "        else:\n",
        "            # High VRAM setup\n",
        "            commands['High VRAM (12GB+)'] = f\"{base_cmd} --t2v-14B --attention sage2 --profile 3 --compile --teacache 2.0\"\n",
        "\n",
        "        # GPU-specific optimizations\n",
        "        if \"10\" in gpu_name or \"20\" in gpu_name:\n",
        "            commands['RTX 10XX/20XX Optimized'] = f\"{base_cmd} --attention sdpa --profile 4 --teacache 1.5\"\n",
        "        elif \"30\" in gpu_name or \"40\" in gpu_name:\n",
        "            commands['RTX 30XX/40XX Optimized'] = f\"{base_cmd} --compile --attention sage --profile 3 --teacache 2.0\"\n",
        "        elif \"50\" in gpu_name:\n",
        "            commands['RTX 50XX Optimized'] = f\"{base_cmd} --attention sage --profile 4 --fp16\"\n",
        "\n",
        "        # Fallback command\n",
        "        commands['Safe Fallback'] = f\"{base_cmd} --t2v-1-3B --attention sdpa --profile 4 --teacache 0 --fp16\"\n",
        "\n",
        "        # Debug command\n",
        "        commands['Debug Mode'] = f\"{base_cmd} --verbose 2 --check-loras --attention sdpa --profile 4\"\n",
        "\n",
        "        return commands\n",
        "\n",
        "    def run_full_diagnostic(self):\n",
        "        \"\"\"Run complete diagnostic and repair sequence\"\"\"\n",
        "        print(\"üè• WAN2GP Comprehensive Diagnostic and Auto-Repair System\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"üñ•Ô∏è Platform: {self.platform}\")\n",
        "        print(f\"üêç Python: {self.python_cmd}\")\n",
        "        print(f\"üì¶ Pip: {self.pip_cmd}\")\n",
        "        print(f\"üîß Virtual Environment: {'Yes' if self.use_venv else 'No'}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Run all diagnostics\n",
        "        checks = [\n",
        "            self.check_python_version,\n",
        "            self.check_gpu_compatibility,\n",
        "            self.check_cuda_pytorch_compatibility,\n",
        "            self.check_wan2gp_installation,\n",
        "            self.check_dependencies,\n",
        "            self.check_attention_mechanisms,\n",
        "            self.check_memory_and_performance\n",
        "        ]\n",
        "\n",
        "        print(\"\\nüìã Running Diagnostics...\")\n",
        "        for check in checks:\n",
        "            try:\n",
        "                check()\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Diagnostic error: {str(e)}\")\n",
        "                self.issues_found.append(f\"Diagnostic error: {str(e)}\")\n",
        "\n",
        "        # Auto-repair if issues found\n",
        "        if self.issues_found:\n",
        "            print(f\"\\n‚ö†Ô∏è Found {len(self.issues_found)} issues:\")\n",
        "            for i, issue in enumerate(self.issues_found, 1):\n",
        "                print(f\"  {i}. {issue}\")\n",
        "\n",
        "            print(f\"\\nüîß Attempting automatic repairs...\")\n",
        "\n",
        "            # Apply repairs based on issues found\n",
        "            if any(\"PyTorch\" in issue for issue in self.issues_found):\n",
        "                self.auto_repair_pytorch()\n",
        "\n",
        "            if any(\"dependencies\" in issue.lower() for issue in self.issues_found):\n",
        "                self.auto_repair_dependencies()\n",
        "\n",
        "            if any(\"repository\" in issue.lower() for issue in self.issues_found):\n",
        "                self.auto_repair_wan2gp_repo()\n",
        "\n",
        "            if any(\"attention\" in issue.lower() for issue in self.issues_found):\n",
        "                self.auto_repair_attention_mechanisms()\n",
        "\n",
        "        # Generate launch commands\n",
        "        commands = self.generate_optimized_launch_commands()\n",
        "\n",
        "        # Final report\n",
        "        self.display_final_report(commands)\n",
        "\n",
        "    def display_final_report(self, commands):\n",
        "        \"\"\"Display comprehensive final report\"\"\"\n",
        "\n",
        "        # Create styled HTML report\n",
        "        html_report = f\"\"\"\n",
        "        <div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                    color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n",
        "            <h2>üè• WAN2GP Diagnostic Report</h2>\n",
        "            <div style=\"background-color: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "                <h3>üìä System Status</h3>\n",
        "                <p><strong>Platform:</strong> {self.platform}</p>\n",
        "                <p><strong>GPU:</strong> {self.gpu_info.get('name', 'Unknown')} ({self.gpu_info.get('vram_gb', 0):.1f}GB VRAM)</p>\n",
        "                <p><strong>Issues Found:</strong> {len(self.issues_found)}</p>\n",
        "                <p><strong>Repairs Applied:</strong> {len(self.repairs_applied)}</p>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        if self.repairs_applied:\n",
        "            html_report += f\"\"\"\n",
        "            <div style=\"background-color: #28a745; color: white; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "                <h3>‚úÖ Repairs Applied Successfully:</h3>\n",
        "                <ul>\n",
        "            \"\"\"\n",
        "            for repair in self.repairs_applied:\n",
        "                html_report += f\"<li>{repair}</li>\"\n",
        "            html_report += \"</ul></div>\"\n",
        "\n",
        "        if self.issues_found and not self.repairs_applied:\n",
        "            html_report += f\"\"\"\n",
        "            <div style=\"background-color: #dc3545; color: white; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "                <h3>‚ö†Ô∏è Unresolved Issues:</h3>\n",
        "                <ul>\n",
        "            \"\"\"\n",
        "            for issue in self.issues_found:\n",
        "                html_report += f\"<li>{issue}</li>\"\n",
        "            html_report += \"</ul></div>\"\n",
        "\n",
        "        display(HTML(html_report))\n",
        "\n",
        "        # Display optimized commands\n",
        "        print(\"\\nüöÄ Recommended Launch Commands:\")\n",
        "        print(\"=\" * 50)\n",
        "        for name, command in commands.items():\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  {command}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"‚úÖ Diagnostic complete! Use the appropriate command above to launch WAN2GP.\")\n",
        "        if self.issues_found and not self.repairs_applied:\n",
        "            print(\"‚ö†Ô∏è  Some issues require manual intervention. Check the report above.\")\n",
        "\n",
        "# Execute diagnostic system\n",
        "diagnostic_system = WAN2GPDiagnosticAndRepair()\n",
        "diagnostic_system.run_full_diagnostic()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZzJeUGqaCLJf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "050b281f-4310-4d5b-8b7d-a4f148c28d9e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üè• WAN2GP Comprehensive Diagnostic and Auto-Repair System\n",
            "============================================================\n",
            "üñ•Ô∏è Platform: Google Colab\n",
            "üêç Python: .venv/bin/python\n",
            "üì¶ Pip: .venv/bin/pip\n",
            "üîß Virtual Environment: Yes\n",
            "============================================================\n",
            "\n",
            "üìã Running Diagnostics...\n",
            "üîç Checking Python version...\n",
            "‚úÖ Python version: 3.11.13\n",
            "üîç Checking GPU compatibility...\n",
            "‚úÖ GPU detected: 0  Tesla T4                       Off\n",
            "‚úÖ VRAM: 15.0GB\n",
            "üîç Checking CUDA and PyTorch compatibility...\n",
            "‚úÖ PyTorch version: 2.6.0+cu124\n",
            "‚úÖ CUDA available in PyTorch: True\n",
            "üîç Checking WAN2GP installation...\n",
            "‚úÖ WAN2GP found at: ../Wan2GP\n",
            "üîç Checking critical dependencies...\n",
            "‚úÖ PyTorch installed\n",
            "‚úÖ TorchVision installed\n",
            "‚úÖ Gradio installed\n",
            "‚úÖ Transformers installed\n",
            "‚úÖ Accelerate installed\n",
            "‚úÖ Diffusers installed\n",
            "üîç Checking attention mechanisms...\n",
            "  ‚úÖ Triton 3.2.0\n",
            "  ‚ùå SageAttention not available\n",
            "  ‚ùå Flash Attention not available\n",
            "üîç Checking memory and performance...\n",
            "‚úÖ System RAM: 12.7GB\n",
            "‚úÖ Free disk space: 74.8GB\n",
            "\n",
            "‚ö†Ô∏è Found 2 issues:\n",
            "  1. Python 3.11.13 detected. Python 3.10.9 recommended for best compatibility.\n",
            "  2. Low system RAM (12.7GB). 16GB+ recommended for best performance.\n",
            "\n",
            "üîß Attempting automatic repairs...\n",
            "\n",
            "üöÄ Generating optimized launch commands...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
              "                    color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n",
              "            <h2>üè• WAN2GP Diagnostic Report</h2>\n",
              "            <div style=\"background-color: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
              "                <h3>üìä System Status</h3>\n",
              "                <p><strong>Platform:</strong> Google Colab</p>\n",
              "                <p><strong>GPU:</strong> 0  Tesla T4                       Off (15.0GB VRAM)</p>\n",
              "                <p><strong>Issues Found:</strong> 2</p>\n",
              "                <p><strong>Repairs Applied:</strong> 0</p>\n",
              "            </div>\n",
              "        </div>\n",
              "        \n",
              "            <div style=\"background-color: #dc3545; color: white; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
              "                <h3>‚ö†Ô∏è Unresolved Issues:</h3>\n",
              "                <ul>\n",
              "            <li>Python 3.11.13 detected. Python 3.10.9 recommended for best compatibility.</li><li>Low system RAM (12.7GB). 16GB+ recommended for best performance.</li></ul></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Recommended Launch Commands:\n",
            "==================================================\n",
            "\n",
            "High VRAM (12GB+):\n",
            "  python wgp.py --t2v-14B --attention sage2 --profile 3 --compile --teacache 2.0\n",
            "\n",
            "Safe Fallback:\n",
            "  python wgp.py --t2v-1-3B --attention sdpa --profile 4 --teacache 0 --fp16\n",
            "\n",
            "Debug Mode:\n",
            "  python wgp.py --verbose 2 --check-loras --attention sdpa --profile 4\n",
            "\n",
            "==================================================\n",
            "‚úÖ Diagnostic complete! Use the appropriate command above to launch WAN2GP.\n",
            "‚ö†Ô∏è  Some issues require manual intervention. Check the report above.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (2) - Quick Diagnostic Runner and Emergency Repair Tools (Latest v6.2)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "class QuickDiagnosticRunner:\n",
        "    def __init__(self):\n",
        "        self.platform = self.detect_platform()\n",
        "        self.pip_cmd, self.python_cmd = self.get_platform_commands()\n",
        "\n",
        "    def detect_platform(self):\n",
        "        \"\"\"Quick platform detection\"\"\"\n",
        "        if \"google.colab\" in sys.modules:\n",
        "            return \"Google Colab\"\n",
        "        elif any(indicator in str(sys.executable).lower() for indicator in [\"lightning\", \"teamspace\"]):\n",
        "            return \"Lightning AI\"\n",
        "        else:\n",
        "            return \"Generic/Vast.AI\"\n",
        "\n",
        "    def get_platform_commands(self):\n",
        "        \"\"\"Get platform-specific commands\"\"\"\n",
        "        if self.platform == \"Lightning AI\":\n",
        "            return \"pip\", \"python\"\n",
        "        else:\n",
        "            return \".venv/bin/pip\" if os.path.exists(\".venv\") else \"pip\", \".venv/bin/python\" if os.path.exists(\".venv\") else \"python\"\n",
        "\n",
        "    def run_cmd(self, cmd, timeout=30):\n",
        "        \"\"\"Execute command safely\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)\n",
        "            return result.returncode == 0, result.stdout, result.stderr\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, \"\", \"Timeout\"\n",
        "        except Exception as e:\n",
        "            return False, \"\", str(e)\n",
        "\n",
        "    def emergency_pytorch_fix(self):\n",
        "        \"\"\"Emergency PyTorch installation fix\"\"\"\n",
        "        print(\"üö® Emergency PyTorch Fix...\")\n",
        "\n",
        "        # Detect GPU generation for correct PyTorch version\n",
        "        success, gpu_info, _ = self.run_cmd(\"nvidia-smi\")\n",
        "\n",
        "        if \"RTX 50\" in gpu_info:\n",
        "            pytorch_url = \"https://download.pytorch.org/whl/test/cu128\"\n",
        "            torch_version = \"torch==2.7.0\"\n",
        "        else:\n",
        "            pytorch_url = \"https://download.pytorch.org/whl/test/cu124\"\n",
        "            torch_version = \"torch==2.6.0\"\n",
        "\n",
        "        cmd = f\"{self.pip_cmd} install --upgrade {torch_version} torchvision torchaudio --index-url {pytorch_url}\"\n",
        "        success, stdout, stderr = self.run_cmd(cmd, timeout=300)\n",
        "\n",
        "        if success:\n",
        "            print(\"‚úÖ PyTorch emergency fix applied\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå PyTorch fix failed: {stderr}\")\n",
        "            return False\n",
        "\n",
        "    def emergency_dependency_fix(self):\n",
        "        \"\"\"Emergency dependency installation\"\"\"\n",
        "        print(\"üö® Emergency Dependency Fix...\")\n",
        "\n",
        "        essential_packages = [\n",
        "            \"gradio>=4.0.0\", \"transformers\", \"accelerate\", \"diffusers\",\n",
        "            \"opencv-python\", \"Pillow\", \"numpy\", \"scipy\", \"psutil\"\n",
        "        ]\n",
        "\n",
        "        for package in essential_packages:\n",
        "            cmd = f\"{self.pip_cmd} install {package}\"\n",
        "            success, _, _ = self.run_cmd(cmd, timeout=60)\n",
        "            print(\"‚úÖ\" if success else \"‚ùå\", package)\n",
        "\n",
        "        print(\"‚úÖ Emergency dependencies installed\")\n",
        "\n",
        "    def quick_system_check(self):\n",
        "        \"\"\"Quick system health check\"\"\"\n",
        "        checks = {}\n",
        "\n",
        "        # GPU Check\n",
        "        success, output, _ = self.run_cmd(\"nvidia-smi\")\n",
        "        checks['GPU'] = \"‚úÖ Available\" if success and \"RTX\" in output else \"‚ùå Issue detected\"\n",
        "\n",
        "        # PyTorch Check\n",
        "        try:\n",
        "            import torch\n",
        "            checks['PyTorch'] = f\"‚úÖ {torch.__version__}\" if torch.cuda.is_available() else \"‚ùå CUDA not available\"\n",
        "        except ImportError:\n",
        "            checks['PyTorch'] = \"‚ùå Not installed\"\n",
        "\n",
        "        # WAN2GP Check\n",
        "        wan_exists = any(os.path.exists(path) for path in [\"Wan2GP/wgp.py\", \"wan2gp/wgp.py\", \"WAN2GP/wgp.py\"])\n",
        "        checks['WAN2GP'] = \"‚úÖ Found\" if wan_exists else \"‚ùå Missing\"\n",
        "\n",
        "        # Dependencies Check\n",
        "        try:\n",
        "            import gradio, transformers, accelerate, diffusers\n",
        "            checks['Dependencies'] = \"‚úÖ Core packages available\"\n",
        "        except ImportError:\n",
        "            checks['Dependencies'] = \"‚ùå Missing packages\"\n",
        "\n",
        "        return checks\n",
        "\n",
        "    def generate_emergency_commands(self):\n",
        "        \"\"\"Generate emergency launch commands\"\"\"\n",
        "        commands = {\n",
        "            \"Ultra Safe Mode\": f\"{self.python_cmd} wgp.py --t2v-1-3B --attention sdpa --profile 4 --teacache 0 --fp16\",\n",
        "            \"Memory Emergency\": f\"{self.python_cmd} wgp.py --t2v-1-3B --profile 5 --perc-reserved-mem-max 0.2\",\n",
        "            \"Debug Mode\": f\"{self.python_cmd} wgp.py --verbose 2 --attention sdpa --profile 4\",\n",
        "            \"Network Share\": f\"{self.python_cmd} wgp.py --listen --server-port 7861 --attention sdpa\"\n",
        "        }\n",
        "        return commands\n",
        "\n",
        "    def run_quick_diagnostic(self):\n",
        "        \"\"\"Run quick diagnostic and provide emergency options\"\"\"\n",
        "\n",
        "        print(f\"‚ö° Quick Diagnostic - Platform: {self.platform}\")\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "        # Quick system check\n",
        "        checks = self.quick_system_check()\n",
        "\n",
        "        issues = []\n",
        "        for component, status in checks.items():\n",
        "            print(f\"{component}: {status}\")\n",
        "            if \"‚ùå\" in status:\n",
        "                issues.append(component)\n",
        "\n",
        "        # Emergency repairs\n",
        "        if issues:\n",
        "            print(f\"\\nüö® {len(issues)} issues detected. Applying emergency fixes...\")\n",
        "\n",
        "            if \"PyTorch\" in issues:\n",
        "                self.emergency_pytorch_fix()\n",
        "\n",
        "            if \"Dependencies\" in issues:\n",
        "                self.emergency_dependency_fix()\n",
        "\n",
        "            if \"WAN2GP\" in issues:\n",
        "                print(\"üîß Cloning WAN2GP repository...\")\n",
        "                success, _, _ = self.run_cmd(\"git clone --depth 1 https://github.com/deepbeepmeep/Wan2GP.git\", timeout=120)\n",
        "                print(\"‚úÖ Repository cloned\" if success else \"‚ùå Clone failed\")\n",
        "\n",
        "        # Generate emergency commands\n",
        "        commands = self.generate_emergency_commands()\n",
        "\n",
        "        # Display results\n",
        "        html_display = f\"\"\"\n",
        "        <div style=\"background: linear-gradient(45deg, #ff6b6b, #feca57); color: white;\n",
        "                    padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "            <h3>‚ö° Quick Diagnostic Results</h3>\n",
        "            <p><strong>Platform:</strong> {self.platform}</p>\n",
        "            <p><strong>Issues Found:</strong> {len(issues)}</p>\n",
        "            <p><strong>Status:</strong> {'üö® Needs Attention' if issues else '‚úÖ System Ready'}</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(html_display))\n",
        "\n",
        "        print(\"\\nüöÄ Emergency Launch Commands:\")\n",
        "        print(\"-\" * 40)\n",
        "        for name, command in commands.items():\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  {command}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 40)\n",
        "        print(\"‚ö° Quick diagnostic complete!\")\n",
        "\n",
        "        if not issues:\n",
        "            print(\"‚úÖ System appears healthy. Try the Ultra Safe Mode command first.\")\n",
        "        else:\n",
        "            print(\"üö® Emergency fixes applied. Test with Ultra Safe Mode.\")\n",
        "\n",
        "# Execute quick diagnostic\n",
        "quick_runner = QuickDiagnosticRunner()\n",
        "quick_runner.run_quick_diagnostic()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0sx8G7LBCNyw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "f7e1b066-d820-4bd7-e523-1ce5c9ba7fcb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Quick Diagnostic - Platform: Google Colab\n",
            "========================================\n",
            "GPU: ‚ùå Issue detected\n",
            "PyTorch: ‚úÖ 2.6.0+cu124\n",
            "WAN2GP: ‚ùå Missing\n",
            "Dependencies: ‚úÖ Core packages available\n",
            "\n",
            "üö® 2 issues detected. Applying emergency fixes...\n",
            "üîß Cloning WAN2GP repository...\n",
            "‚úÖ Repository cloned\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"background: linear-gradient(45deg, #ff6b6b, #feca57); color: white;\n",
              "                    padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
              "            <h3>‚ö° Quick Diagnostic Results</h3>\n",
              "            <p><strong>Platform:</strong> Google Colab</p>\n",
              "            <p><strong>Issues Found:</strong> 2</p>\n",
              "            <p><strong>Status:</strong> üö® Needs Attention</p>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Emergency Launch Commands:\n",
            "----------------------------------------\n",
            "\n",
            "Ultra Safe Mode:\n",
            "  .venv/bin/python wgp.py --t2v-1-3B --attention sdpa --profile 4 --teacache 0 --fp16\n",
            "\n",
            "Memory Emergency:\n",
            "  .venv/bin/python wgp.py --t2v-1-3B --profile 5 --perc-reserved-mem-max 0.2\n",
            "\n",
            "Debug Mode:\n",
            "  .venv/bin/python wgp.py --verbose 2 --attention sdpa --profile 4\n",
            "\n",
            "Network Share:\n",
            "  .venv/bin/python wgp.py --listen --server-port 7861 --attention sdpa\n",
            "\n",
            "========================================\n",
            "‚ö° Quick diagnostic complete!\n",
            "üö® Emergency fixes applied. Test with Ultra Safe Mode.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0d4f1a0eed749e3b90d4615c6d5ce56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c973a012f3814a4d8ba009a158b608d0",
              "IPY_MODEL_bd23376cdd344017a4f892dc34cd5207",
              "IPY_MODEL_bf4662c2448c4ed18a819e7b9bc01e20"
            ],
            "layout": "IPY_MODEL_17727f9759d74b3f969e1c801229ca7d"
          }
        },
        "c973a012f3814a4d8ba009a158b608d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "HF Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_11c97b5235a24b21a479c44221636c16",
            "placeholder": "Enter your HuggingFace token here...",
            "style": "IPY_MODEL_34b377ce972745b8a6230da4f76fec76",
            "value": ""
          }
        },
        "bd23376cdd344017a4f892dc34cd5207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "üîê Authenticate",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_19b200f6d734471e94c510e672166565",
            "style": "IPY_MODEL_ba682407f14648e796fb11635b3b2e52",
            "tooltip": ""
          }
        },
        "bf4662c2448c4ed18a819e7b9bc01e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "danger",
            "description": "üö´ Clear Auth",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_52774508a33943e58705553dee14adda",
            "style": "IPY_MODEL_81d9f8e1415b4a72898bf9caa1757870",
            "tooltip": ""
          }
        },
        "17727f9759d74b3f969e1c801229ca7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c97b5235a24b21a479c44221636c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "400px"
          }
        },
        "34b377ce972745b8a6230da4f76fec76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "19b200f6d734471e94c510e672166565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba682407f14648e796fb11635b3b2e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "52774508a33943e58705553dee14adda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81d9f8e1415b4a72898bf9caa1757870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "efcf4c82a99b4d50bc1f655b20e92912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91a7a8040e94189bc7f3ab1823f865f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c9270e28e2a34096bef343a9626ed87c",
            "value": "<span style='color: #dc3545; font-weight: bold;'>üî¥ Not authenticated</span>"
          }
        },
        "b91a7a8040e94189bc7f3ab1823f865f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9270e28e2a34096bef343a9626ed87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "954107bc6f774536a0fc8dee4e7cc6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_606be75fe82e4451b758b4ed55531a23",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1512f08d8ff24637ac87f3f50f07b561",
            "value": "<br>"
          }
        },
        "606be75fe82e4451b758b4ed55531a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1512f08d8ff24637ac87f3f50f07b561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c4c93e35a394ad1b3dfe515ca57d768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_352b514653b44f79a9a9e74576512908",
              "IPY_MODEL_b88aa9ef9e5f446a8a5597fdd090d8cd",
              "IPY_MODEL_7bdf2d4625dc4be48a5edc8d7efcd2d7"
            ],
            "layout": "IPY_MODEL_4f59c028917145019508ffe33f6caa65"
          }
        },
        "352b514653b44f79a9a9e74576512908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "‚òëÔ∏è Select All LoRAs",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_33bc1b5985cd4b2492df363f4b0475d8",
            "style": "IPY_MODEL_a81f8a7e5ebd44b5964402c484ee7602",
            "tooltip": ""
          }
        },
        "b88aa9ef9e5f446a8a5597fdd090d8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "warning",
            "description": "‚òê Clear All Selections",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_bac99f5916c24e7d9fd707be1960c435",
            "style": "IPY_MODEL_803a0770938944cb80948db75838ef4e",
            "tooltip": ""
          }
        },
        "7bdf2d4625dc4be48a5edc8d7efcd2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "üì• Download Selected LoRAs",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_db4078f0c1ac4338a5fe5da1ad59d63b",
            "style": "IPY_MODEL_bdf2aaf3b8f4452a9b882f901bf1d4bd",
            "tooltip": ""
          }
        },
        "4f59c028917145019508ffe33f6caa65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bc1b5985cd4b2492df363f4b0475d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a81f8a7e5ebd44b5964402c484ee7602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "bac99f5916c24e7d9fd707be1960c435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803a0770938944cb80948db75838ef4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "db4078f0c1ac4338a5fe5da1ad59d63b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf2aaf3b8f4452a9b882f901bf1d4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2ab302be476245db8b46b9ec917b9bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "Progress:",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ae3f3c7068045df8d6b7625436465a6",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaa1e11fe84f494bb718c7b92b81262a",
            "value": 0
          }
        },
        "5ae3f3c7068045df8d6b7625436465a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa1e11fe84f494bb718c7b92b81262a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc68c29aadcf496f8cb48269d76ce00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328e0ccf73134ee890d8a386a83f5b35",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_efcf02e17249493f8705be717b9b417a",
            "value": "<div style=\"background: linear-gradient(90deg, #28a745, #20c997); color: white; padding: 12px 20px; border-radius: 8px; margin: 20px 0 10px 0; font-weight: bold; font-size: 16px;\">üìÇ ACCELERATION LoRAs</div>"
          }
        },
        "328e0ccf73134ee890d8a386a83f5b35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efcf02e17249493f8705be717b9b417a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "657f73988f6b464aac5f3b5f7d224d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Safe-Forcing lightx2v - 2-8 steps generation, 2x speed improvement (89MB)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a407691a8d414b0d9c51172daf8739f3",
            "style": "IPY_MODEL_acc923a14c91448b812b7edae1a1cd42",
            "value": false
          }
        },
        "a407691a8d414b0d9c51172daf8739f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "2px 0",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "700px"
          }
        },
        "acc923a14c91448b812b7edae1a1cd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "cd49eb2518ef4843bc80225065677e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "CausVid - 4-12 steps generation, 2x speed improvement (89MB)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a8dfc4c7637949128bab7e6d7ac800fa",
            "style": "IPY_MODEL_76ebe70230254e68a7475ac231191c51",
            "value": false
          }
        },
        "a8dfc4c7637949128bab7e6d7ac800fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "2px 0",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "700px"
          }
        },
        "76ebe70230254e68a7475ac231191c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "188ba320ab4047c995135f3ea44fc18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "AccVid T2V - 2x speed improvement, CFG=1 (44MB)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e030992eda8448b7b62a7194ad678b75",
            "style": "IPY_MODEL_e94dab324d584070b29986f63b687b46",
            "value": false
          }
        },
        "e030992eda8448b7b62a7194ad678b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "2px 0",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "700px"
          }
        },
        "e94dab324d584070b29986f63b687b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "94700edb2cc14b6d96701674d464a2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bb26c8182e42218c0b2f8cd80256d8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8efe086f5a2f485f9f14811d92c74aec",
            "value": "<div style=\"background: linear-gradient(90deg, #28a745, #20c997); color: white; padding: 12px 20px; border-radius: 8px; margin: 20px 0 10px 0; font-weight: bold; font-size: 16px;\">üìÇ IMAGE-TO-VIDEO LoRAs</div>"
          }
        },
        "c1bb26c8182e42218c0b2f8cd80256d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efe086f5a2f485f9f14811d92c74aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33e3879bc96c4df29150866ca73809ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "AccVid I2V - Image-to-video acceleration (44MB)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_983401f454a6432bb6328da304cfe6de",
            "style": "IPY_MODEL_e6fea0d1300f42158985baeecd8f310a",
            "value": false
          }
        },
        "983401f454a6432bb6328da304cfe6de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "2px 0",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "700px"
          }
        },
        "e6fea0d1300f42158985baeecd8f310a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "93ba6a86c9ef42d09ab9e5147a9b774d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f76c3ec5134d00a8f52cc47995c20a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a88037e664194958b1adca097fc4814d",
            "value": "<br>"
          }
        },
        "77f76c3ec5134d00a8f52cc47995c20a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88037e664194958b1adca097fc4814d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16b91894a4ad434fa1bd6829195a3ee6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_75054a1ab1c64bb5a1bf54ac9582afe9",
            "msg_id": "",
            "outputs": []
          }
        },
        "75054a1ab1c64bb5a1bf54ac9582afe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}