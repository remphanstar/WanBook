{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remphanstar/WanBook/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (1) WAN2GP Setup Introduction & Enhanced Platform Detection v4.0 (System Compliant)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "from IPython.display import display, HTML, Markdown\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if \"google.colab\" not in sys.modules:\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"WAN2GP Setup Introduction & Enhanced Platform Detection\")\n",
        "\n",
        "def detect_platform():\n",
        "    \"\"\"Enhanced platform detection with comprehensive indicators\"\"\"\n",
        "\n",
        "    # Lightning AI detection - multiple indicators for reliability\n",
        "    lightning_indicators = [\n",
        "        \"lightning\" in str(sys.executable).lower(),\n",
        "        \"teamspace-studios\" in os.getcwd(),\n",
        "        \"LIGHTNING_CLOUDSPACE_HOST\" in os.environ,\n",
        "        \"LIGHTNING_CLOUDSPACE_ID\" in os.environ,\n",
        "        \"commands/python\" in str(sys.executable),\n",
        "        \"/home/zeus/miniconda3/envs/cloudspace\" in str(sys.executable),\n",
        "        os.path.exists(\"/teamspace\"),\n",
        "        os.path.exists(\"/commands\")\n",
        "    ]\n",
        "\n",
        "    # Google Colab detection\n",
        "    colab_indicators = [\n",
        "        \"google.colab\" in sys.modules,\n",
        "        \"/content\" in os.getcwd()\n",
        "    ]\n",
        "\n",
        "    # Vast.AI detection\n",
        "    vast_indicators = [\n",
        "        \"VAST_CONTAINER_LABEL\" in os.environ,\n",
        "        \"/workspace\" in os.getcwd(),\n",
        "        \"vast\" in os.environ.get(\"HOSTNAME\", \"\").lower()\n",
        "    ]\n",
        "\n",
        "    if any(lightning_indicators):\n",
        "        return \"Lightning AI\"\n",
        "    elif any(colab_indicators):\n",
        "        return \"Google Colab\"\n",
        "    elif any(vast_indicators):\n",
        "        return \"Vast.AI/Generic\"\n",
        "    else:\n",
        "        return \"Vast.AI/Generic\"\n",
        "\n",
        "def get_platform_commands(platform):\n",
        "    \"\"\"Get platform-specific pip and python commands - ENFORCED VENV FOR COLAB\"\"\"\n",
        "    if platform == \"Lightning AI\":\n",
        "        return \"pip\", \"python\", False  # (pip_cmd, python_cmd, use_venv)\n",
        "    elif platform == \"Google Colab\":\n",
        "        # ENFORCED: Always use venv for Google Colab per system instructions\n",
        "        return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "    else:  # Vast.AI/Generic\n",
        "        return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "# Detect current platform\n",
        "current_platform = detect_platform()\n",
        "pip_cmd, python_cmd, use_venv = get_platform_commands(current_platform)\n",
        "\n",
        "# Display platform information\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "           color: white; padding: 20px; border-radius: 10px; text-align: center; margin: 10px 0;\n",
        "           box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "    <h1>üöÄ Wan2GP Full Setup Notebook</h1>\n",
        "    <p>A cross-platform Jupyter notebook (Colab, Lightning AI, Vast.ai) that installs Wan2GP,\n",
        "       common LoRA packs, and optional performance extras (FlashAttention 2, SageAttention, xFormers).\n",
        "       It accelerates all downloads with <strong>aria2c</strong> for maximum speed.</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 8px; border: 1px solid #dee2e6; margin: 15px 0;\">\n",
        "    <div style=\"background-color: #007bff; color: white; padding: 15px; border-radius: 5px; text-align: center; margin-bottom: 20px;\">\n",
        "        <h3 style=\"margin: 0; color: white;\">üéØ Platform Detection Results</h3>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Currently Running on: <strong style=\"color: #28a745; background-color: white; padding: 2px 6px; border-radius: 3px;\">{current_platform}</strong></p>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Virtual Environment: <strong>{\"Yes\" if use_venv else \"No (Lightning AI)\"}</strong></p>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Pip Command: <strong>{pip_cmd}</strong></p>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Python Command: <strong>{python_cmd}</strong></p>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "print(\"üìã Platform Detection Debug Info:\")\n",
        "print(f\"üîç - Detected Platform: {current_platform}\")\n",
        "print(f\"üêç - Python Executable: {sys.executable}\")\n",
        "print(f\"üìÅ - Current Working Directory: {os.getcwd()}\")\n",
        "print(f\"üåê - Google Colab Check: {'google.colab' in sys.modules}\")\n",
        "print(f\"‚ö° - Lightning Environment Variables: {[key for key in os.environ.keys() if 'LIGHTNING' in key]}\")\n",
        "print(f\"üîß - Virtual Environment Usage: {use_venv}\")\n",
        "print(f\"üì¶ - Pip Command: {pip_cmd}\")\n",
        "print(f\"üêç - Python Command: {python_cmd}\")\n",
        "\n",
        "# CRITICAL: Enforce venv for Google Colab per system instructions\n",
        "if current_platform == \"Google Colab\" and not use_venv:\n",
        "    print(\"üö® CRITICAL: Detected Google Colab but venv is disabled - FORCE ENABLING\")\n",
        "    use_venv = True\n",
        "    pip_cmd = \".venv/bin/pip\"\n",
        "    python_cmd = \".venv/bin/python\"\n",
        "    print(\"‚úÖ ENFORCED: Google Colab now using venv commands\")\n",
        "elif current_platform == \"Google Colab\":\n",
        "    print(\"‚úÖ CONFIRMED: Google Colab correctly configured for venv usage\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q7hLV1Oz-aBD",
        "outputId": "427df31c-75c5-448f-8b8b-a44b93189a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
              "           color: white; padding: 20px; border-radius: 10px; text-align: center; margin: 10px 0; \n",
              "           box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "    <h1>üöÄ Wan2GP Full Setup Notebook</h1>\n",
              "    <p>A cross-platform Jupyter notebook (Colab, Lightning AI, Vast.ai) that installs Wan2GP, \n",
              "       common LoRA packs, and optional performance extras (FlashAttention 2, SageAttention, xFormers). \n",
              "       It accelerates all downloads with <strong>aria2c</strong> for maximum speed.</p>\n",
              "</div>\n",
              "\n",
              "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 8px; border: 1px solid #dee2e6; margin: 15px 0;\">\n",
              "    <div style=\"background-color: #007bff; color: white; padding: 15px; border-radius: 5px; text-align: center; margin-bottom: 20px;\">\n",
              "        <h3 style=\"margin: 0; color: white;\">üéØ Platform Detection Results</h3>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Currently Running on: <strong style=\"color: #28a745; background-color: white; padding: 2px 6px; border-radius: 3px;\">Google Colab</strong></p>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Virtual Environment: <strong>Yes</strong></p>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Pip Command: <strong>.venv/bin/pip</strong></p>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Python Command: <strong>.venv/bin/python</strong></p>\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Platform Detection Debug Info:\n",
            "üîç - Detected Platform: Google Colab\n",
            "üêç - Python Executable: /usr/bin/python3\n",
            "üìÅ - Current Working Directory: /content\n",
            "üåê - Google Colab Check: True\n",
            "‚ö° - Lightning Environment Variables: []\n",
            "üîß - Virtual Environment Usage: True\n",
            "üì¶ - Pip Command: .venv/bin/pip\n",
            "üêç - Python Command: .venv/bin/python\n",
            "‚úÖ CONFIRMED: Google Colab correctly configured for venv usage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (2) Complete System + Python Environment Setup - Cross-Platform v4.0 (System Compliant)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if \"google.colab\" not in sys.modules:\n",
        "        from IPython.display import display, Markdown\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"Complete System + Python Environment Setup\")\n",
        "\n",
        "class CompleteEnvironmentSetup:\n",
        "    def __init__(self):\n",
        "        # Use global platform configuration from Cell 1\n",
        "        try:\n",
        "            self.current_platform = current_platform\n",
        "            self.pip_cmd = pip_cmd\n",
        "            self.python_cmd = python_cmd\n",
        "            self.use_venv = use_venv\n",
        "        except NameError:\n",
        "            print(\"‚ö†Ô∏è Platform detection variables not found. Using fallback detection.\")\n",
        "            self.detect_platform_fallback()\n",
        "\n",
        "        # CRITICAL ENFORCEMENT: Ensure venv for Google Colab per system instructions\n",
        "        self.enforce_colab_venv()\n",
        "\n",
        "        self.setup_phases = [\n",
        "            (\"System Packages\", self.install_system_packages),\n",
        "            (\"Directory Protection\", self.setup_directory_protection),\n",
        "            (\"Repository Clone\", self.clone_repository),\n",
        "            (\"Virtual Environment\", self.setup_virtual_environment),\n",
        "            (\"Matplotlib Fix\", self.fix_matplotlib_backend),\n",
        "            (\"PyTorch Installation\", self.install_pytorch),\n",
        "            (\"Requirements\", self.install_requirements),\n",
        "            (\"Environment Verification\", self.verify_complete_setup),\n",
        "        ]\n",
        "\n",
        "        self.current_phase = 0\n",
        "        self.total_phases = len(self.setup_phases)\n",
        "\n",
        "    def enforce_colab_venv(self):\n",
        "        \"\"\"CRITICAL: Enforce venv usage for Google Colab per system instructions\"\"\"\n",
        "        if hasattr(self, 'current_platform') and self.current_platform == \"Google Colab\":\n",
        "            if not hasattr(self, 'use_venv') or not self.use_venv or self.pip_cmd != \".venv/bin/pip\":\n",
        "                print(\"üö® ENFORCING: Google Colab MUST use venv per system instructions\")\n",
        "                self.use_venv = True\n",
        "                self.pip_cmd = \".venv/bin/pip\"\n",
        "                self.python_cmd = \".venv/bin/python\"\n",
        "                print(\"‚úÖ ENFORCED: System setup using venv commands\")\n",
        "            else:\n",
        "                print(\"‚úÖ VERIFIED: System setup correctly using venv for Colab\")\n",
        "\n",
        "    def detect_platform_fallback(self):\n",
        "        \"\"\"Fallback platform detection - ENFORCES VENV FOR COLAB\"\"\"\n",
        "        if \"google.colab\" in sys.modules:\n",
        "            self.current_platform = \"Google Colab\"\n",
        "            # ENFORCED: Always venv for Colab per system instructions\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "        elif any([\"lightning\" in str(sys.executable).lower(), \"teamspace\" in os.getcwd()]):\n",
        "            self.current_platform = \"Lightning AI\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \"pip\", \"python\", False\n",
        "        else:\n",
        "            self.current_platform = \"Generic\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "    def update_progress(self, phase_name, status=\"in_progress\"):\n",
        "        \"\"\"Update setup progress with visual indicators\"\"\"\n",
        "        progress_percent = (self.current_phase / self.total_phases) * 100\n",
        "        status_icons = {\n",
        "            \"in_progress\": \"üîÑ\",\n",
        "            \"success\": \"‚úÖ\",\n",
        "            \"failed\": \"‚ùå\"\n",
        "        }\n",
        "\n",
        "        print(f\"\\n[{self.current_phase + 1}/{self.total_phases}] {status_icons[status]} {phase_name}\")\n",
        "        print(f\"Progress: {progress_percent:.1f}% | Platform: {self.current_platform}\")\n",
        "        print(f\"üîß Using: {self.pip_cmd} | {self.python_cmd} | venv: {self.use_venv}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "    def run_command_safely(self, command, description, timeout=300):\n",
        "        \"\"\"Execute command with comprehensive error handling\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=timeout\n",
        "            )\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(f\"‚úÖ {description} completed successfully\")\n",
        "                return True, result.stdout\n",
        "            else:\n",
        "                print(f\"‚ùå {description} failed (exit code {result.returncode})\")\n",
        "                if result.stderr:\n",
        "                    # Check for specific ensurepip failure\n",
        "                    if \"ensurepip\" in result.stderr:\n",
        "                        print(f\"‚ö†Ô∏è ensurepip module failure detected\")\n",
        "                        return \"ensurepip_failure\", result.stderr\n",
        "                    print(f\"   Error: {result.stderr.strip()[:200]}\")\n",
        "                return False, result.stderr\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"‚è∞ {description} timed out after {timeout}s\")\n",
        "            return False, f\"Timeout after {timeout}s\"\n",
        "        except Exception as e:\n",
        "            print(f\"üí• {description} crashed: {e}\")\n",
        "            return False, str(e)\n",
        "\n",
        "    def install_system_packages(self):\n",
        "        \"\"\"Install system packages - same for all platforms\"\"\"\n",
        "        print(\"üîß Installing system packages...\")\n",
        "\n",
        "        if not shutil.which(\"apt-get\"):\n",
        "            print(\"üì¶ apt-get not found. Skipping system package installation.\")\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            print(\"üì¶ Updating package lists...\")\n",
        "            subprocess.run([\"sudo\", \"apt-get\", \"update\", \"-qq\"], check=True, timeout=60)\n",
        "\n",
        "            print(\"üîß Installing aria2, git, build-essential, and wget...\")\n",
        "            subprocess.run([\"sudo\", \"apt-get\", \"install\", \"-y\", \"aria2\", \"git\", \"build-essential\", \"wget\"], check=True, timeout=180)\n",
        "\n",
        "            print(\"‚úÖ System packages installed successfully\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚ùå System package installation failed: {e}\")\n",
        "            return False\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"‚è∞ System package installation timed out\")\n",
        "            return False\n",
        "\n",
        "    def setup_directory_protection(self):\n",
        "        \"\"\"Critical directory protection to prevent recursive cloning\"\"\"\n",
        "        print(\"üõ°Ô∏è Setting up directory protection...\")\n",
        "\n",
        "        current_dir = os.getcwd()\n",
        "        print(f\"üìç Current directory: {current_dir}\")\n",
        "\n",
        "        # Check if we're already inside a Wan2GP directory\n",
        "        if \"Wan2GP\" in current_dir:\n",
        "            print(\"‚ö†Ô∏è Already inside Wan2GP directory - navigating to safe location\")\n",
        "\n",
        "            # Navigate to content root (Colab) or appropriate base directory\n",
        "            if self.current_platform == \"Google Colab\":\n",
        "                safe_dir = \"/content\"\n",
        "            elif self.current_platform == \"Lightning AI\":\n",
        "                safe_dir = os.path.expanduser(\"~\")\n",
        "            else:\n",
        "                safe_dir = os.path.expanduser(\"~\")\n",
        "\n",
        "            try:\n",
        "                os.chdir(safe_dir)\n",
        "                print(f\"üìÅ Moved to safe directory: {os.getcwd()}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to navigate to safe directory: {e}\")\n",
        "                return False\n",
        "\n",
        "        # Check for existing Wan2GP directory and handle it\n",
        "        repo_path = os.path.join(os.getcwd(), \"Wan2GP\")\n",
        "        if os.path.exists(repo_path):\n",
        "            print(f\"üìÅ Found existing Wan2GP directory at: {repo_path}\")\n",
        "\n",
        "            # Check if it looks like a valid repository\n",
        "            if os.path.exists(os.path.join(repo_path, \".git\")):\n",
        "                print(\"‚úÖ Existing directory appears to be a valid git repository\")\n",
        "                # Check if it's the correct repository\n",
        "                try:\n",
        "                    os.chdir(repo_path)\n",
        "                    result = subprocess.run([\"git\", \"remote\", \"get-url\", \"origin\"],\n",
        "                                          capture_output=True, text=True, timeout=10)\n",
        "                    if result.returncode == 0 and \"Wan2GP\" in result.stdout:\n",
        "                        print(\"‚úÖ Existing repository is correct - using it\")\n",
        "                        return True\n",
        "                    else:\n",
        "                        print(\"‚ö†Ô∏è Existing repository is not the correct one\")\n",
        "                        os.chdir(\"..\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Could not verify existing repository: {e}\")\n",
        "                    os.chdir(\"..\")\n",
        "\n",
        "            # If we reach here, remove the problematic directory\n",
        "            print(\"üóëÔ∏è Removing problematic existing directory...\")\n",
        "            try:\n",
        "                shutil.rmtree(repo_path)\n",
        "                print(\"‚úÖ Problematic directory removed\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to remove existing directory: {e}\")\n",
        "                # Try to rename it instead\n",
        "                try:\n",
        "                    backup_name = f\"Wan2GP_backup_{int(time.time())}\"\n",
        "                    os.rename(repo_path, backup_name)\n",
        "                    print(f\"‚úÖ Renamed problematic directory to {backup_name}\")\n",
        "                except Exception as e2:\n",
        "                    print(f\"‚ùå Could not even rename directory: {e2}\")\n",
        "                    return False\n",
        "\n",
        "        print(\"‚úÖ Directory protection setup complete\")\n",
        "        return True\n",
        "\n",
        "    def clone_repository(self):\n",
        "        \"\"\"Clone WAN2GP repository with enhanced protection\"\"\"\n",
        "        REPO_DIR = \"Wan2GP\"\n",
        "        REPO_URL = \"https://github.com/deepbeepmeep/Wan2GP.git\"\n",
        "\n",
        "        print(\"üìÇ Setting up WAN2GP repository...\")\n",
        "        print(f\"üìç Working from: {os.getcwd()}\")\n",
        "\n",
        "        # Final check - ensure we're not in a nested situation\n",
        "        current_path = os.getcwd()\n",
        "        if current_path.count(\"Wan2GP\") > 0:\n",
        "            print(\"üö® CRITICAL: Still in Wan2GP directory path!\")\n",
        "            print(\"üîÑ Attempting emergency navigation...\")\n",
        "\n",
        "            # Emergency navigation\n",
        "            if self.current_platform == \"Google Colab\":\n",
        "                emergency_path = \"/content\"\n",
        "            else:\n",
        "                emergency_path = os.path.expanduser(\"~\")\n",
        "\n",
        "            try:\n",
        "                os.chdir(emergency_path)\n",
        "                print(f\"üÜò Emergency navigation successful: {os.getcwd()}\")\n",
        "            except Exception as e:\n",
        "                print(f\"üí• Emergency navigation failed: {e}\")\n",
        "                return False\n",
        "\n",
        "        if not os.path.exists(REPO_DIR):\n",
        "            print(f\"üì• Cloning repository from {REPO_URL}...\")\n",
        "            try:\n",
        "                subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL], check=True, timeout=120)\n",
        "                print(\"‚úÖ Repository cloned successfully\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"‚ùå Failed to clone repository: {e}\")\n",
        "                return False\n",
        "            except subprocess.TimeoutExpired:\n",
        "                print(\"‚è∞ Repository clone timed out\")\n",
        "                return False\n",
        "        else:\n",
        "            print(f\"üìÅ Directory {REPO_DIR} already exists\")\n",
        "\n",
        "        try:\n",
        "            os.chdir(REPO_DIR)\n",
        "            final_path = os.getcwd()\n",
        "            print(f\"üìÅ Changed to directory: {final_path}\")\n",
        "\n",
        "            # Verify we're in the right place\n",
        "            if final_path.count(\"Wan2GP\") > 1:\n",
        "                print(\"üö® WARNING: Detected nested Wan2GP directories!\")\n",
        "                print(f\"üîç Current path: {final_path}\")\n",
        "                return False\n",
        "\n",
        "            print(\"‚úÖ Repository setup verified\")\n",
        "            return True\n",
        "        except FileNotFoundError:\n",
        "            print(f\"‚ùå Directory {REPO_DIR} not found\")\n",
        "            return False\n",
        "\n",
        "    def setup_venv_manual_pip(self):\n",
        "        \"\"\"Create venv without pip, then install pip manually\"\"\"\n",
        "        try:\n",
        "            print(\"üîß Creating venv without pip...\")\n",
        "            subprocess.run([sys.executable, \"-m\", \"venv\", \".venv\", \"--without-pip\"],\n",
        "                          check=True, timeout=60)\n",
        "\n",
        "            print(\"üì• Downloading get-pip.py...\")\n",
        "            subprocess.run([\"wget\", \"https://bootstrap.pypa.io/get-pip.py\"], check=True)\n",
        "\n",
        "            print(\"üîß Installing pip manually...\")\n",
        "            subprocess.run([\".venv/bin/python\", \"get-pip.py\"], check=True)\n",
        "\n",
        "            print(\"‚úÖ Virtual environment with manual pip created successfully\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Manual pip installation failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def setup_virtual_environment(self):\n",
        "        \"\"\"Create virtual environment - ENFORCED for Google Colab\"\"\"\n",
        "        if not self.use_venv:\n",
        "            print(\"‚ö° Lightning AI detected - using system environment (no venv)\")\n",
        "            return True\n",
        "\n",
        "        print(\"üêç Setting up virtual environment...\")\n",
        "        print(f\"üîß Platform: {self.current_platform} - venv REQUIRED per system instructions\")\n",
        "\n",
        "        # Check if venv already exists\n",
        "        if os.path.exists(\".venv/bin/python\"):\n",
        "            print(\"‚úÖ Virtual environment already exists and appears functional\")\n",
        "            return True\n",
        "\n",
        "        print(\"üî® Creating virtual environment...\")\n",
        "\n",
        "        # Try multiple methods for virtual environment creation\n",
        "        venv_methods = [\n",
        "            ([sys.executable, \"-m\", \"venv\", \"--system-site-packages\", \".venv\"], \"venv with system packages\"),\n",
        "            ([sys.executable, \"-m\", \"venv\", \".venv\"], \"standard venv\"),\n",
        "            ([sys.executable, \"-m\", \"virtualenv\", \".venv\"], \"virtualenv package\"),\n",
        "        ]\n",
        "\n",
        "        for command, method_name in venv_methods:\n",
        "            print(f\"üîÑ Trying: {method_name}\")\n",
        "            success, error_msg = self.run_command_safely(command, f\"Virtual environment creation ({method_name})\", timeout=60)\n",
        "\n",
        "            if success == True:\n",
        "                print(\"‚úÖ Virtual environment created successfully\")\n",
        "                return True\n",
        "            elif success == \"ensurepip_failure\":\n",
        "                print(\"‚ö†Ô∏è ensurepip failure detected - trying manual pip installation...\")\n",
        "                if self.setup_venv_manual_pip():\n",
        "                    return True\n",
        "                break  # Don't try other methods if ensurepip failed\n",
        "            else:\n",
        "                print(f\"‚ùå {method_name} failed\")\n",
        "                if error_msg:\n",
        "                    print(f\"   Error: {error_msg[:200]}\")\n",
        "                continue\n",
        "\n",
        "        # Final fallback ONLY for non-Colab platforms per system instructions\n",
        "        if self.current_platform != \"Google Colab\":\n",
        "            print(\"üîÑ All virtual environment methods failed - switching to system installation\")\n",
        "            print(\"‚ö° Overriding to system-wide installation\")\n",
        "            self.use_venv = False\n",
        "            self.pip_cmd = \"pip\"\n",
        "            self.python_cmd = \"python\"\n",
        "            return True\n",
        "        else:\n",
        "            print(\"üö® CRITICAL: Google Colab REQUIRES venv per system instructions - cannot fallback\")\n",
        "            return False\n",
        "\n",
        "    def fix_matplotlib_backend(self):\n",
        "        \"\"\"Fix matplotlib backend issue for Colab environment\"\"\"\n",
        "        print(\"üé® Fixing matplotlib backend compatibility...\")\n",
        "\n",
        "        try:\n",
        "            # Create matplotlib configuration fix\n",
        "            matplotlib_fix_script = \"\"\"\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# Fix matplotlib backend for Colab/Jupyter environments\n",
        "# This prevents the 'module://matplotlib_inline.backend_inline' error\n",
        "def fix_matplotlib_backend():\n",
        "    # Override problematic MPLBACKEND environment variable\n",
        "    if 'MPLBACKEND' in os.environ:\n",
        "        old_backend = os.environ['MPLBACKEND']\n",
        "        if 'inline' in old_backend or 'module://' in old_backend:\n",
        "            # Set to a safe backend for headless environments\n",
        "            os.environ['MPLBACKEND'] = 'Agg'\n",
        "            print(f\"üîß Fixed matplotlib backend: {old_backend} -> Agg\")\n",
        "\n",
        "    # Ensure matplotlib uses safe backend before any imports\n",
        "    try:\n",
        "        import matplotlib\n",
        "        matplotlib.use('Agg', force=True)\n",
        "        print(\"‚úÖ Matplotlib backend set to 'Agg' (headless mode)\")\n",
        "    except ImportError:\n",
        "        print(\"‚ö†Ô∏è Matplotlib not yet installed - will be fixed after requirements\")\n",
        "\n",
        "    return True\n",
        "\n",
        "# Apply the fix\n",
        "fix_matplotlib_backend()\n",
        "\"\"\"\n",
        "\n",
        "            # Write the fix to a file that can be imported\n",
        "            fix_file_path = \"matplotlib_backend_fix.py\"\n",
        "            with open(fix_file_path, 'w') as f:\n",
        "                f.write(matplotlib_fix_script)\n",
        "\n",
        "            # Execute the fix\n",
        "            success, _ = self.run_command_safely([self.python_cmd, fix_file_path],\n",
        "                                               \"Matplotlib backend fix\", timeout=30)\n",
        "\n",
        "            if success:\n",
        "                print(\"‚úÖ Matplotlib backend fix applied successfully\")\n",
        "                return True\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Matplotlib backend fix execution failed, continuing anyway\")\n",
        "                return True  # Non-critical failure\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Matplotlib backend fix failed: {e}\")\n",
        "            print(\"üîÑ Continuing setup - will be resolved during runtime\")\n",
        "            return True  # Non-critical failure\n",
        "\n",
        "    def install_pytorch(self):\n",
        "        \"\"\"Install PyTorch using enforced venv commands\"\"\"\n",
        "        print(\"üî• Installing PyTorch...\")\n",
        "        print(f\"üîß Using pip command: {self.pip_cmd}\")\n",
        "\n",
        "        # Use CUDA 12.4 for RTX 10XX-40XX as per documentation[6]\n",
        "        pytorch_cmd = [\n",
        "            self.pip_cmd, \"install\",\n",
        "            \"torch==2.6.0\", \"torchvision\", \"torchaudio\",\n",
        "            \"--index-url\", \"https://download.pytorch.org/whl/test/cu124\"\n",
        "        ]\n",
        "\n",
        "        success, _ = self.run_command_safely(pytorch_cmd, \"PyTorch installation\", timeout=300)\n",
        "        return success == True\n",
        "\n",
        "    def install_requirements(self):\n",
        "        \"\"\"Install requirements.txt using enforced venv commands\"\"\"\n",
        "        print(\"üì¶ Installing requirements...\")\n",
        "        print(f\"üîß Using pip command: {self.pip_cmd}\")\n",
        "\n",
        "        if not os.path.exists(\"requirements.txt\"):\n",
        "            print(\"‚ö†Ô∏è requirements.txt not found, skipping\")\n",
        "            return True\n",
        "\n",
        "        req_cmd = [self.pip_cmd, \"install\", \"-r\", \"requirements.txt\"]\n",
        "        success, _ = self.run_command_safely(req_cmd, \"Requirements installation\", timeout=300)\n",
        "        return success == True\n",
        "\n",
        "    def verify_complete_setup(self):\n",
        "        \"\"\"Verify the complete installation using enforced venv commands\"\"\"\n",
        "        print(\"üîç Verifying installation...\")\n",
        "        print(f\"üîß Using python command: {self.python_cmd}\")\n",
        "\n",
        "        # Verify directory structure\n",
        "        current_dir = os.getcwd()\n",
        "        print(f\"üìç Final directory: {current_dir}\")\n",
        "\n",
        "        if current_dir.count(\"Wan2GP\") > 1:\n",
        "            print(\"üö® CRITICAL: Nested directory structure detected!\")\n",
        "            print(\"‚ùå Setup verification failed due to directory structure\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # Test PyTorch installation\n",
        "            result = subprocess.run([self.python_cmd, \"-c\", \"import torch; print(f'PyTorch {torch.__version__} installed'); print(f'CUDA available: {torch.cuda.is_available()}')\"],\n",
        "                                  capture_output=True, text=True, timeout=30)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(\"‚úÖ PyTorch verification successful:\")\n",
        "                for line in result.stdout.strip().split('\\n'):\n",
        "                    print(f\"   {line}\")\n",
        "\n",
        "                # Verify main WanGP file exists\n",
        "                if os.path.exists(\"wgp.py\"):\n",
        "                    print(\"‚úÖ WanGP main file found\")\n",
        "                else:\n",
        "                    print(\"‚ö†Ô∏è WanGP main file (wgp.py) not found\")\n",
        "\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå PyTorch verification failed: {result.stderr}\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Verification failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def run_complete_setup(self):\n",
        "        \"\"\"Execute the complete setup process with enforced venv\"\"\"\n",
        "        print(\"üöÄ WAN2GP Complete System + Python Environment Setup\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Platform: {self.current_platform}\")\n",
        "        print(f\"Virtual Environment: {'Yes' if self.use_venv else 'No'}\")\n",
        "        print(f\"Pip Command: {self.pip_cmd}\")\n",
        "        print(f\"Python Command: {self.python_cmd}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Final enforcement check per system instructions\n",
        "        if hasattr(self, 'current_platform') and self.current_platform == \"Google Colab\" and not self.use_venv:\n",
        "            print(\"üö® FATAL: Google Colab not using venv per system instructions - ABORTING\")\n",
        "            return False\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for phase_name, phase_func in self.setup_phases:\n",
        "            self.update_progress(phase_name, \"in_progress\")\n",
        "\n",
        "            phase_start = time.time()\n",
        "            success = phase_func()\n",
        "            phase_duration = time.time() - phase_start\n",
        "\n",
        "            if success:\n",
        "                self.update_progress(phase_name, \"success\")\n",
        "                print(f\"‚è±Ô∏è {phase_name} completed in {phase_duration:.1f}s\")\n",
        "                self.current_phase += 1\n",
        "            else:\n",
        "                self.update_progress(phase_name, \"failed\")\n",
        "                print(f\"üí• Setup failed at: {phase_name}\")\n",
        "                print(\"\\nüîÑ Setup Issues - Platform-Specific Troubleshooting:\")\n",
        "                print(\"üì± Colab: Restart runtime and re-run all cells\")\n",
        "                print(\"‚ö° Lightning.AI: Ensure you're using the correct Python version\")\n",
        "                print(\"üåå Vast.AI: Check GPU drivers and CUDA installation\")\n",
        "                return False\n",
        "\n",
        "        total_duration = time.time() - start_time\n",
        "        print(f\"\\nüéâ WAN2GP setup completed successfully in {total_duration:.1f}s!\")\n",
        "        print(\"üöÄ Ready to launch WAN2GP!\")\n",
        "        return True\n",
        "\n",
        "# Execute the complete setup\n",
        "setup = CompleteEnvironmentSetup()\n",
        "setup.run_complete_setup()\n"
      ],
      "metadata": {
        "id": "Wc1mj9zi_ExM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e844ccaf-2abc-45a1-9e2b-0bc7b50b1d61",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ VERIFIED: System setup correctly using venv for Colab\n",
            "üöÄ WAN2GP Complete System + Python Environment Setup\n",
            "======================================================================\n",
            "Platform: Google Colab\n",
            "Virtual Environment: Yes\n",
            "Pip Command: .venv/bin/pip\n",
            "Python Command: .venv/bin/python\n",
            "======================================================================\n",
            "\n",
            "[1/8] üîÑ System Packages\n",
            "Progress: 0.0% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "üîß Installing system packages...\n",
            "üì¶ Updating package lists...\n",
            "üîß Installing aria2, git, build-essential, and wget...\n",
            "‚úÖ System packages installed successfully\n",
            "\n",
            "[1/8] ‚úÖ System Packages\n",
            "Progress: 0.0% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "‚è±Ô∏è System Packages completed in 11.2s\n",
            "\n",
            "[2/8] üîÑ Directory Protection\n",
            "Progress: 12.5% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "üõ°Ô∏è Setting up directory protection...\n",
            "üìç Current directory: /content\n",
            "üìÅ Found existing Wan2GP directory at: /content/Wan2GP\n",
            "‚úÖ Existing directory appears to be a valid git repository\n",
            "‚úÖ Existing repository is correct - using it\n",
            "\n",
            "[2/8] ‚úÖ Directory Protection\n",
            "Progress: 12.5% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "‚è±Ô∏è Directory Protection completed in 0.1s\n",
            "\n",
            "[3/8] üîÑ Repository Clone\n",
            "Progress: 25.0% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "üìÇ Setting up WAN2GP repository...\n",
            "üìç Working from: /content/Wan2GP\n",
            "üö® CRITICAL: Still in Wan2GP directory path!\n",
            "üîÑ Attempting emergency navigation...\n",
            "üÜò Emergency navigation successful: /content\n",
            "üìÅ Directory Wan2GP already exists\n",
            "üìÅ Changed to directory: /content/Wan2GP\n",
            "‚úÖ Repository setup verified\n",
            "\n",
            "[3/8] ‚úÖ Repository Clone\n",
            "Progress: 25.0% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "‚è±Ô∏è Repository Clone completed in 0.0s\n",
            "\n",
            "[4/8] üîÑ Virtual Environment\n",
            "Progress: 37.5% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "üêç Setting up virtual environment...\n",
            "üîß Platform: Google Colab - venv REQUIRED per system instructions\n",
            "‚úÖ Virtual environment already exists and appears functional\n",
            "\n",
            "[4/8] ‚úÖ Virtual Environment\n",
            "Progress: 37.5% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "‚è±Ô∏è Virtual Environment completed in 0.0s\n",
            "\n",
            "[5/8] üîÑ Matplotlib Fix\n",
            "Progress: 50.0% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "üé® Fixing matplotlib backend compatibility...\n",
            "‚úÖ Matplotlib backend fix completed successfully\n",
            "‚úÖ Matplotlib backend fix applied successfully\n",
            "\n",
            "[5/8] ‚úÖ Matplotlib Fix\n",
            "Progress: 50.0% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "‚è±Ô∏è Matplotlib Fix completed in 1.0s\n",
            "\n",
            "[6/8] üîÑ PyTorch Installation\n",
            "Progress: 62.5% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "üî• Installing PyTorch...\n",
            "üîß Using pip command: .venv/bin/pip\n",
            "‚úÖ PyTorch installation completed successfully\n",
            "\n",
            "[6/8] ‚úÖ PyTorch Installation\n",
            "Progress: 62.5% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "‚è±Ô∏è PyTorch Installation completed in 3.2s\n",
            "\n",
            "[7/8] üîÑ Requirements\n",
            "Progress: 75.0% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "üì¶ Installing requirements...\n",
            "üîß Using pip command: .venv/bin/pip\n",
            "‚úÖ Requirements installation completed successfully\n",
            "\n",
            "[7/8] ‚úÖ Requirements\n",
            "Progress: 75.0% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "‚è±Ô∏è Requirements completed in 3.6s\n",
            "\n",
            "[8/8] üîÑ Environment Verification\n",
            "Progress: 87.5% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "üîç Verifying installation...\n",
            "üîß Using python command: .venv/bin/python\n",
            "üìç Final directory: /content/Wan2GP\n",
            "‚úÖ PyTorch verification successful:\n",
            "   PyTorch 2.6.0+cu124 installed\n",
            "   CUDA available: True\n",
            "‚úÖ WanGP main file found\n",
            "\n",
            "[8/8] ‚úÖ Environment Verification\n",
            "Progress: 87.5% | Platform: Google Colab\n",
            "üîß Using: .venv/bin/pip | .venv/bin/python | venv: True\n",
            "============================================================\n",
            "‚è±Ô∏è Environment Verification completed in 7.3s\n",
            "\n",
            "üéâ WAN2GP setup completed successfully in 26.3s!\n",
            "üöÄ Ready to launch WAN2GP!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (3) WAN2GP Essential Downloads - Complete Interface Population System\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import time\n",
        "import urllib.request\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if \"google.colab\" not in sys.modules:\n",
        "        from IPython.display import display, Markdown\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"WAN2GP Essential Downloads - Complete Interface Population System\")\n",
        "\n",
        "class WAN2GPCompleteDownloader:\n",
        "    def __init__(self):\n",
        "        # Use global platform configuration from Cell 1\n",
        "        try:\n",
        "            self.current_platform = current_platform\n",
        "            self.pip_cmd = pip_cmd\n",
        "            self.python_cmd = python_cmd\n",
        "            self.use_venv = use_venv\n",
        "        except NameError:\n",
        "            print(\"‚ö†Ô∏è Platform detection variables not found. Using fallback detection.\")\n",
        "            self.detect_platform_fallback()\n",
        "\n",
        "        # Essential model configurations from documentation[3][14]\n",
        "        self.essential_models = {\n",
        "            # Core Text2Video Models - populate model dropdown\n",
        "            \"wan_t2v_1_3b\": {\n",
        "                \"name\": \"Wan 2.1 Text2Video 1.3B\",\n",
        "                \"filename\": \"Wan2_1-T2V-1_3B_bf16.safetensors\",\n",
        "                \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_bf16.safetensors\",\n",
        "                \"size\": \"2.87 GB\",\n",
        "                \"destination\": \"ckpts/\",\n",
        "                \"priority\": \"essential\",\n",
        "                \"description\": \"Fast T2V model (6GB VRAM)\"\n",
        "            },\n",
        "            \"wan_t2v_1_3b_fp32\": {\n",
        "                \"name\": \"Wan 2.1 Text2Video 1.3B FP32\",\n",
        "                \"filename\": \"Wan2_1-T2V-1_3B_fp32.safetensors\",\n",
        "                \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_fp32.safetensors\",\n",
        "                \"size\": \"5.68 GB\",\n",
        "                \"destination\": \"ckpts/\",\n",
        "                \"priority\": \"high\",\n",
        "                \"description\": \"I2V compatibility model\"\n",
        "            },\n",
        "            # Essential Text Encoder - required for all models[3]\n",
        "            \"umt5_encoder\": {\n",
        "                \"name\": \"UMT5 Text Encoder XXL\",\n",
        "                \"filename\": \"umt5_xxl_fp16.safetensors\",\n",
        "                \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/umt5_xxl_fp16.safetensors\",\n",
        "                \"size\": \"3.0 GB\",\n",
        "                \"destination\": \"text_encoders/\",\n",
        "                \"priority\": \"essential\",\n",
        "                \"description\": \"Required text encoder for all models\"\n",
        "            },\n",
        "            # Essential VAE Models - required for generation[3]\n",
        "            \"wan_vae_bf16\": {\n",
        "                \"name\": \"Wan VAE BF16\",\n",
        "                \"filename\": \"Wan2_1_VAE_bf16.safetensors\",\n",
        "                \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_bf16.safetensors\",\n",
        "                \"size\": \"254 MB\",\n",
        "                \"destination\": \"vae/\",\n",
        "                \"priority\": \"essential\",\n",
        "                \"description\": \"Required VAE for video generation\"\n",
        "            },\n",
        "            \"wan_vae_fp32\": {\n",
        "                \"name\": \"Wan VAE FP32\",\n",
        "                \"filename\": \"Wan2_1_VAE_fp32.safetensors\",\n",
        "                \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_fp32.safetensors\",\n",
        "                \"size\": \"508 MB\",\n",
        "                \"destination\": \"vae/\",\n",
        "                \"priority\": \"high\",\n",
        "                \"description\": \"Alternative VAE format\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Essential LoRA configurations from documentation[9][17]\n",
        "        self.essential_loras = {\n",
        "            # Speed Enhancement LoRAs - populate LoRA checkboxes[9]\n",
        "            \"safe_forcing\": {\n",
        "                \"name\": \"Safe-Forcing lightx2v (2-step generation)\",\n",
        "                \"filename\": \"Wan2_1-T2V-14B-lightx2v-cfg-step-distill-lora-rank32.safetensors\",\n",
        "                \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-14B-lightx2v-cfg-step-distill-lora-rank32.safetensors\",\n",
        "                \"size\": \"134 MB\",\n",
        "                \"destination\": \"loras/\",\n",
        "                \"priority\": \"essential\",\n",
        "                \"description\": \"2-step generation, 2x speed boost\"\n",
        "            },\n",
        "            \"causvid\": {\n",
        "                \"name\": \"CausVid (4-12 step generation)\",\n",
        "                \"filename\": \"Wan2_1-CausVid-14B-T2V-lora-rank32.safetensors\",\n",
        "                \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-CausVid-14B-T2V-lora-rank32.safetensors\",\n",
        "                \"size\": \"134 MB\",\n",
        "                \"destination\": \"loras/\",\n",
        "                \"priority\": \"essential\",\n",
        "                \"description\": \"4-12 steps, 2x speed improvement\"\n",
        "            },\n",
        "            \"accvid_t2v\": {\n",
        "                \"name\": \"AccVid T2V (2x speed improvement)\",\n",
        "                \"filename\": \"Wan2_1-AccVid-T2V-14B-lora-rank32-fp16.safetensors\",\n",
        "                \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-AccVid-T2V-14B-lora-rank32-fp16.safetensors\",\n",
        "                \"size\": \"134 MB\",\n",
        "                \"destination\": \"loras/\",\n",
        "                \"priority\": \"high\",\n",
        "                \"description\": \"2x speed, no CFG needed\"\n",
        "            },\n",
        "            \"accvid_i2v\": {\n",
        "                \"name\": \"AccVid I2V (Image2Video acceleration)\",\n",
        "                \"filename\": \"Wan2_1-AccVid-I2V-480P-14B-lora-rank32-fp16.safetensors\",\n",
        "                \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-AccVid-I2V-480P-14B-lora-rank32-fp16.safetensors\",\n",
        "                \"size\": \"134 MB\",\n",
        "                \"destination\": \"lorasi2v/\",\n",
        "                \"priority\": \"high\",\n",
        "                \"description\": \"I2V speed enhancement\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.all_downloads = {**self.essential_models, **self.essential_loras}\n",
        "\n",
        "    def detect_platform_fallback(self):\n",
        "        \"\"\"Fallback platform detection - ENFORCES VENV FOR COLAB per system instructions\"\"\"\n",
        "        if \"google.colab\" in sys.modules:\n",
        "            self.current_platform = \"Google Colab\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "        elif any([\"lightning\" in str(sys.executable).lower(), \"teamspace\" in os.getcwd()]):\n",
        "            self.current_platform = \"Lightning AI\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \"pip\", \"python\", False\n",
        "        else:\n",
        "            self.current_platform = \"Generic\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "    def create_directory_structure(self):\n",
        "        \"\"\"Create complete WAN2GP directory structure from documentation[3][9]\"\"\"\n",
        "        print(\"üìÅ Creating WAN2GP directory structure...\")\n",
        "\n",
        "        # Complete directory structure from documentation[9][17]\n",
        "        directories = {\n",
        "            \"ckpts\": \"Main model files - populate model dropdown\",\n",
        "            \"text_encoders\": \"Text encoding models - required for generation\",\n",
        "            \"vae\": \"VAE models - required for generation\",\n",
        "            \"vae_approx\": \"Approximate VAE models\",\n",
        "            \"clip_vision\": \"CLIP vision models\",\n",
        "            \"loras\": \"General T2V LoRAs - populate LoRA checkboxes\",\n",
        "            \"loras1.3B\": \"1.3B specific LoRAs\",\n",
        "            \"loras14B\": \"14B specific LoRAs\",\n",
        "            \"lorasi2v\": \"Image-to-video LoRAs\",\n",
        "            \"lorashunyuan\": \"Hunyuan Video LoRAs\",\n",
        "            \"lorashunyuani2v\": \"Hunyuan I2V LoRAs\",\n",
        "            \"lorasltxv\": \"LTX Video LoRAs\"\n",
        "        }\n",
        "\n",
        "        for directory, description in directories.items():\n",
        "            Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"   ‚úÖ {directory}/ - {description}\")\n",
        "\n",
        "        print(\"‚úÖ Complete directory structure created\")\n",
        "        return True\n",
        "\n",
        "    def download_with_fallback_methods(self, config, item_id):\n",
        "        \"\"\"Download using multiple methods with comprehensive fallback\"\"\"\n",
        "        filename = config[\"filename\"]\n",
        "        url = config[\"url\"]\n",
        "        destination = config[\"destination\"]\n",
        "        full_path = os.path.join(destination, filename)\n",
        "\n",
        "        print(f\"\\nüì• Downloading: {config['name']}\")\n",
        "        print(f\"üìä Size: {config['size']}\")\n",
        "        print(f\"üìÑ File: {filename}\")\n",
        "        print(f\"üìÅ Destination: {full_path}\")\n",
        "        print(f\"üîó URL: {url}\")\n",
        "\n",
        "        # Check if file already exists\n",
        "        if os.path.exists(full_path):\n",
        "            file_size = os.path.getsize(full_path)\n",
        "            if file_size > 1024:  # File exists and has content\n",
        "                print(f\"‚úÖ {filename} already exists ({file_size:,} bytes) - skipping\")\n",
        "                return True\n",
        "\n",
        "        # Ensure destination directory exists\n",
        "        Path(destination).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Method 1: HuggingFace Hub (if available)\n",
        "        if self.try_huggingface_hub_download(url, full_path, filename):\n",
        "            return True\n",
        "\n",
        "        # Method 2: aria2c (fastest for large files)\n",
        "        if self.try_aria2c_download(url, full_path):\n",
        "            return True\n",
        "\n",
        "        # Method 3: wget (reliable fallback)\n",
        "        if self.try_wget_download(url, full_path):\n",
        "            return True\n",
        "\n",
        "        # Method 4: Python urllib (final fallback)\n",
        "        if self.try_urllib_download(url, full_path):\n",
        "            return True\n",
        "\n",
        "        print(f\"‚ùå All download methods failed for {filename}\")\n",
        "        return False\n",
        "\n",
        "    def try_huggingface_hub_download(self, url, full_path, filename):\n",
        "        \"\"\"Try HuggingFace Hub download using python command\"\"\"\n",
        "        try:\n",
        "            print(\"üîÑ Trying HuggingFace Hub...\")\n",
        "\n",
        "            if \"huggingface.co\" in url and \"/resolve/main/\" in url:\n",
        "                repo_part = url.split(\"huggingface.co/\")[1].split(\"/resolve/main/\")[0]\n",
        "                file_part = url.split(\"/resolve/main/\")[1]\n",
        "\n",
        "                # Create download script\n",
        "                download_script = f'''\n",
        "import sys\n",
        "try:\n",
        "    from huggingface_hub import hf_hub_download\n",
        "    import os\n",
        "\n",
        "    # Download to proper location\n",
        "    downloaded_path = hf_hub_download(\n",
        "        repo_id=\"{repo_part}\",\n",
        "        filename=\"{file_part}\",\n",
        "        local_dir=\".\",\n",
        "        local_dir_use_symlinks=False\n",
        "    )\n",
        "\n",
        "    # Verify file exists and has content\n",
        "    if os.path.exists(\"{full_path}\") and os.path.getsize(\"{full_path}\") > 1024:\n",
        "        print(\"HF_SUCCESS\")\n",
        "    else:\n",
        "        print(\"HF_FAILED\")\n",
        "        sys.exit(1)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"HF_ERROR: {{e}}\")\n",
        "    sys.exit(1)\n",
        "'''\n",
        "\n",
        "                result = subprocess.run([\n",
        "                    self.python_cmd, \"-c\", download_script\n",
        "                ], capture_output=True, text=True, timeout=600)\n",
        "\n",
        "                if result.returncode == 0 and \"HF_SUCCESS\" in result.stdout:\n",
        "                    print(\"‚úÖ HuggingFace Hub download successful\")\n",
        "                    return True\n",
        "                else:\n",
        "                    print(f\"‚ùå HuggingFace Hub failed: {result.stderr}\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è URL not compatible with HuggingFace Hub\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå HuggingFace Hub error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def try_aria2c_download(self, url, full_path):\n",
        "        \"\"\"Try aria2c download (fastest for large files)\"\"\"\n",
        "        try:\n",
        "            print(\"üîÑ Trying aria2c (16 connections)...\")\n",
        "\n",
        "            result = subprocess.run([\n",
        "                \"aria2c\",\n",
        "                \"--max-connection-per-server=16\",\n",
        "                \"--split=16\",\n",
        "                \"--min-split-size=1M\",\n",
        "                \"--continue=true\",\n",
        "                \"--timeout=60\",\n",
        "                \"--retry-wait=3\",\n",
        "                \"--max-tries=3\",\n",
        "                \"--out\", os.path.basename(full_path),\n",
        "                \"--dir\", os.path.dirname(full_path) or \".\",\n",
        "                url\n",
        "            ], capture_output=True, text=True, timeout=1800)\n",
        "\n",
        "            if result.returncode == 0 and os.path.exists(full_path):\n",
        "                print(\"‚úÖ aria2c download successful\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå aria2c failed: {result.stderr}\")\n",
        "                return False\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(\"‚ùå aria2c not found\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå aria2c error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def try_wget_download(self, url, full_path):\n",
        "        \"\"\"Try wget download\"\"\"\n",
        "        try:\n",
        "            print(\"üîÑ Trying wget...\")\n",
        "\n",
        "            result = subprocess.run([\n",
        "                \"wget\",\n",
        "                \"--continue\",\n",
        "                \"--timeout=60\",\n",
        "                \"--tries=3\",\n",
        "                \"--retry-connrefused\",\n",
        "                \"--waitretry=3\",\n",
        "                \"-O\", full_path,\n",
        "                url\n",
        "            ], capture_output=True, text=True, timeout=1800)\n",
        "\n",
        "            if result.returncode == 0 and os.path.exists(full_path):\n",
        "                print(\"‚úÖ wget download successful\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå wget failed: {result.stderr}\")\n",
        "                return False\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(\"‚ùå wget not found\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå wget error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def try_urllib_download(self, url, full_path):\n",
        "        \"\"\"Try Python urllib download with progress\"\"\"\n",
        "        try:\n",
        "            print(\"üîÑ Trying Python urllib...\")\n",
        "\n",
        "            def download_with_progress(url, filepath):\n",
        "                try:\n",
        "                    # Ensure directory exists\n",
        "                    Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                    # Download file\n",
        "                    urllib.request.urlretrieve(url, filepath)\n",
        "\n",
        "                    # Verify download\n",
        "                    return os.path.exists(filepath) and os.path.getsize(filepath) > 1024\n",
        "                except Exception as e:\n",
        "                    print(f\"urllib error: {e}\")\n",
        "                    return False\n",
        "\n",
        "            if download_with_progress(url, full_path):\n",
        "                print(\"‚úÖ Python urllib download successful\")\n",
        "                return True\n",
        "            else:\n",
        "                print(\"‚ùå Python urllib download failed\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Python urllib error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def download_essential_pack(self):\n",
        "        \"\"\"Download essential models and LoRAs for immediate functionality\"\"\"\n",
        "        print(\"üéØ Downloading Essential Pack for WAN2GP Interface Population...\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"üìã This will populate:\")\n",
        "        print(\"   ‚Ä¢ Model dropdown with Wan 2.1 T2V models\")\n",
        "        print(\"   ‚Ä¢ Advanced tab LoRA checkboxes with speed enhancements\")\n",
        "        print(\"   ‚Ä¢ Required text encoders and VAE models\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Essential items in priority order\n",
        "        essential_priority = [\n",
        "            # Critical for basic functionality\n",
        "            (\"wan_vae_bf16\", \"essential\"),     # Required VAE\n",
        "            (\"umt5_encoder\", \"essential\"),     # Required text encoder\n",
        "            (\"wan_t2v_1_3b\", \"essential\"),     # Main model for dropdown\n",
        "            # Speed enhancements for LoRA checkboxes\n",
        "            (\"safe_forcing\", \"essential\"),     # 2-step generation\n",
        "            (\"causvid\", \"essential\"),          # Fast generation\n",
        "            # Additional functionality\n",
        "            (\"wan_t2v_1_3b_fp32\", \"high\"),     # I2V compatibility\n",
        "            (\"wan_vae_fp32\", \"high\"),          # Alternative VAE\n",
        "            (\"accvid_t2v\", \"high\"),            # T2V acceleration\n",
        "            (\"accvid_i2v\", \"high\")             # I2V acceleration\n",
        "        ]\n",
        "\n",
        "        successful_downloads = 0\n",
        "        total_items = len(essential_priority)\n",
        "\n",
        "        for i, (item_id, priority) in enumerate(essential_priority, 1):\n",
        "            config = self.all_downloads[item_id]\n",
        "            print(f\"\\n[{i}/{total_items}] Processing {config['name']} (Priority: {priority})\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            if self.download_with_fallback_methods(config, item_id):\n",
        "                successful_downloads += 1\n",
        "                print(f\"‚úÖ {config['name']} downloaded successfully\")\n",
        "            else:\n",
        "                print(f\"‚ùå {config['name']} download failed\")\n",
        "                if priority == \"essential\":\n",
        "                    print(\"‚ö†Ô∏è This is an essential file - WAN2GP functionality may be limited\")\n",
        "\n",
        "        success_rate = (successful_downloads / total_items) * 100\n",
        "\n",
        "        print(f\"\\nüìä Essential Pack Download Summary:\")\n",
        "        print(f\"Total items: {total_items}\")\n",
        "        print(f\"Successful: {successful_downloads}\")\n",
        "        print(f\"Failed: {total_items - successful_downloads}\")\n",
        "        print(f\"Success rate: {success_rate:.1f}%\")\n",
        "\n",
        "        # Verify interface population\n",
        "        self.verify_interface_population()\n",
        "\n",
        "        if success_rate >= 80:\n",
        "            print(\"üéâ Essential pack download completed successfully!\")\n",
        "            print(\"‚úÖ WAN2GP interface should now show models and LoRAs\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Some downloads failed, but WAN2GP may still be functional\")\n",
        "            print(\"üîÑ You can re-run this cell to retry failed downloads\")\n",
        "            return False\n",
        "\n",
        "    def verify_interface_population(self):\n",
        "        \"\"\"Verify that downloaded files will populate the Gradio interface\"\"\"\n",
        "        print(f\"\\nüîç Verifying Interface Population...\")\n",
        "\n",
        "        # Check models for dropdown population\n",
        "        model_files = list(Path(\"ckpts\").glob(\"*.safetensors\"))\n",
        "        print(f\"üìÑ Models in ckpts/ (will appear in model dropdown): {len(model_files)}\")\n",
        "        for model in model_files:\n",
        "            print(f\"   ‚úÖ {model.name}\")\n",
        "\n",
        "        # Check LoRAs for checkbox population\n",
        "        lora_files = list(Path(\"loras\").glob(\"*.safetensors\"))\n",
        "        print(f\"üé® LoRAs in loras/ (will appear in Advanced tab): {len(lora_files)}\")\n",
        "        for lora in lora_files:\n",
        "            print(f\"   ‚úÖ {lora.name}\")\n",
        "\n",
        "        # Check I2V LoRAs\n",
        "        i2v_lora_files = list(Path(\"lorasi2v\").glob(\"*.safetensors\"))\n",
        "        print(f\"üñºÔ∏è I2V LoRAs in lorasi2v/: {len(i2v_lora_files)}\")\n",
        "        for lora in i2v_lora_files:\n",
        "            print(f\"   ‚úÖ {lora.name}\")\n",
        "\n",
        "        # Check essential components\n",
        "        encoder_files = list(Path(\"text_encoders\").glob(\"*.safetensors\"))\n",
        "        print(f\"üìù Text encoders (required): {len(encoder_files)}\")\n",
        "\n",
        "        vae_files = list(Path(\"vae\").glob(\"*.safetensors\"))\n",
        "        print(f\"üé≠ VAE models (required): {len(vae_files)}\")\n",
        "\n",
        "        # Summary for interface readiness\n",
        "        interface_ready = (len(model_files) >= 1 and len(encoder_files) >= 1 and\n",
        "                          len(vae_files) >= 1 and len(lora_files) >= 2)\n",
        "\n",
        "        if interface_ready:\n",
        "            print(f\"\\n‚úÖ Interface Population Verified!\")\n",
        "            print(f\"üéâ WAN2GP will show:\")\n",
        "            print(f\"   ‚Ä¢ {len(model_files)} model(s) in dropdown menu\")\n",
        "            print(f\"   ‚Ä¢ {len(lora_files)} LoRA(s) in Advanced tab checkboxes\")\n",
        "            print(f\"   ‚Ä¢ All required components for generation\")\n",
        "        else:\n",
        "            print(f\"\\n‚ö†Ô∏è Interface may have limited options\")\n",
        "            print(f\"üí° Ensure at least 1 model, 1 encoder, 1 VAE, and 2 LoRAs are downloaded\")\n",
        "\n",
        "        return interface_ready\n",
        "\n",
        "# Create and execute the download system\n",
        "downloader = WAN2GPCompleteDownloader()\n",
        "\n",
        "# Display download interface\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "           color: white; padding: 20px; border-radius: 10px; text-align: center;\n",
        "           margin: 10px 0; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "    <h2>üéØ WAN2GP Essential Downloads</h2>\n",
        "    <p><strong>Platform:</strong> {downloader.current_platform}</p>\n",
        "    <p><strong>Python Command:</strong> {downloader.python_cmd}</p>\n",
        "    <p>This will populate your Gradio interface with models and LoRAs</p>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "print(\"üéØ WAN2GP Essential Download Options:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. Essential Pack (Recommended) - ~8GB\")\n",
        "print(\"   ‚Ä¢ Wan T2V 1.3B model + FP32 variant\")\n",
        "print(\"   ‚Ä¢ Text encoder & VAE (required components)\")\n",
        "print(\"   ‚Ä¢ Speed enhancement LoRAs (Safe-Forcing, CausVid, AccVid)\")\n",
        "print(\"   ‚Ä¢ Populates model dropdown and LoRA checkboxes\")\n",
        "print(\"\")\n",
        "print(\"2. Skip Downloads\")\n",
        "print(\"   ‚Ä¢ Use if models already downloaded\")\n",
        "print(\"   ‚Ä¢ WAN2GP will auto-download minimal models on first use\")\n",
        "print(\"\")\n",
        "\n",
        "choice = input(\"üéØ Select option (1/2 or Enter for Essential): \").strip()\n",
        "\n",
        "# Execute download based on choice\n",
        "if choice == \"2\":\n",
        "    print(\"‚è≠Ô∏è Skipping downloads - WAN2GP will auto-download models when needed\")\n",
        "    success = True\n",
        "else:\n",
        "    # Create directory structure first\n",
        "    if not downloader.create_directory_structure():\n",
        "        print(\"‚ùå Failed to create directory structure\")\n",
        "        success = False\n",
        "    else:\n",
        "        # Download essential pack\n",
        "        success = downloader.download_essential_pack()\n",
        "\n",
        "if success:\n",
        "    print(\"\\nüéâ Download system completed successfully!\")\n",
        "    print(\"‚úÖ WAN2GP models and LoRAs should now appear in interface menus\")\n",
        "    print(\"üöÄ Proceed to Cell 4 to launch WAN2GP with public Gradio link\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Some downloads may have failed\")\n",
        "    print(\"üîÑ You can re-run this cell to retry failed downloads\")\n",
        "    print(\"üí° WAN2GP may still work with auto-downloaded models\")\n"
      ],
      "metadata": {
        "id": "yP38IfT3_Gy9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b39f2e2-d282-4dbf-e8d4-ce4a01a50d3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
              "           color: white; padding: 20px; border-radius: 10px; text-align: center; \n",
              "           margin: 10px 0; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "    <h2>üéØ WAN2GP Essential Downloads</h2>\n",
              "    <p><strong>Platform:</strong> Google Colab</p>\n",
              "    <p><strong>Python Command:</strong> .venv/bin/python</p>\n",
              "    <p>This will populate your Gradio interface with models and LoRAs</p>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ WAN2GP Essential Download Options:\n",
            "============================================================\n",
            "1. Essential Pack (Recommended) - ~8GB\n",
            "   ‚Ä¢ Wan T2V 1.3B model + FP32 variant\n",
            "   ‚Ä¢ Text encoder & VAE (required components)\n",
            "   ‚Ä¢ Speed enhancement LoRAs (Safe-Forcing, CausVid, AccVid)\n",
            "   ‚Ä¢ Populates model dropdown and LoRA checkboxes\n",
            "\n",
            "2. Skip Downloads\n",
            "   ‚Ä¢ Use if models already downloaded\n",
            "   ‚Ä¢ WAN2GP will auto-download minimal models on first use\n",
            "\n",
            "üéØ Select option (1/2 or Enter for Essential): 1\n",
            "üìÅ Creating WAN2GP directory structure...\n",
            "   ‚úÖ ckpts/ - Main model files - populate model dropdown\n",
            "   ‚úÖ text_encoders/ - Text encoding models - required for generation\n",
            "   ‚úÖ vae/ - VAE models - required for generation\n",
            "   ‚úÖ vae_approx/ - Approximate VAE models\n",
            "   ‚úÖ clip_vision/ - CLIP vision models\n",
            "   ‚úÖ loras/ - General T2V LoRAs - populate LoRA checkboxes\n",
            "   ‚úÖ loras1.3B/ - 1.3B specific LoRAs\n",
            "   ‚úÖ loras14B/ - 14B specific LoRAs\n",
            "   ‚úÖ lorasi2v/ - Image-to-video LoRAs\n",
            "   ‚úÖ lorashunyuan/ - Hunyuan Video LoRAs\n",
            "   ‚úÖ lorashunyuani2v/ - Hunyuan I2V LoRAs\n",
            "   ‚úÖ lorasltxv/ - LTX Video LoRAs\n",
            "‚úÖ Complete directory structure created\n",
            "üéØ Downloading Essential Pack for WAN2GP Interface Population...\n",
            "======================================================================\n",
            "üìã This will populate:\n",
            "   ‚Ä¢ Model dropdown with Wan 2.1 T2V models\n",
            "   ‚Ä¢ Advanced tab LoRA checkboxes with speed enhancements\n",
            "   ‚Ä¢ Required text encoders and VAE models\n",
            "======================================================================\n",
            "\n",
            "[1/9] Processing Wan VAE BF16 (Priority: essential)\n",
            "============================================================\n",
            "\n",
            "üì• Downloading: Wan VAE BF16\n",
            "üìä Size: 254 MB\n",
            "üìÑ File: Wan2_1_VAE_bf16.safetensors\n",
            "üìÅ Destination: vae/Wan2_1_VAE_bf16.safetensors\n",
            "üîó URL: https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_bf16.safetensors\n",
            "üîÑ Trying HuggingFace Hub...\n",
            "‚ùå HuggingFace Hub failed: /content/Wan2GP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "\n",
            "üîÑ Trying aria2c (16 connections)...\n",
            "‚úÖ aria2c download successful\n",
            "‚úÖ Wan VAE BF16 downloaded successfully\n",
            "\n",
            "[2/9] Processing UMT5 Text Encoder XXL (Priority: essential)\n",
            "============================================================\n",
            "\n",
            "üì• Downloading: UMT5 Text Encoder XXL\n",
            "üìä Size: 3.0 GB\n",
            "üìÑ File: umt5_xxl_fp16.safetensors\n",
            "üìÅ Destination: text_encoders/umt5_xxl_fp16.safetensors\n",
            "üîó URL: https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/umt5_xxl_fp16.safetensors\n",
            "üîÑ Trying HuggingFace Hub...\n",
            "‚ùå HuggingFace Hub failed: /content/Wan2GP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "\n",
            "üîÑ Trying aria2c (16 connections)...\n",
            "‚ùå aria2c failed: \n",
            "üîÑ Trying wget...\n",
            "‚ùå wget failed: --2025-07-05 19:29:33--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/umt5_xxl_fp16.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.105, 3.166.152.110, 3.166.152.65, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-05 19:29:33 ERROR 404: Not Found.\n",
            "\n",
            "\n",
            "üîÑ Trying Python urllib...\n",
            "urllib error: HTTP Error 404: Not Found\n",
            "‚ùå Python urllib download failed\n",
            "‚ùå All download methods failed for umt5_xxl_fp16.safetensors\n",
            "‚ùå UMT5 Text Encoder XXL download failed\n",
            "‚ö†Ô∏è This is an essential file - WAN2GP functionality may be limited\n",
            "\n",
            "[3/9] Processing Wan 2.1 Text2Video 1.3B (Priority: essential)\n",
            "============================================================\n",
            "\n",
            "üì• Downloading: Wan 2.1 Text2Video 1.3B\n",
            "üìä Size: 2.87 GB\n",
            "üìÑ File: Wan2_1-T2V-1_3B_bf16.safetensors\n",
            "üìÅ Destination: ckpts/Wan2_1-T2V-1_3B_bf16.safetensors\n",
            "üîó URL: https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_bf16.safetensors\n",
            "üîÑ Trying HuggingFace Hub...\n",
            "‚ùå HuggingFace Hub failed: /content/Wan2GP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "\n",
            "üîÑ Trying aria2c (16 connections)...\n",
            "‚úÖ aria2c download successful\n",
            "‚úÖ Wan 2.1 Text2Video 1.3B downloaded successfully\n",
            "\n",
            "[4/9] Processing Safe-Forcing lightx2v (2-step generation) (Priority: essential)\n",
            "============================================================\n",
            "\n",
            "üì• Downloading: Safe-Forcing lightx2v (2-step generation)\n",
            "üìä Size: 134 MB\n",
            "üìÑ File: Wan2_1-T2V-14B-lightx2v-cfg-step-distill-lora-rank32.safetensors\n",
            "üìÅ Destination: loras/Wan2_1-T2V-14B-lightx2v-cfg-step-distill-lora-rank32.safetensors\n",
            "üîó URL: https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-14B-lightx2v-cfg-step-distill-lora-rank32.safetensors\n",
            "üîÑ Trying HuggingFace Hub...\n",
            "‚ùå HuggingFace Hub failed: /content/Wan2GP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "\n",
            "üîÑ Trying aria2c (16 connections)...\n",
            "‚ùå aria2c failed: \n",
            "üîÑ Trying wget...\n",
            "‚ùå wget failed: --2025-07-05 19:30:45--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-14B-lightx2v-cfg-step-distill-lora-rank32.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.105, 3.166.152.110, 3.166.152.65, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-05 19:30:45 ERROR 404: Not Found.\n",
            "\n",
            "\n",
            "üîÑ Trying Python urllib...\n",
            "urllib error: HTTP Error 404: Not Found\n",
            "‚ùå Python urllib download failed\n",
            "‚ùå All download methods failed for Wan2_1-T2V-14B-lightx2v-cfg-step-distill-lora-rank32.safetensors\n",
            "‚ùå Safe-Forcing lightx2v (2-step generation) download failed\n",
            "‚ö†Ô∏è This is an essential file - WAN2GP functionality may be limited\n",
            "\n",
            "[5/9] Processing CausVid (4-12 step generation) (Priority: essential)\n",
            "============================================================\n",
            "\n",
            "üì• Downloading: CausVid (4-12 step generation)\n",
            "üìä Size: 134 MB\n",
            "üìÑ File: Wan2_1-CausVid-14B-T2V-lora-rank32.safetensors\n",
            "üìÅ Destination: loras/Wan2_1-CausVid-14B-T2V-lora-rank32.safetensors\n",
            "üîó URL: https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-CausVid-14B-T2V-lora-rank32.safetensors\n",
            "üîÑ Trying HuggingFace Hub...\n",
            "‚ùå HuggingFace Hub failed: /content/Wan2GP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "\n",
            "üîÑ Trying aria2c (16 connections)...\n",
            "‚ùå aria2c failed: \n",
            "üîÑ Trying wget...\n",
            "‚ùå wget failed: --2025-07-05 19:30:46--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-CausVid-14B-T2V-lora-rank32.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.105, 3.166.152.110, 3.166.152.65, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-05 19:30:46 ERROR 404: Not Found.\n",
            "\n",
            "\n",
            "üîÑ Trying Python urllib...\n",
            "urllib error: HTTP Error 404: Not Found\n",
            "‚ùå Python urllib download failed\n",
            "‚ùå All download methods failed for Wan2_1-CausVid-14B-T2V-lora-rank32.safetensors\n",
            "‚ùå CausVid (4-12 step generation) download failed\n",
            "‚ö†Ô∏è This is an essential file - WAN2GP functionality may be limited\n",
            "\n",
            "[6/9] Processing Wan 2.1 Text2Video 1.3B FP32 (Priority: high)\n",
            "============================================================\n",
            "\n",
            "üì• Downloading: Wan 2.1 Text2Video 1.3B FP32\n",
            "üìä Size: 5.68 GB\n",
            "üìÑ File: Wan2_1-T2V-1_3B_fp32.safetensors\n",
            "üìÅ Destination: ckpts/Wan2_1-T2V-1_3B_fp32.safetensors\n",
            "üîó URL: https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-T2V-1_3B_fp32.safetensors\n",
            "üîÑ Trying HuggingFace Hub...\n",
            "‚ùå HuggingFace Hub failed: /content/Wan2GP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "\n",
            "üîÑ Trying aria2c (16 connections)...\n",
            "‚úÖ aria2c download successful\n",
            "‚úÖ Wan 2.1 Text2Video 1.3B FP32 downloaded successfully\n",
            "\n",
            "[7/9] Processing Wan VAE FP32 (Priority: high)\n",
            "============================================================\n",
            "\n",
            "üì• Downloading: Wan VAE FP32\n",
            "üìä Size: 508 MB\n",
            "üìÑ File: Wan2_1_VAE_fp32.safetensors\n",
            "üìÅ Destination: vae/Wan2_1_VAE_fp32.safetensors\n",
            "üîó URL: https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_fp32.safetensors\n",
            "üîÑ Trying HuggingFace Hub...\n",
            "‚ùå HuggingFace Hub failed: /content/Wan2GP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "\n",
            "üîÑ Trying aria2c (16 connections)...\n",
            "‚úÖ aria2c download successful\n",
            "‚úÖ Wan VAE FP32 downloaded successfully\n",
            "\n",
            "[8/9] Processing AccVid T2V (2x speed improvement) (Priority: high)\n",
            "============================================================\n",
            "\n",
            "üì• Downloading: AccVid T2V (2x speed improvement)\n",
            "üìä Size: 134 MB\n",
            "üìÑ File: Wan2_1-AccVid-T2V-14B-lora-rank32-fp16.safetensors\n",
            "üìÅ Destination: loras/Wan2_1-AccVid-T2V-14B-lora-rank32-fp16.safetensors\n",
            "üîó URL: https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-AccVid-T2V-14B-lora-rank32-fp16.safetensors\n",
            "üîÑ Trying HuggingFace Hub...\n",
            "‚ùå HuggingFace Hub failed: /content/Wan2GP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "\n",
            "üîÑ Trying aria2c (16 connections)...\n",
            "‚ùå aria2c failed: \n",
            "üîÑ Trying wget...\n",
            "‚ùå wget failed: --2025-07-05 19:32:44--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-AccVid-T2V-14B-lora-rank32-fp16.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.105, 3.166.152.65, 3.166.152.44, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-05 19:32:44 ERROR 404: Not Found.\n",
            "\n",
            "\n",
            "üîÑ Trying Python urllib...\n",
            "urllib error: HTTP Error 404: Not Found\n",
            "‚ùå Python urllib download failed\n",
            "‚ùå All download methods failed for Wan2_1-AccVid-T2V-14B-lora-rank32-fp16.safetensors\n",
            "‚ùå AccVid T2V (2x speed improvement) download failed\n",
            "\n",
            "[9/9] Processing AccVid I2V (Image2Video acceleration) (Priority: high)\n",
            "============================================================\n",
            "\n",
            "üì• Downloading: AccVid I2V (Image2Video acceleration)\n",
            "üìä Size: 134 MB\n",
            "üìÑ File: Wan2_1-AccVid-I2V-480P-14B-lora-rank32-fp16.safetensors\n",
            "üìÅ Destination: lorasi2v/Wan2_1-AccVid-I2V-480P-14B-lora-rank32-fp16.safetensors\n",
            "üîó URL: https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-AccVid-I2V-480P-14B-lora-rank32-fp16.safetensors\n",
            "üîÑ Trying HuggingFace Hub...\n",
            "‚ùå HuggingFace Hub failed: /content/Wan2GP/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "\n",
            "üîÑ Trying aria2c (16 connections)...\n",
            "‚ùå aria2c failed: \n",
            "üîÑ Trying wget...\n",
            "‚ùå wget failed: --2025-07-05 19:32:44--  https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1-AccVid-I2V-480P-14B-lora-rank32-fp16.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.105, 3.166.152.65, 3.166.152.44, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-05 19:32:44 ERROR 404: Not Found.\n",
            "\n",
            "\n",
            "üîÑ Trying Python urllib...\n",
            "urllib error: HTTP Error 404: Not Found\n",
            "‚ùå Python urllib download failed\n",
            "‚ùå All download methods failed for Wan2_1-AccVid-I2V-480P-14B-lora-rank32-fp16.safetensors\n",
            "‚ùå AccVid I2V (Image2Video acceleration) download failed\n",
            "\n",
            "üìä Essential Pack Download Summary:\n",
            "Total items: 9\n",
            "Successful: 4\n",
            "Failed: 5\n",
            "Success rate: 44.4%\n",
            "\n",
            "üîç Verifying Interface Population...\n",
            "üìÑ Models in ckpts/ (will appear in model dropdown): 5\n",
            "   ‚úÖ wan2.1_image2video_480p_14B_quanto_mfp16_int8.safetensors\n",
            "   ‚úÖ Wan2_1-T2V-1_3B_fp32.safetensors\n",
            "   ‚úÖ Wan2.1_VAE.safetensors\n",
            "   ‚úÖ Wan2_1-T2V-1_3B_bf16.safetensors\n",
            "   ‚úÖ fantasy_proj_model.safetensors\n",
            "üé® LoRAs in loras/ (will appear in Advanced tab): 3\n",
            "   ‚úÖ Wan2_1-T2V-14B-lightx2v-cfg-step-distill-lora-rank32.safetensors\n",
            "   ‚úÖ Wan2_1-CausVid-14B-T2V-lora-rank32.safetensors\n",
            "   ‚úÖ Wan2_1-AccVid-T2V-14B-lora-rank32-fp16.safetensors\n",
            "üñºÔ∏è I2V LoRAs in lorasi2v/: 1\n",
            "   ‚úÖ Wan2_1-AccVid-I2V-480P-14B-lora-rank32-fp16.safetensors\n",
            "üìù Text encoders (required): 1\n",
            "üé≠ VAE models (required): 2\n",
            "\n",
            "‚úÖ Interface Population Verified!\n",
            "üéâ WAN2GP will show:\n",
            "   ‚Ä¢ 5 model(s) in dropdown menu\n",
            "   ‚Ä¢ 3 LoRA(s) in Advanced tab checkboxes\n",
            "   ‚Ä¢ All required components for generation\n",
            "‚ö†Ô∏è Some downloads failed, but WAN2GP may still be functional\n",
            "üîÑ You can re-run this cell to retry failed downloads\n",
            "\n",
            "‚ö†Ô∏è Some downloads may have failed\n",
            "üîÑ You can re-run this cell to retry failed downloads\n",
            "üí° WAN2GP may still work with auto-downloaded models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (4) WAN2GP Launch - Enhanced with Public Gradio Link & Error Handling v5.0\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import signal\n",
        "import time\n",
        "import sys\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if \"google.colab\" not in sys.modules:\n",
        "        from IPython.display import display, Markdown\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"WAN2GP Launch - Enhanced with Public Gradio Link & Error Handling\")\n",
        "\n",
        "class WAN2GPLauncher:\n",
        "    def __init__(self):\n",
        "        # Use global platform configuration from Cell 1\n",
        "        try:\n",
        "            self.current_platform = current_platform\n",
        "            self.pip_cmd = pip_cmd\n",
        "            self.python_cmd = python_cmd\n",
        "            self.use_venv = use_venv\n",
        "        except NameError:\n",
        "            print(\"‚ö†Ô∏è Platform detection variables not found. Using fallback detection.\")\n",
        "            self.detect_platform_fallback()\n",
        "\n",
        "        # CRITICAL ENFORCEMENT: Ensure venv for Google Colab per system instructions\n",
        "        self.enforce_colab_venv()\n",
        "\n",
        "        # Model configurations from documentation[3][14]\n",
        "        self.model_options = {\n",
        "            \"1\": {\n",
        "                \"flag\": \"--t2v-1-3B\",\n",
        "                \"name\": \"Wan 2.1 Text2Video 1.3B\",\n",
        "                \"vram\": \"6GB\",\n",
        "                \"speed\": \"Fast\",\n",
        "                \"description\": \"Fast generation, lower VRAM\"\n",
        "            },\n",
        "            \"2\": {\n",
        "                \"flag\": \"--t2v-14B\",\n",
        "                \"name\": \"Wan 2.1 Text2Video 14B\",\n",
        "                \"vram\": \"12GB\",\n",
        "                \"speed\": \"Slower\",\n",
        "                \"description\": \"High quality, more VRAM\"\n",
        "            },\n",
        "            \"3\": {\n",
        "                \"flag\": \"--i2v-1-3B\",\n",
        "                \"name\": \"Wan Fun InP 1.3B\",\n",
        "                \"vram\": \"6GB\",\n",
        "                \"speed\": \"Fast\",\n",
        "                \"description\": \"Image-to-video, fast\"\n",
        "            },\n",
        "            \"4\": {\n",
        "                \"flag\": \"--i2v-14B\",\n",
        "                \"name\": \"Wan 2.1 Image2Video 14B\",\n",
        "                \"vram\": \"12GB\",\n",
        "                \"speed\": \"Slower\",\n",
        "                \"description\": \"High quality I2V\"\n",
        "            },\n",
        "            \"5\": {\n",
        "                \"flag\": \"--vace-1-3B\",\n",
        "                \"name\": \"Wan Vace 1.3B\",\n",
        "                \"vram\": \"6GB\",\n",
        "                \"speed\": \"Fast\",\n",
        "                \"description\": \"ControlNet, motion transfer\"\n",
        "            },\n",
        "            \"6\": {\n",
        "                \"flag\": \"--vace-14B\",\n",
        "                \"name\": \"Wan Vace 14B\",\n",
        "                \"vram\": \"12GB\",\n",
        "                \"speed\": \"Slower\",\n",
        "                \"description\": \"Advanced ControlNet features\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Performance configurations from documentation[5][13]\n",
        "        self.performance_options = {\n",
        "            \"A\": {\n",
        "                \"name\": \"Low VRAM Mode\",\n",
        "                \"args\": [\"--profile\", \"4\", \"--attention\", \"sdpa\"],\n",
        "                \"description\": \"Memory efficient, stable (RTX 10XX-20XX)\"\n",
        "            },\n",
        "            \"B\": {\n",
        "                \"name\": \"High Performance Mode\",\n",
        "                \"args\": [\"--compile\", \"--attention\", \"sage\", \"--profile\", \"3\"],\n",
        "                \"description\": \"Fast generation (RTX 30XX-40XX)\"\n",
        "            },\n",
        "            \"C\": {\n",
        "                \"name\": \"Emergency Fallback\",\n",
        "                \"args\": [\"--attention\", \"sdpa\", \"--profile\", \"4\", \"--fp16\"],\n",
        "                \"description\": \"Maximum compatibility\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def detect_platform_fallback(self):\n",
        "        \"\"\"Fallback platform detection - ENFORCES VENV FOR COLAB per system instructions\"\"\"\n",
        "        if \"google.colab\" in sys.modules:\n",
        "            self.current_platform = \"Google Colab\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "        elif any([\"lightning\" in str(sys.executable).lower(), \"teamspace\" in os.getcwd()]):\n",
        "            self.current_platform = \"Lightning AI\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \"pip\", \"python\", False\n",
        "        else:\n",
        "            self.current_platform = \"Generic\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "    def enforce_colab_venv(self):\n",
        "        \"\"\"CRITICAL: Enforce venv usage for Google Colab per system instructions\"\"\"\n",
        "        if hasattr(self, 'current_platform') and self.current_platform == \"Google Colab\":\n",
        "            if not hasattr(self, 'use_venv') or not self.use_venv or self.python_cmd != \".venv/bin/python\":\n",
        "                print(\"üö® ENFORCING: Google Colab MUST use venv per system instructions\")\n",
        "                self.use_venv = True\n",
        "                self.pip_cmd = \".venv/bin/pip\"\n",
        "                self.python_cmd = \".venv/bin/python\"\n",
        "                print(\"‚úÖ ENFORCED: Launch system using venv commands\")\n",
        "            else:\n",
        "                print(\"‚úÖ VERIFIED: Launch system correctly using venv for Colab\")\n",
        "\n",
        "    def setup_runtime_environment(self):\n",
        "        \"\"\"Setup runtime environment to prevent common errors\"\"\"\n",
        "        print(\"üîß Setting up runtime environment...\")\n",
        "\n",
        "        # Fix environment variables for headless operation\n",
        "        env_fixes = {\n",
        "            'XDG_RUNTIME_DIR': '/tmp/runtime-root',\n",
        "            'ALSA_CARD': 'null',\n",
        "            'PULSE_SERVER': 'unix:/dev/null',\n",
        "            'MPLBACKEND': 'Agg',\n",
        "            'MATPLOTLIB_BACKEND': 'Agg'\n",
        "        }\n",
        "\n",
        "        for key, value in env_fixes.items():\n",
        "            os.environ[key] = value\n",
        "            print(f\"   ‚úÖ {key} = {value}\")\n",
        "\n",
        "        # Create runtime directory\n",
        "        os.makedirs('/tmp/runtime-root', exist_ok=True)\n",
        "\n",
        "        print(\"‚úÖ Runtime environment configured for headless operation\")\n",
        "        return True\n",
        "\n",
        "    def show_launch_options(self):\n",
        "        \"\"\"Display launch options with public link information\"\"\"\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                   color: white; padding: 20px; border-radius: 10px; text-align: center;\n",
        "                   margin: 10px 0; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "            <h2>üöÄ WAN2GP Launch Options</h2>\n",
        "            <p><strong>Platform:</strong> {self.current_platform}</p>\n",
        "            <p><strong>Python Command:</strong> {self.python_cmd}</p>\n",
        "            <p>Includes <strong>--share</strong> flag for public Gradio link generation</p>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "        print(\"üéØ WAN2GP Model Selection (with Public Gradio Link):\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        for key, config in self.model_options.items():\n",
        "            print(f\"{key}. {config['name']}\")\n",
        "            print(f\"   VRAM: {config['vram']} | Speed: {config['speed']}\")\n",
        "            print(f\"   {config['description']}\")\n",
        "            print()\n",
        "\n",
        "        print(\"üîß Performance Optimization Options:\")\n",
        "        print(\"=\" * 40)\n",
        "        for key, config in self.performance_options.items():\n",
        "            print(f\"{key}. {config['name']}\")\n",
        "            print(f\"   {config['description']}\")\n",
        "            print()\n",
        "\n",
        "        # Get user selections\n",
        "        model_choice = input(\"üéØ Select model (1-6, or Enter for default Wan T2V 1.3B): \").strip()\n",
        "        perf_choice = input(\"‚ö° Select performance (A-C, or Enter for Low VRAM): \").strip().upper()\n",
        "\n",
        "        # Process selections\n",
        "        if model_choice in self.model_options:\n",
        "            selected_model = self.model_options[model_choice]\n",
        "            model_flag = selected_model[\"flag\"]\n",
        "            model_name = selected_model[\"name\"]\n",
        "        else:\n",
        "            model_flag = \"--t2v-1-3B\"\n",
        "            model_name = \"Wan 2.1 Text2Video 1.3B (default)\"\n",
        "\n",
        "        if perf_choice in self.performance_options:\n",
        "            perf_config = self.performance_options[perf_choice]\n",
        "            perf_args = perf_config[\"args\"]\n",
        "            perf_name = perf_config[\"name\"]\n",
        "        else:\n",
        "            perf_args = [\"--profile\", \"4\", \"--attention\", \"sdpa\"]\n",
        "            perf_name = \"Low VRAM Mode (default)\"\n",
        "\n",
        "        return model_flag, model_name, perf_args, perf_name\n",
        "\n",
        "    def launch_wan2gp_with_public_link(self, model_flag, model_name, perf_args, perf_name):\n",
        "        \"\"\"Launch WAN2GP with public Gradio link and comprehensive error handling\"\"\"\n",
        "        print(\"üöÄ Launching WAN2GP with Public Gradio Link...\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Platform: {self.current_platform}\")\n",
        "        print(f\"Python Command: {self.python_cmd}\")\n",
        "        print(f\"Selected Model: {model_name}\")\n",
        "        print(f\"Performance Mode: {perf_name}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Final enforcement check per system instructions\n",
        "        if self.current_platform == \"Google Colab\" and not self.use_venv:\n",
        "            print(\"üö® FATAL: Google Colab not using venv per system instructions - ABORTING\")\n",
        "            return False\n",
        "\n",
        "        # Setup runtime environment\n",
        "        self.setup_runtime_environment()\n",
        "\n",
        "        # Verify we're in the correct directory\n",
        "        if not os.path.exists(\"wgp.py\"):\n",
        "            print(\"‚ùå wgp.py not found. Make sure you're in the Wan2GP directory.\")\n",
        "            print(f\"üìç Current directory: {os.getcwd()}\")\n",
        "            return False\n",
        "\n",
        "        # Build launch command with public link support from CLI documentation[5][13]\n",
        "        base_cmd = [\n",
        "            self.python_cmd,\n",
        "            \"wgp.py\",\n",
        "            model_flag,\n",
        "            \"--share\",        # Creates public HuggingFace URL per documentation[5]\n",
        "            \"--listen\",       # Make server accessible on network\n",
        "            \"--server-port\", \"7860\"\n",
        "        ]\n",
        "\n",
        "        # Add performance arguments\n",
        "        base_cmd.extend(perf_args)\n",
        "\n",
        "        # Add stability arguments from troubleshooting guide[8][16]\n",
        "        stability_args = [\n",
        "            \"--verbose\", \"1\"  # Moderate verbosity for monitoring\n",
        "        ]\n",
        "        base_cmd.extend(stability_args)\n",
        "\n",
        "        print(f\"üéØ Launch command: {' '.join(base_cmd)}\")\n",
        "        print()\n",
        "        print(\"üîÑ Starting WAN2GP...\")\n",
        "        print(\"üåê Local interface: http://localhost:7860\")\n",
        "        print(\"üîó Public Gradio link will be generated and displayed below\")\n",
        "        print(\"‚èπÔ∏è Press Ctrl+C in this cell to stop WAN2GP\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        try:\n",
        "            # Launch WAN2GP with real-time output monitoring\n",
        "            process = subprocess.Popen(\n",
        "                base_cmd,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.STDOUT,\n",
        "                universal_newlines=True,\n",
        "                bufsize=1\n",
        "            )\n",
        "\n",
        "            gradio_link_found = False\n",
        "            start_time = time.time()\n",
        "            output_lines = []\n",
        "\n",
        "            print(\"üìã WAN2GP Output:\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # Monitor output for important information\n",
        "            while True:\n",
        "                output = process.stdout.readline()\n",
        "                if output == '' and process.poll() is not None:\n",
        "                    break\n",
        "\n",
        "                if output:\n",
        "                    line = output.strip()\n",
        "                    print(line)\n",
        "                    output_lines.append(line)\n",
        "\n",
        "                    # Detect and highlight public Gradio link\n",
        "                    if \"Running on public URL:\" in line and not gradio_link_found:\n",
        "                        gradio_link_found = True\n",
        "                        # Extract URL\n",
        "                        url = line.split(\"Running on public URL:\")[-1].strip()\n",
        "\n",
        "                        # Display prominent link notification\n",
        "                        display(HTML(f\"\"\"\n",
        "                        <div style=\"background: linear-gradient(90deg, #00ff41, #00d4ff);\n",
        "                                    padding: 20px; border-radius: 15px; margin: 15px 0;\n",
        "                                    border: 3px solid #00ff41; text-align: center;\n",
        "                                    box-shadow: 0 8px 25px rgba(0,255,65,0.3);\">\n",
        "                            <h2 style=\"color: #000; margin: 0; font-size: 24px;\">\n",
        "                                üåê PUBLIC GRADIO LINK READY!\n",
        "                            </h2>\n",
        "                            <p style=\"color: #000; margin: 10px 0; font-size: 18px;\">\n",
        "                                <strong>Click here to access WAN2GP remotely:</strong>\n",
        "                            </p>\n",
        "                            <div style=\"background: white; padding: 15px; border-radius: 10px;\n",
        "                                        margin: 10px 0; border: 2px solid #000;\">\n",
        "                                <a href=\"{url}\" target=\"_blank\"\n",
        "                                   style=\"color: #000; font-weight: bold; font-size: 20px;\n",
        "                                          text-decoration: none;\">\n",
        "                                    {url}\n",
        "                                </a>\n",
        "                            </div>\n",
        "                            <p style=\"color: #000; margin: 5px 0; font-size: 14px;\">\n",
        "                                üïí Link expires in 72 hours ‚Ä¢ üîó Right-click to copy\n",
        "                            </p>\n",
        "                        </div>\n",
        "                        \"\"\"))\n",
        "\n",
        "                    # Monitor for successful startup indicators\n",
        "                    if \"Running on local URL:\" in line:\n",
        "                        print(\"‚úÖ Local server started successfully\")\n",
        "\n",
        "                    # Monitor for model loading\n",
        "                    if \"Loading model\" in line or \"Model loaded\" in line:\n",
        "                        print(\"üì¶ Model loading detected...\")\n",
        "\n",
        "                    # Filter harmless warnings but continue execution\n",
        "                    harmless_warnings = [\n",
        "                        \"xdg_runtime_dir\", \"alsa lib\", \"unknown pcm\",\n",
        "                        \"no such file or directory\", \"switching to fp16\"\n",
        "                    ]\n",
        "\n",
        "                    if any(warning in line.lower() for warning in harmless_warnings):\n",
        "                        continue  # Don't treat as errors\n",
        "\n",
        "                # Timeout check (10 minutes for initial startup)\n",
        "                if time.time() - start_time > 600:\n",
        "                    print(\"‚ö†Ô∏è Startup timeout reached (10 minutes)\")\n",
        "                    print(\"üîç Check output above for any error messages\")\n",
        "                    break\n",
        "\n",
        "            # Final status check\n",
        "            if not gradio_link_found:\n",
        "                print(\"\\n‚ö†Ô∏è Public Gradio link not detected in output\")\n",
        "                print(\"üîç WAN2GP may still be accessible locally at: http://localhost:7860\")\n",
        "                print(\"üí° Check the output above for any error messages\")\n",
        "\n",
        "            # Keep process running until interrupted\n",
        "            try:\n",
        "                print(\"\\n‚è∏Ô∏è WAN2GP is running. Press Ctrl+C to stop...\")\n",
        "                process.wait()\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\n‚èπÔ∏è Stopping WAN2GP...\")\n",
        "                process.terminate()\n",
        "                # Give process time to clean up\n",
        "                try:\n",
        "                    process.wait(timeout=5)\n",
        "                except subprocess.TimeoutExpired:\n",
        "                    process.kill()\n",
        "                print(\"‚úÖ WAN2GP stopped successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error launching WAN2GP: {e}\")\n",
        "            print(\"\\nüîß Troubleshooting suggestions:\")\n",
        "            print(\"1. Verify models were downloaded in Cell 3\")\n",
        "            print(\"2. Check that wgp.py exists in current directory\")\n",
        "            print(\"3. Try the emergency fallback command below\")\n",
        "            print(\"\\nüÜò Emergency fallback command:\")\n",
        "            print(f\"{self.python_cmd} wgp.py --t2v-1-3B --attention sdpa --profile 4\")\n",
        "            return False\n",
        "\n",
        "        return gradio_link_found\n",
        "\n",
        "# Create launcher instance\n",
        "launcher = WAN2GPLauncher()\n",
        "\n",
        "# Show options and get user selections\n",
        "model_flag, model_name, perf_args, perf_name = launcher.show_launch_options()\n",
        "\n",
        "# Launch WAN2GP with selected configuration\n",
        "success = launcher.launch_wan2gp_with_public_link(model_flag, model_name, perf_args, perf_name)\n",
        "\n",
        "if success:\n",
        "    print(\"\\nüéâ WAN2GP launch completed successfully!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Launch encountered issues - check output above for details\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GU-zDsAW_MwT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "outputId": "f2d02259-cecc-4fb1-9224-2768f46e3c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ VERIFIED: Launch system correctly using venv for Colab\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
              "                   color: white; padding: 20px; border-radius: 10px; text-align: center; \n",
              "                   margin: 10px 0; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "            <h2>üöÄ WAN2GP Launch Options</h2>\n",
              "            <p><strong>Platform:</strong> Google Colab</p>\n",
              "            <p><strong>Python Command:</strong> .venv/bin/python</p>\n",
              "            <p>Includes <strong>--share</strong> flag for public Gradio link generation</p>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ WAN2GP Model Selection (with Public Gradio Link):\n",
            "======================================================================\n",
            "1. Wan 2.1 Text2Video 1.3B\n",
            "   VRAM: 6GB | Speed: Fast\n",
            "   Fast generation, lower VRAM\n",
            "\n",
            "2. Wan 2.1 Text2Video 14B\n",
            "   VRAM: 12GB | Speed: Slower\n",
            "   High quality, more VRAM\n",
            "\n",
            "3. Wan Fun InP 1.3B\n",
            "   VRAM: 6GB | Speed: Fast\n",
            "   Image-to-video, fast\n",
            "\n",
            "4. Wan 2.1 Image2Video 14B\n",
            "   VRAM: 12GB | Speed: Slower\n",
            "   High quality I2V\n",
            "\n",
            "5. Wan Vace 1.3B\n",
            "   VRAM: 6GB | Speed: Fast\n",
            "   ControlNet, motion transfer\n",
            "\n",
            "6. Wan Vace 14B\n",
            "   VRAM: 12GB | Speed: Slower\n",
            "   Advanced ControlNet features\n",
            "\n",
            "üîß Performance Optimization Options:\n",
            "========================================\n",
            "A. Low VRAM Mode\n",
            "   Memory efficient, stable (RTX 10XX-20XX)\n",
            "\n",
            "B. High Performance Mode\n",
            "   Fast generation (RTX 30XX-40XX)\n",
            "\n",
            "C. Emergency Fallback\n",
            "   Maximum compatibility\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (1) - WAN2GP Comprehensive Diagnostic and Auto-Repair System (Latest v6.2 Compatible)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import importlib.util\n",
        "\n",
        "class WAN2GPDiagnosticAndRepair:\n",
        "    def __init__(self):\n",
        "        self.platform = self.detect_platform()\n",
        "        self.pip_cmd, self.python_cmd, self.use_venv = self.get_platform_commands()\n",
        "        self.issues_found = []\n",
        "        self.repairs_applied = []\n",
        "        self.gpu_info = {}\n",
        "\n",
        "    def detect_platform(self):\n",
        "        \"\"\"Enhanced platform detection with comprehensive indicators\"\"\"\n",
        "        # Lightning AI detection - multiple indicators for reliability\n",
        "        lightning_indicators = [\n",
        "            \"lightning\" in str(sys.executable).lower(),\n",
        "            \"teamspace-studios\" in os.getcwd(),\n",
        "            \"LIGHTNING_CLOUDSPACE_HOST\" in os.environ,\n",
        "            \"LIGHTNING_CLOUDSPACE_ID\" in os.environ,\n",
        "            \"/commands/python\" in str(sys.executable),\n",
        "            \"/home/zeus/miniconda3/envs/cloudspace\" in str(sys.executable),\n",
        "            os.path.exists(\"/teamspace\"),\n",
        "            os.path.exists(\"/commands\")\n",
        "        ]\n",
        "\n",
        "        # Google Colab detection\n",
        "        colab_indicators = [\n",
        "            \"google.colab\" in sys.modules,\n",
        "            \"/content\" in os.getcwd()\n",
        "        ]\n",
        "\n",
        "        # Vast.AI detection\n",
        "        vast_indicators = [\n",
        "            \"VAST_CONTAINER_LABEL\" in os.environ,\n",
        "            \"/workspace\" in os.getcwd(),\n",
        "            \"vast\" in os.environ.get(\"HOSTNAME\", \"\").lower()\n",
        "        ]\n",
        "\n",
        "        if any(lightning_indicators):\n",
        "            return \"Lightning AI\"\n",
        "        elif any(colab_indicators):\n",
        "            return \"Google Colab\"\n",
        "        elif any(vast_indicators):\n",
        "            return \"Vast.AI/Generic\"\n",
        "        else:\n",
        "            return \"Vast.AI/Generic\"\n",
        "\n",
        "    def get_platform_commands(self):\n",
        "        \"\"\"Get platform-specific pip and python commands\"\"\"\n",
        "        if self.platform == \"Lightning AI\":\n",
        "            return \"pip\", \"python\", False  # (pip_cmd, python_cmd, use_venv)\n",
        "        elif self.platform == \"Google Colab\":\n",
        "            return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "        else:  # Vast.AI/Generic\n",
        "            return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "    def run_command_safely(self, command, description, timeout=60):\n",
        "        \"\"\"Execute command with comprehensive error handling\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                command, capture_output=True, text=True, timeout=timeout, shell=isinstance(command, str)\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                return True, result.stdout\n",
        "            else:\n",
        "                return False, result.stderr\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, f\"Timeout after {timeout}s\"\n",
        "        except Exception as e:\n",
        "            return False, str(e)\n",
        "\n",
        "    def check_gpu_compatibility(self):\n",
        "        \"\"\"Comprehensive GPU detection and compatibility check\"\"\"\n",
        "        print(\"üîç Checking GPU compatibility...\")\n",
        "\n",
        "        # Check NVIDIA GPU presence\n",
        "        success, output = self.run_command_safely(\"nvidia-smi\", \"GPU Detection\")\n",
        "        if not success:\n",
        "            self.issues_found.append(\"No NVIDIA GPU detected or nvidia-smi not available\")\n",
        "            return False\n",
        "\n",
        "        # Parse GPU info\n",
        "        try:\n",
        "            # Extract GPU name and VRAM from nvidia-smi output\n",
        "            lines = output.split('\\n')\n",
        "            for line in lines:\n",
        "                if 'RTX' in line or 'GTX' in line or 'Tesla' in line or 'A100' in line:\n",
        "                    gpu_name = line.split('|')[1].strip() if '|' in line else \"Unknown GPU\"\n",
        "                    self.gpu_info['name'] = gpu_name\n",
        "                    break\n",
        "\n",
        "            # Check VRAM\n",
        "            for line in lines:\n",
        "                if 'MiB' in line and '/' in line:\n",
        "                    vram_info = [part for part in line.split() if 'MiB' in part]\n",
        "                    if len(vram_info) >= 2:\n",
        "                        total_vram = int(vram_info[-1].replace('MiB', ''))\n",
        "                        self.gpu_info['vram_mb'] = total_vram\n",
        "                        self.gpu_info['vram_gb'] = total_vram / 1024\n",
        "                        break\n",
        "\n",
        "            print(f\"‚úÖ GPU detected: {self.gpu_info.get('name', 'Unknown')}\")\n",
        "            print(f\"‚úÖ VRAM: {self.gpu_info.get('vram_gb', 0):.1f}GB\")\n",
        "\n",
        "            # Check VRAM adequacy\n",
        "            vram_gb = self.gpu_info.get('vram_gb', 0)\n",
        "            if vram_gb < 6:\n",
        "                self.issues_found.append(f\"Low VRAM detected ({vram_gb:.1f}GB). Minimum 6GB recommended.\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.issues_found.append(f\"GPU info parsing failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def check_cuda_pytorch_compatibility(self):\n",
        "        \"\"\"Check CUDA and PyTorch compatibility\"\"\"\n",
        "        print(\"üîç Checking CUDA and PyTorch compatibility...\")\n",
        "\n",
        "        # Check CUDA version\n",
        "        success, cuda_output = self.run_command_safely(\"nvcc --version\", \"CUDA Version Check\")\n",
        "        if not success:\n",
        "            success, cuda_output = self.run_command_safely(\"nvidia-smi\", \"CUDA Runtime Check\")\n",
        "\n",
        "        # Check PyTorch installation\n",
        "        try:\n",
        "            import torch\n",
        "            pytorch_version = torch.__version__\n",
        "            cuda_available = torch.cuda.is_available()\n",
        "\n",
        "            print(f\"‚úÖ PyTorch version: {pytorch_version}\")\n",
        "            print(f\"‚úÖ CUDA available in PyTorch: {cuda_available}\")\n",
        "\n",
        "            if not cuda_available:\n",
        "                self.issues_found.append(\"PyTorch cannot detect CUDA\")\n",
        "                return False\n",
        "\n",
        "            # Check for version compatibility\n",
        "            if \"50\" in self.gpu_info.get('name', '') and not pytorch_version.startswith('2.7'):\n",
        "                self.issues_found.append(\"RTX 50XX series requires PyTorch 2.7.0 or newer\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except ImportError:\n",
        "            self.issues_found.append(\"PyTorch not installed\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            self.issues_found.append(f\"PyTorch check failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def check_python_version(self):\n",
        "        \"\"\"Check Python version compatibility\"\"\"\n",
        "        print(\"üîç Checking Python version...\")\n",
        "\n",
        "        python_version = sys.version_info\n",
        "        version_string = f\"{python_version.major}.{python_version.minor}.{python_version.micro}\"\n",
        "        print(f\"‚úÖ Python version: {version_string}\")\n",
        "\n",
        "        if python_version.major != 3 or python_version.minor != 10:\n",
        "            self.issues_found.append(f\"Python {version_string} detected. Python 3.10.9 recommended for best compatibility.\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def check_wan2gp_installation(self):\n",
        "        \"\"\"Check WAN2GP installation and repository\"\"\"\n",
        "        print(\"üîç Checking WAN2GP installation...\")\n",
        "\n",
        "        wan2gp_paths = [\"Wan2GP\", \"wan2gp\", \"WAN2GP\", \"../Wan2GP\", \"../wan2gp\"]\n",
        "        wan2gp_found = False\n",
        "\n",
        "        for path in wan2gp_paths:\n",
        "            if os.path.exists(path):\n",
        "                wan2gp_found = True\n",
        "                wgp_py_path = os.path.join(path, \"wgp.py\")\n",
        "                if os.path.exists(wgp_py_path):\n",
        "                    print(f\"‚úÖ WAN2GP found at: {path}\")\n",
        "                    return True\n",
        "                break\n",
        "\n",
        "        if not wan2gp_found:\n",
        "            self.issues_found.append(\"WAN2GP repository not found\")\n",
        "            return False\n",
        "\n",
        "        self.issues_found.append(\"WAN2GP repository found but wgp.py missing\")\n",
        "        return False\n",
        "\n",
        "    def check_dependencies(self):\n",
        "        \"\"\"Check critical dependencies\"\"\"\n",
        "        print(\"üîç Checking critical dependencies...\")\n",
        "\n",
        "        critical_deps = {\n",
        "            'torch': 'PyTorch',\n",
        "            'torchvision': 'TorchVision',\n",
        "            'gradio': 'Gradio',\n",
        "            'transformers': 'Transformers',\n",
        "            'accelerate': 'Accelerate',\n",
        "            'diffusers': 'Diffusers'\n",
        "        }\n",
        "\n",
        "        missing_deps = []\n",
        "        for dep, name in critical_deps.items():\n",
        "            try:\n",
        "                importlib.import_module(dep)\n",
        "                print(f\"‚úÖ {name} installed\")\n",
        "            except ImportError:\n",
        "                missing_deps.append(dep)\n",
        "                print(f\"‚ùå {name} missing\")\n",
        "\n",
        "        if missing_deps:\n",
        "            self.issues_found.append(f\"Missing dependencies: {', '.join(missing_deps)}\")\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def check_attention_mechanisms(self):\n",
        "        \"\"\"Check available attention mechanisms\"\"\"\n",
        "        print(\"üîç Checking attention mechanisms...\")\n",
        "\n",
        "        attention_status = {}\n",
        "\n",
        "        # Check Triton\n",
        "        try:\n",
        "            import triton\n",
        "            attention_status['triton'] = f\"‚úÖ Triton {triton.__version__}\"\n",
        "        except ImportError:\n",
        "            attention_status['triton'] = \"‚ùå Triton not available\"\n",
        "\n",
        "        # Check SageAttention\n",
        "        try:\n",
        "            import sageattention\n",
        "            attention_status['sage'] = \"‚úÖ SageAttention available\"\n",
        "        except ImportError:\n",
        "            attention_status['sage'] = \"‚ùå SageAttention not available\"\n",
        "\n",
        "        # Check Flash Attention\n",
        "        try:\n",
        "            import flash_attn\n",
        "            attention_status['flash'] = \"‚úÖ Flash Attention available\"\n",
        "        except ImportError:\n",
        "            attention_status['flash'] = \"‚ùå Flash Attention not available\"\n",
        "\n",
        "        for mech, status in attention_status.items():\n",
        "            print(f\"  {status}\")\n",
        "\n",
        "        # Recommend fallback if advanced attention not available\n",
        "        if all(\"‚ùå\" in status for status in attention_status.values()):\n",
        "            self.issues_found.append(\"No advanced attention mechanisms available. Will use SDPA fallback.\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def check_memory_and_performance(self):\n",
        "        \"\"\"Check memory and performance configuration\"\"\"\n",
        "        print(\"üîç Checking memory and performance...\")\n",
        "\n",
        "        # Check available system RAM\n",
        "        try:\n",
        "            import psutil\n",
        "            ram_gb = psutil.virtual_memory().total / (1024**3)\n",
        "            print(f\"‚úÖ System RAM: {ram_gb:.1f}GB\")\n",
        "\n",
        "            if ram_gb < 16:\n",
        "                self.issues_found.append(f\"Low system RAM ({ram_gb:.1f}GB). 16GB+ recommended for best performance.\")\n",
        "        except ImportError:\n",
        "            print(\"‚ö†Ô∏è Cannot check system RAM (psutil not available)\")\n",
        "\n",
        "        # Check disk space\n",
        "        try:\n",
        "            disk_usage = shutil.disk_usage(os.getcwd())\n",
        "            free_gb = disk_usage.free / (1024**3)\n",
        "            print(f\"‚úÖ Free disk space: {free_gb:.1f}GB\")\n",
        "\n",
        "            if free_gb < 20:\n",
        "                self.issues_found.append(f\"Low disk space ({free_gb:.1f}GB). 20GB+ recommended.\")\n",
        "        except Exception:\n",
        "            print(\"‚ö†Ô∏è Cannot check disk space\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def auto_repair_pytorch(self):\n",
        "        \"\"\"Auto-repair PyTorch installation\"\"\"\n",
        "        print(\"üîß Attempting PyTorch repair...\")\n",
        "\n",
        "        # Determine correct PyTorch version based on GPU\n",
        "        if \"50\" in self.gpu_info.get('name', ''):\n",
        "            # RTX 50XX series\n",
        "            pytorch_cmd = [\n",
        "                self.pip_cmd, \"install\", \"--upgrade\",\n",
        "                \"torch==2.7.0\", \"torchvision\", \"torchaudio\",\n",
        "                \"--index-url\", \"https://download.pytorch.org/whl/test/cu128\"\n",
        "            ]\n",
        "        else:\n",
        "            # RTX 10XX-40XX series\n",
        "            pytorch_cmd = [\n",
        "                self.pip_cmd, \"install\", \"--upgrade\",\n",
        "                \"torch==2.6.0\", \"torchvision\", \"torchaudio\",\n",
        "                \"--index-url\", \"https://download.pytorch.org/whl/test/cu124\"\n",
        "            ]\n",
        "\n",
        "        success, output = self.run_command_safely(pytorch_cmd, \"PyTorch Installation\", timeout=300)\n",
        "        if success:\n",
        "            self.repairs_applied.append(\"PyTorch installation repaired\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå PyTorch repair failed: {output}\")\n",
        "            return False\n",
        "\n",
        "    def auto_repair_dependencies(self):\n",
        "        \"\"\"Auto-repair missing dependencies\"\"\"\n",
        "        print(\"üîß Installing missing dependencies...\")\n",
        "\n",
        "        # Install core requirements\n",
        "        requirements_cmd = [self.pip_cmd, \"install\", \"-r\", \"requirements.txt\"]\n",
        "        success, output = self.run_command_safely(requirements_cmd, \"Dependencies Installation\", timeout=300)\n",
        "\n",
        "        if success:\n",
        "            self.repairs_applied.append(\"Dependencies installed\")\n",
        "            return True\n",
        "        else:\n",
        "            # Fallback: install critical packages individually\n",
        "            critical_packages = [\n",
        "                \"gradio>=4.0.0\", \"transformers\", \"accelerate\", \"diffusers\",\n",
        "                \"opencv-python\", \"Pillow\", \"numpy\", \"scipy\"\n",
        "            ]\n",
        "\n",
        "            for package in critical_packages:\n",
        "                cmd = [self.pip_cmd, \"install\", package]\n",
        "                success, _ = self.run_command_safely(cmd, f\"Installing {package}\", timeout=60)\n",
        "                if success:\n",
        "                    print(f\"‚úÖ Installed {package}\")\n",
        "\n",
        "            self.repairs_applied.append(\"Critical dependencies installed individually\")\n",
        "            return True\n",
        "\n",
        "    def auto_repair_wan2gp_repo(self):\n",
        "        \"\"\"Auto-repair WAN2GP repository\"\"\"\n",
        "        print(\"üîß Cloning WAN2GP repository...\")\n",
        "\n",
        "        repo_url = \"https://github.com/deepbeepmeep/Wan2GP.git\"\n",
        "        clone_cmd = [\"git\", \"clone\", \"--depth\", \"1\", repo_url]\n",
        "\n",
        "        success, output = self.run_command_safely(clone_cmd, \"Repository Clone\", timeout=120)\n",
        "        if success:\n",
        "            self.repairs_applied.append(\"WAN2GP repository cloned\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå Repository clone failed: {output}\")\n",
        "            return False\n",
        "\n",
        "    def auto_repair_attention_mechanisms(self):\n",
        "        \"\"\"Auto-repair attention mechanisms\"\"\"\n",
        "        print(\"üîß Installing performance optimizations...\")\n",
        "\n",
        "        repairs = []\n",
        "\n",
        "        # Install Triton for Windows\n",
        "        if os.name == 'nt':  # Windows\n",
        "            triton_cmd = [self.pip_cmd, \"install\", \"triton-windows\"]\n",
        "            success, _ = self.run_command_safely(triton_cmd, \"Triton Installation\", timeout=120)\n",
        "            if success:\n",
        "                repairs.append(\"Triton (Windows)\")\n",
        "\n",
        "        # Install SageAttention\n",
        "        sage_cmd = [self.pip_cmd, \"install\", \"sageattention>=1.0.6\"]\n",
        "        success, _ = self.run_command_safely(sage_cmd, \"SageAttention Installation\", timeout=120)\n",
        "        if success:\n",
        "            repairs.append(\"SageAttention\")\n",
        "\n",
        "        if repairs:\n",
        "            self.repairs_applied.append(f\"Installed: {', '.join(repairs)}\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def generate_optimized_launch_commands(self):\n",
        "        \"\"\"Generate optimized launch commands based on hardware\"\"\"\n",
        "        print(\"\\nüöÄ Generating optimized launch commands...\")\n",
        "\n",
        "        vram_gb = self.gpu_info.get('vram_gb', 8)\n",
        "        gpu_name = self.gpu_info.get('name', 'Unknown')\n",
        "\n",
        "        commands = {}\n",
        "\n",
        "        # Base command components\n",
        "        base_cmd = \"python wgp.py\"\n",
        "\n",
        "        if vram_gb < 8:\n",
        "            # Low VRAM setup\n",
        "            commands['Low VRAM (6-8GB)'] = f\"{base_cmd} --t2v-1-3B --attention sdpa --profile 4 --teacache 1.5\"\n",
        "        elif vram_gb < 12:\n",
        "            # Medium VRAM setup\n",
        "            commands['Medium VRAM (8-12GB)'] = f\"{base_cmd} --t2v-14B --attention sage --profile 4 --teacache 2.0\"\n",
        "        else:\n",
        "            # High VRAM setup\n",
        "            commands['High VRAM (12GB+)'] = f\"{base_cmd} --t2v-14B --attention sage2 --profile 3 --compile --teacache 2.0\"\n",
        "\n",
        "        # GPU-specific optimizations\n",
        "        if \"10\" in gpu_name or \"20\" in gpu_name:\n",
        "            commands['RTX 10XX/20XX Optimized'] = f\"{base_cmd} --attention sdpa --profile 4 --teacache 1.5\"\n",
        "        elif \"30\" in gpu_name or \"40\" in gpu_name:\n",
        "            commands['RTX 30XX/40XX Optimized'] = f\"{base_cmd} --compile --attention sage --profile 3 --teacache 2.0\"\n",
        "        elif \"50\" in gpu_name:\n",
        "            commands['RTX 50XX Optimized'] = f\"{base_cmd} --attention sage --profile 4 --fp16\"\n",
        "\n",
        "        # Fallback command\n",
        "        commands['Safe Fallback'] = f\"{base_cmd} --t2v-1-3B --attention sdpa --profile 4 --teacache 0 --fp16\"\n",
        "\n",
        "        # Debug command\n",
        "        commands['Debug Mode'] = f\"{base_cmd} --verbose 2 --check-loras --attention sdpa --profile 4\"\n",
        "\n",
        "        return commands\n",
        "\n",
        "    def run_full_diagnostic(self):\n",
        "        \"\"\"Run complete diagnostic and repair sequence\"\"\"\n",
        "        print(\"üè• WAN2GP Comprehensive Diagnostic and Auto-Repair System\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"üñ•Ô∏è Platform: {self.platform}\")\n",
        "        print(f\"üêç Python: {self.python_cmd}\")\n",
        "        print(f\"üì¶ Pip: {self.pip_cmd}\")\n",
        "        print(f\"üîß Virtual Environment: {'Yes' if self.use_venv else 'No'}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Run all diagnostics\n",
        "        checks = [\n",
        "            self.check_python_version,\n",
        "            self.check_gpu_compatibility,\n",
        "            self.check_cuda_pytorch_compatibility,\n",
        "            self.check_wan2gp_installation,\n",
        "            self.check_dependencies,\n",
        "            self.check_attention_mechanisms,\n",
        "            self.check_memory_and_performance\n",
        "        ]\n",
        "\n",
        "        print(\"\\nüìã Running Diagnostics...\")\n",
        "        for check in checks:\n",
        "            try:\n",
        "                check()\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Diagnostic error: {str(e)}\")\n",
        "                self.issues_found.append(f\"Diagnostic error: {str(e)}\")\n",
        "\n",
        "        # Auto-repair if issues found\n",
        "        if self.issues_found:\n",
        "            print(f\"\\n‚ö†Ô∏è Found {len(self.issues_found)} issues:\")\n",
        "            for i, issue in enumerate(self.issues_found, 1):\n",
        "                print(f\"  {i}. {issue}\")\n",
        "\n",
        "            print(f\"\\nüîß Attempting automatic repairs...\")\n",
        "\n",
        "            # Apply repairs based on issues found\n",
        "            if any(\"PyTorch\" in issue for issue in self.issues_found):\n",
        "                self.auto_repair_pytorch()\n",
        "\n",
        "            if any(\"dependencies\" in issue.lower() for issue in self.issues_found):\n",
        "                self.auto_repair_dependencies()\n",
        "\n",
        "            if any(\"repository\" in issue.lower() for issue in self.issues_found):\n",
        "                self.auto_repair_wan2gp_repo()\n",
        "\n",
        "            if any(\"attention\" in issue.lower() for issue in self.issues_found):\n",
        "                self.auto_repair_attention_mechanisms()\n",
        "\n",
        "        # Generate launch commands\n",
        "        commands = self.generate_optimized_launch_commands()\n",
        "\n",
        "        # Final report\n",
        "        self.display_final_report(commands)\n",
        "\n",
        "    def display_final_report(self, commands):\n",
        "        \"\"\"Display comprehensive final report\"\"\"\n",
        "\n",
        "        # Create styled HTML report\n",
        "        html_report = f\"\"\"\n",
        "        <div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                    color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n",
        "            <h2>üè• WAN2GP Diagnostic Report</h2>\n",
        "            <div style=\"background-color: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "                <h3>üìä System Status</h3>\n",
        "                <p><strong>Platform:</strong> {self.platform}</p>\n",
        "                <p><strong>GPU:</strong> {self.gpu_info.get('name', 'Unknown')} ({self.gpu_info.get('vram_gb', 0):.1f}GB VRAM)</p>\n",
        "                <p><strong>Issues Found:</strong> {len(self.issues_found)}</p>\n",
        "                <p><strong>Repairs Applied:</strong> {len(self.repairs_applied)}</p>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        if self.repairs_applied:\n",
        "            html_report += f\"\"\"\n",
        "            <div style=\"background-color: #28a745; color: white; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "                <h3>‚úÖ Repairs Applied Successfully:</h3>\n",
        "                <ul>\n",
        "            \"\"\"\n",
        "            for repair in self.repairs_applied:\n",
        "                html_report += f\"<li>{repair}</li>\"\n",
        "            html_report += \"</ul></div>\"\n",
        "\n",
        "        if self.issues_found and not self.repairs_applied:\n",
        "            html_report += f\"\"\"\n",
        "            <div style=\"background-color: #dc3545; color: white; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "                <h3>‚ö†Ô∏è Unresolved Issues:</h3>\n",
        "                <ul>\n",
        "            \"\"\"\n",
        "            for issue in self.issues_found:\n",
        "                html_report += f\"<li>{issue}</li>\"\n",
        "            html_report += \"</ul></div>\"\n",
        "\n",
        "        display(HTML(html_report))\n",
        "\n",
        "        # Display optimized commands\n",
        "        print(\"\\nüöÄ Recommended Launch Commands:\")\n",
        "        print(\"=\" * 50)\n",
        "        for name, command in commands.items():\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  {command}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"‚úÖ Diagnostic complete! Use the appropriate command above to launch WAN2GP.\")\n",
        "        if self.issues_found and not self.repairs_applied:\n",
        "            print(\"‚ö†Ô∏è  Some issues require manual intervention. Check the report above.\")\n",
        "\n",
        "# Execute diagnostic system\n",
        "diagnostic_system = WAN2GPDiagnosticAndRepair()\n",
        "diagnostic_system.run_full_diagnostic()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZzJeUGqaCLJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (2) - Quick Diagnostic Runner and Emergency Repair Tools (Latest v6.2)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "class QuickDiagnosticRunner:\n",
        "    def __init__(self):\n",
        "        self.platform = self.detect_platform()\n",
        "        self.pip_cmd, self.python_cmd = self.get_platform_commands()\n",
        "\n",
        "    def detect_platform(self):\n",
        "        \"\"\"Quick platform detection\"\"\"\n",
        "        if \"google.colab\" in sys.modules:\n",
        "            return \"Google Colab\"\n",
        "        elif any(indicator in str(sys.executable).lower() for indicator in [\"lightning\", \"teamspace\"]):\n",
        "            return \"Lightning AI\"\n",
        "        else:\n",
        "            return \"Generic/Vast.AI\"\n",
        "\n",
        "    def get_platform_commands(self):\n",
        "        \"\"\"Get platform-specific commands\"\"\"\n",
        "        if self.platform == \"Lightning AI\":\n",
        "            return \"pip\", \"python\"\n",
        "        else:\n",
        "            return \".venv/bin/pip\" if os.path.exists(\".venv\") else \"pip\", \".venv/bin/python\" if os.path.exists(\".venv\") else \"python\"\n",
        "\n",
        "    def run_cmd(self, cmd, timeout=30):\n",
        "        \"\"\"Execute command safely\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)\n",
        "            return result.returncode == 0, result.stdout, result.stderr\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, \"\", \"Timeout\"\n",
        "        except Exception as e:\n",
        "            return False, \"\", str(e)\n",
        "\n",
        "    def emergency_pytorch_fix(self):\n",
        "        \"\"\"Emergency PyTorch installation fix\"\"\"\n",
        "        print(\"üö® Emergency PyTorch Fix...\")\n",
        "\n",
        "        # Detect GPU generation for correct PyTorch version\n",
        "        success, gpu_info, _ = self.run_cmd(\"nvidia-smi\")\n",
        "\n",
        "        if \"RTX 50\" in gpu_info:\n",
        "            pytorch_url = \"https://download.pytorch.org/whl/test/cu128\"\n",
        "            torch_version = \"torch==2.7.0\"\n",
        "        else:\n",
        "            pytorch_url = \"https://download.pytorch.org/whl/test/cu124\"\n",
        "            torch_version = \"torch==2.6.0\"\n",
        "\n",
        "        cmd = f\"{self.pip_cmd} install --upgrade {torch_version} torchvision torchaudio --index-url {pytorch_url}\"\n",
        "        success, stdout, stderr = self.run_cmd(cmd, timeout=300)\n",
        "\n",
        "        if success:\n",
        "            print(\"‚úÖ PyTorch emergency fix applied\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå PyTorch fix failed: {stderr}\")\n",
        "            return False\n",
        "\n",
        "    def emergency_dependency_fix(self):\n",
        "        \"\"\"Emergency dependency installation\"\"\"\n",
        "        print(\"üö® Emergency Dependency Fix...\")\n",
        "\n",
        "        essential_packages = [\n",
        "            \"gradio>=4.0.0\", \"transformers\", \"accelerate\", \"diffusers\",\n",
        "            \"opencv-python\", \"Pillow\", \"numpy\", \"scipy\", \"psutil\"\n",
        "        ]\n",
        "\n",
        "        for package in essential_packages:\n",
        "            cmd = f\"{self.pip_cmd} install {package}\"\n",
        "            success, _, _ = self.run_cmd(cmd, timeout=60)\n",
        "            print(\"‚úÖ\" if success else \"‚ùå\", package)\n",
        "\n",
        "        print(\"‚úÖ Emergency dependencies installed\")\n",
        "\n",
        "    def quick_system_check(self):\n",
        "        \"\"\"Quick system health check\"\"\"\n",
        "        checks = {}\n",
        "\n",
        "        # GPU Check\n",
        "        success, output, _ = self.run_cmd(\"nvidia-smi\")\n",
        "        checks['GPU'] = \"‚úÖ Available\" if success and \"RTX\" in output else \"‚ùå Issue detected\"\n",
        "\n",
        "        # PyTorch Check\n",
        "        try:\n",
        "            import torch\n",
        "            checks['PyTorch'] = f\"‚úÖ {torch.__version__}\" if torch.cuda.is_available() else \"‚ùå CUDA not available\"\n",
        "        except ImportError:\n",
        "            checks['PyTorch'] = \"‚ùå Not installed\"\n",
        "\n",
        "        # WAN2GP Check\n",
        "        wan_exists = any(os.path.exists(path) for path in [\"Wan2GP/wgp.py\", \"wan2gp/wgp.py\", \"WAN2GP/wgp.py\"])\n",
        "        checks['WAN2GP'] = \"‚úÖ Found\" if wan_exists else \"‚ùå Missing\"\n",
        "\n",
        "        # Dependencies Check\n",
        "        try:\n",
        "            import gradio, transformers, accelerate, diffusers\n",
        "            checks['Dependencies'] = \"‚úÖ Core packages available\"\n",
        "        except ImportError:\n",
        "            checks['Dependencies'] = \"‚ùå Missing packages\"\n",
        "\n",
        "        return checks\n",
        "\n",
        "    def generate_emergency_commands(self):\n",
        "        \"\"\"Generate emergency launch commands\"\"\"\n",
        "        commands = {\n",
        "            \"Ultra Safe Mode\": f\"{self.python_cmd} wgp.py --t2v-1-3B --attention sdpa --profile 4 --teacache 0 --fp16\",\n",
        "            \"Memory Emergency\": f\"{self.python_cmd} wgp.py --t2v-1-3B --profile 5 --perc-reserved-mem-max 0.2\",\n",
        "            \"Debug Mode\": f\"{self.python_cmd} wgp.py --verbose 2 --attention sdpa --profile 4\",\n",
        "            \"Network Share\": f\"{self.python_cmd} wgp.py --listen --server-port 7861 --attention sdpa\"\n",
        "        }\n",
        "        return commands\n",
        "\n",
        "    def run_quick_diagnostic(self):\n",
        "        \"\"\"Run quick diagnostic and provide emergency options\"\"\"\n",
        "\n",
        "        print(f\"‚ö° Quick Diagnostic - Platform: {self.platform}\")\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "        # Quick system check\n",
        "        checks = self.quick_system_check()\n",
        "\n",
        "        issues = []\n",
        "        for component, status in checks.items():\n",
        "            print(f\"{component}: {status}\")\n",
        "            if \"‚ùå\" in status:\n",
        "                issues.append(component)\n",
        "\n",
        "        # Emergency repairs\n",
        "        if issues:\n",
        "            print(f\"\\nüö® {len(issues)} issues detected. Applying emergency fixes...\")\n",
        "\n",
        "            if \"PyTorch\" in issues:\n",
        "                self.emergency_pytorch_fix()\n",
        "\n",
        "            if \"Dependencies\" in issues:\n",
        "                self.emergency_dependency_fix()\n",
        "\n",
        "            if \"WAN2GP\" in issues:\n",
        "                print(\"üîß Cloning WAN2GP repository...\")\n",
        "                success, _, _ = self.run_cmd(\"git clone --depth 1 https://github.com/deepbeepmeep/Wan2GP.git\", timeout=120)\n",
        "                print(\"‚úÖ Repository cloned\" if success else \"‚ùå Clone failed\")\n",
        "\n",
        "        # Generate emergency commands\n",
        "        commands = self.generate_emergency_commands()\n",
        "\n",
        "        # Display results\n",
        "        html_display = f\"\"\"\n",
        "        <div style=\"background: linear-gradient(45deg, #ff6b6b, #feca57); color: white;\n",
        "                    padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "            <h3>‚ö° Quick Diagnostic Results</h3>\n",
        "            <p><strong>Platform:</strong> {self.platform}</p>\n",
        "            <p><strong>Issues Found:</strong> {len(issues)}</p>\n",
        "            <p><strong>Status:</strong> {'üö® Needs Attention' if issues else '‚úÖ System Ready'}</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(html_display))\n",
        "\n",
        "        print(\"\\nüöÄ Emergency Launch Commands:\")\n",
        "        print(\"-\" * 40)\n",
        "        for name, command in commands.items():\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  {command}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 40)\n",
        "        print(\"‚ö° Quick diagnostic complete!\")\n",
        "\n",
        "        if not issues:\n",
        "            print(\"‚úÖ System appears healthy. Try the Ultra Safe Mode command first.\")\n",
        "        else:\n",
        "            print(\"üö® Emergency fixes applied. Test with Ultra Safe Mode.\")\n",
        "\n",
        "# Execute quick diagnostic\n",
        "quick_runner = QuickDiagnosticRunner()\n",
        "quick_runner.run_quick_diagnostic()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0sx8G7LBCNyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}