{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remphanstar/WanBook/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 1 - WAN2GP Setup Introduction + Enhanced Platform Detection\n",
        "\n",
        "import sys\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import os\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if 'google.colab' not in sys.modules:\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"WAN2GP Setup Introduction + Enhanced Platform Detection\")\n",
        "\n",
        "def detect_platform():\n",
        "    \"\"\"Enhanced platform detection with comprehensive indicators\"\"\"\n",
        "\n",
        "    # Lightning AI detection - multiple indicators for reliability\n",
        "    lightning_indicators = [\n",
        "        'lightning' in str(sys.executable).lower(),\n",
        "        'teamspace-studios' in os.getcwd(),\n",
        "        'LIGHTNING_CLOUD_SPACE_HOST' in os.environ,\n",
        "        'LIGHTNING_CLOUD_SPACE_ID' in os.environ,\n",
        "        'commands/python' in str(sys.executable),\n",
        "        '/home/zeus/miniconda3/envs/cloudspace' in str(sys.executable),\n",
        "        os.path.exists('/teamspace'),\n",
        "        os.path.exists('/commands')\n",
        "    ]\n",
        "\n",
        "    # Google Colab detection\n",
        "    colab_indicators = [\n",
        "        'google.colab' in sys.modules,\n",
        "        '/content' in os.getcwd()\n",
        "    ]\n",
        "\n",
        "    # Vast.AI detection\n",
        "    vast_indicators = [\n",
        "        'VAST_CONTAINERLABEL' in os.environ,\n",
        "        '/workspace' in os.getcwd(),\n",
        "        'vast' in os.environ.get('HOSTNAME', '').lower()\n",
        "    ]\n",
        "\n",
        "    if any(lightning_indicators):\n",
        "        return \"Lightning AI\"\n",
        "    elif any(colab_indicators):\n",
        "        return \"Google Colab\"\n",
        "    elif any(vast_indicators):\n",
        "        return \"Vast.AI/Generic\"\n",
        "    else:\n",
        "        return \"Vast.AI/Generic\"\n",
        "\n",
        "def get_platform_commands(platform):\n",
        "    \"\"\"Get platform-specific pip and python commands\"\"\"\n",
        "    if platform == \"Lightning AI\":\n",
        "        return \"pip\", \"python\", False  # pip_cmd, python_cmd, use_venv\n",
        "    elif platform == \"Google Colab\":\n",
        "        return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "    else:  # Vast.AI/Generic\n",
        "        return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "# Detect current platform\n",
        "current_platform = detect_platform()\n",
        "pip_cmd, python_cmd, use_venv = get_platform_commands(current_platform)\n",
        "\n",
        "# Display platform information\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; margin: 10px 0; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "    <h1>üöÄ Wan2GP Full Setup Notebook</h1>\n",
        "    <p>A cross-platform Jupyter notebook (Colab / Lightning AI / Vast.ai) that installs Wan2GP, common LoRA packs, and optional performance extras (FlashAttention 2, SageAttention, xFormers). It accelerates all downloads with <strong>aria2c</strong> for maximum speed.</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 8px; border: 1px solid #dee2e6; margin: 15px 0;\">\n",
        "    <div style=\"background-color: #007bff; color: white; padding: 15px; border-radius: 5px; text-align: center; margin-bottom: 20px;\">\n",
        "        <h3 style=\"margin: 0; color: white;\">üîç Platform Detection Results</h3>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Currently Running on: <strong style=\"color: #28a745; background-color: white; padding: 2px 6px; border-radius: 3px;\">{current_platform}</strong></p>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Virtual Environment: <strong>{\"Yes\" if use_venv else \"No (Lightning AI)\"}</strong></p>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Pip Command: <strong>{pip_cmd}</strong></p>\n",
        "        <p style=\"margin: 5px 0 0 0; color: white;\">Python Command: <strong>{python_cmd}</strong></p>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "print(\"üîç Platform Detection Debug Info:\")\n",
        "print(f\"   - Detected Platform: {current_platform}\")\n",
        "print(f\"   - Python Executable: {sys.executable}\")\n",
        "print(f\"   - Current Working Directory: {os.getcwd()}\")\n",
        "print(f\"   - Google Colab Check: {'google.colab' in sys.modules}\")\n",
        "print(f\"   - Lightning Environment Variables: {[key for key in os.environ.keys() if 'LIGHTNING' in key]}\")\n",
        "print(f\"   - Virtual Environment Usage: {use_venv}\")\n",
        "print(f\"   - Pip Command: {pip_cmd}\")\n",
        "print(f\"   - Python Command: {python_cmd}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q7hLV1Oz-aBD",
        "outputId": "924e9014-7a0f-4b34-e958-3c44e0eb3f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; margin: 10px 0; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "    <h1>üöÄ Wan2GP Full Setup Notebook</h1>\n",
              "    <p>A cross-platform Jupyter notebook (Colab / Lightning AI / Vast.ai) that installs Wan2GP, common LoRA packs, and optional performance extras (FlashAttention 2, SageAttention, xFormers). It accelerates all downloads with <strong>aria2c</strong> for maximum speed.</p>\n",
              "</div>\n",
              "\n",
              "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 8px; border: 1px solid #dee2e6; margin: 15px 0;\">\n",
              "    <div style=\"background-color: #007bff; color: white; padding: 15px; border-radius: 5px; text-align: center; margin-bottom: 20px;\">\n",
              "        <h3 style=\"margin: 0; color: white;\">üîç Platform Detection Results</h3>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Currently Running on: <strong style=\"color: #28a745; background-color: white; padding: 2px 6px; border-radius: 3px;\">Google Colab</strong></p>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Virtual Environment: <strong>Yes</strong></p>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Pip Command: <strong>.venv/bin/pip</strong></p>\n",
              "        <p style=\"margin: 5px 0 0 0; color: white;\">Python Command: <strong>.venv/bin/python</strong></p>\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Platform Detection Debug Info:\n",
            "   - Detected Platform: Google Colab\n",
            "   - Python Executable: /usr/bin/python3\n",
            "   - Current Working Directory: /content\n",
            "   - Google Colab Check: True\n",
            "   - Lightning Environment Variables: []\n",
            "   - Virtual Environment Usage: True\n",
            "   - Pip Command: .venv/bin/pip\n",
            "   - Python Command: .venv/bin/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (2) Complete System + Python Environment Setup - Cross-Platform v3.1 (With Directory Protection)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if \"google.colab\" not in sys.modules:\n",
        "        from IPython.display import display, Markdown\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"Complete System + Python Environment Setup\")\n",
        "\n",
        "class CompleteEnvironmentSetup:\n",
        "    def __init__(self):\n",
        "        # Use global platform configuration from Cell 1\n",
        "        try:\n",
        "            self.current_platform = current_platform\n",
        "            self.pip_cmd = pip_cmd\n",
        "            self.python_cmd = python_cmd\n",
        "            self.use_venv = use_venv\n",
        "        except NameError:\n",
        "            print(\"‚ö†Ô∏è Platform detection variables not found. Using fallback detection.\")\n",
        "            self.detect_platform_fallback()\n",
        "\n",
        "        self.setup_phases = [\n",
        "            (\"System Packages\", self.install_system_packages),\n",
        "            (\"Directory Protection\", self.setup_directory_protection),\n",
        "            (\"Repository Clone\", self.clone_repository),\n",
        "            (\"Virtual Environment\", self.setup_virtual_environment),\n",
        "            (\"PyTorch Installation\", self.install_pytorch),\n",
        "            (\"Requirements\", self.install_requirements),\n",
        "            (\"Environment Verification\", self.verify_complete_setup),\n",
        "        ]\n",
        "\n",
        "        self.current_phase = 0\n",
        "        self.total_phases = len(self.setup_phases)\n",
        "\n",
        "    def detect_platform_fallback(self):\n",
        "        \"\"\"Fallback platform detection if Cell 1 wasn't run\"\"\"\n",
        "        if \"google.colab\" in sys.modules:\n",
        "            self.current_platform = \"Google Colab\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "        elif any([\"lightning\" in str(sys.executable).lower(), \"teamspace\" in os.getcwd()]):\n",
        "            self.current_platform = \"Lightning AI\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \"pip\", \"python\", False\n",
        "        else:\n",
        "            self.current_platform = \"Generic\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "    def update_progress(self, phase_name, status=\"in_progress\"):\n",
        "        \"\"\"Update setup progress with visual indicators\"\"\"\n",
        "        progress_percent = (self.current_phase / self.total_phases) * 100\n",
        "        status_icons = {\n",
        "            \"in_progress\": \"üîÑ\",\n",
        "            \"success\": \"‚úÖ\",\n",
        "            \"failed\": \"‚ùå\"\n",
        "        }\n",
        "\n",
        "        print(f\"\\n[{self.current_phase + 1}/{self.total_phases}] {status_icons[status]} {phase_name}\")\n",
        "        print(f\"Progress: {progress_percent:.1f}% | Platform: {self.current_platform}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "    def run_command_safely(self, command, description, timeout=300):\n",
        "        \"\"\"Execute command with comprehensive error handling\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=timeout\n",
        "            )\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(f\"‚úÖ {description} completed successfully\")\n",
        "                return True, result.stdout\n",
        "            else:\n",
        "                print(f\"‚ùå {description} failed (exit code {result.returncode})\")\n",
        "                if result.stderr:\n",
        "                    # Check for specific ensurepip failure\n",
        "                    if \"ensurepip\" in result.stderr:\n",
        "                        print(f\"‚ö†Ô∏è ensurepip module failure detected\")\n",
        "                        return \"ensurepip_failure\", result.stderr\n",
        "                    print(f\"   Error: {result.stderr.strip()[:200]}\")\n",
        "                return False, result.stderr\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"‚è∞ {description} timed out after {timeout}s\")\n",
        "            return False, f\"Timeout after {timeout}s\"\n",
        "        except Exception as e:\n",
        "            print(f\"üí• {description} crashed: {e}\")\n",
        "            return False, str(e)\n",
        "\n",
        "    def install_system_packages(self):\n",
        "        \"\"\"Install system packages - same for all platforms\"\"\"\n",
        "        print(\"üîß Installing system packages...\")\n",
        "\n",
        "        if not shutil.which(\"apt-get\"):\n",
        "            print(\"üì¶ apt-get not found. Skipping system package installation.\")\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            print(\"üì¶ Updating package lists...\")\n",
        "            subprocess.run([\"sudo\", \"apt-get\", \"update\", \"-qq\"], check=True, timeout=60)\n",
        "\n",
        "            print(\"üîß Installing aria2, git, build-essential, and wget...\")\n",
        "            subprocess.run([\"sudo\", \"apt-get\", \"install\", \"-y\", \"aria2\", \"git\", \"build-essential\", \"wget\"], check=True, timeout=180)\n",
        "\n",
        "            print(\"‚úÖ System packages installed successfully\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚ùå System package installation failed: {e}\")\n",
        "            return False\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"‚è∞ System package installation timed out\")\n",
        "            return False\n",
        "\n",
        "    def setup_directory_protection(self):\n",
        "        \"\"\"Critical directory protection to prevent recursive cloning\"\"\"\n",
        "        print(\"üõ°Ô∏è Setting up directory protection...\")\n",
        "\n",
        "        current_dir = os.getcwd()\n",
        "        print(f\"üìç Current directory: {current_dir}\")\n",
        "\n",
        "        # Check if we're already inside a Wan2GP directory\n",
        "        if \"Wan2GP\" in current_dir:\n",
        "            print(\"‚ö†Ô∏è Already inside Wan2GP directory - navigating to safe location\")\n",
        "\n",
        "            # Navigate to content root (Colab) or appropriate base directory\n",
        "            if self.current_platform == \"Google Colab\":\n",
        "                safe_dir = \"/content\"\n",
        "            elif self.current_platform == \"Lightning AI\":\n",
        "                safe_dir = os.path.expanduser(\"~\")\n",
        "            else:\n",
        "                safe_dir = os.path.expanduser(\"~\")\n",
        "\n",
        "            try:\n",
        "                os.chdir(safe_dir)\n",
        "                print(f\"üìÅ Moved to safe directory: {os.getcwd()}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to navigate to safe directory: {e}\")\n",
        "                return False\n",
        "\n",
        "        # Check for existing Wan2GP directory and handle it\n",
        "        repo_path = os.path.join(os.getcwd(), \"Wan2GP\")\n",
        "        if os.path.exists(repo_path):\n",
        "            print(f\"üìÅ Found existing Wan2GP directory at: {repo_path}\")\n",
        "\n",
        "            # Check if it looks like a valid repository\n",
        "            if os.path.exists(os.path.join(repo_path, \".git\")):\n",
        "                print(\"‚úÖ Existing directory appears to be a valid git repository\")\n",
        "                # Check if it's the correct repository\n",
        "                try:\n",
        "                    os.chdir(repo_path)\n",
        "                    result = subprocess.run([\"git\", \"remote\", \"get-url\", \"origin\"],\n",
        "                                          capture_output=True, text=True, timeout=10)\n",
        "                    if result.returncode == 0 and \"Wan2GP\" in result.stdout:\n",
        "                        print(\"‚úÖ Existing repository is correct - using it\")\n",
        "                        return True\n",
        "                    else:\n",
        "                        print(\"‚ö†Ô∏è Existing repository is not the correct one\")\n",
        "                        os.chdir(\"..\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Could not verify existing repository: {e}\")\n",
        "                    os.chdir(\"..\")\n",
        "\n",
        "            # If we reach here, remove the problematic directory\n",
        "            print(\"üóëÔ∏è Removing problematic existing directory...\")\n",
        "            try:\n",
        "                shutil.rmtree(repo_path)\n",
        "                print(\"‚úÖ Problematic directory removed\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to remove existing directory: {e}\")\n",
        "                # Try to rename it instead\n",
        "                try:\n",
        "                    backup_name = f\"Wan2GP_backup_{int(time.time())}\"\n",
        "                    os.rename(repo_path, backup_name)\n",
        "                    print(f\"‚úÖ Renamed problematic directory to {backup_name}\")\n",
        "                except Exception as e2:\n",
        "                    print(f\"‚ùå Could not even rename directory: {e2}\")\n",
        "                    return False\n",
        "\n",
        "        print(\"‚úÖ Directory protection setup complete\")\n",
        "        return True\n",
        "\n",
        "    def clone_repository(self):\n",
        "        \"\"\"Clone WAN2GP repository with enhanced protection\"\"\"\n",
        "        REPO_DIR = \"Wan2GP\"\n",
        "        REPO_URL = \"https://github.com/deepbeepmeep/Wan2GP.git\"\n",
        "\n",
        "        print(\"üìÇ Setting up WAN2GP repository...\")\n",
        "        print(f\"üìç Working from: {os.getcwd()}\")\n",
        "\n",
        "        # Final check - ensure we're not in a nested situation\n",
        "        current_path = os.getcwd()\n",
        "        if current_path.count(\"Wan2GP\") > 0:\n",
        "            print(\"üö® CRITICAL: Still in Wan2GP directory path!\")\n",
        "            print(\"üîÑ Attempting emergency navigation...\")\n",
        "\n",
        "            # Emergency navigation\n",
        "            if self.current_platform == \"Google Colab\":\n",
        "                emergency_path = \"/content\"\n",
        "            else:\n",
        "                emergency_path = os.path.expanduser(\"~\")\n",
        "\n",
        "            try:\n",
        "                os.chdir(emergency_path)\n",
        "                print(f\"üÜò Emergency navigation successful: {os.getcwd()}\")\n",
        "            except Exception as e:\n",
        "                print(f\"üí• Emergency navigation failed: {e}\")\n",
        "                return False\n",
        "\n",
        "        if not os.path.exists(REPO_DIR):\n",
        "            print(f\"üì• Cloning repository from {REPO_URL}...\")\n",
        "            try:\n",
        "                subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL], check=True, timeout=120)\n",
        "                print(\"‚úÖ Repository cloned successfully\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"‚ùå Failed to clone repository: {e}\")\n",
        "                return False\n",
        "            except subprocess.TimeoutExpired:\n",
        "                print(\"‚è∞ Repository clone timed out\")\n",
        "                return False\n",
        "        else:\n",
        "            print(f\"üìÅ Directory {REPO_DIR} already exists\")\n",
        "\n",
        "        try:\n",
        "            os.chdir(REPO_DIR)\n",
        "            final_path = os.getcwd()\n",
        "            print(f\"üìÅ Changed to directory: {final_path}\")\n",
        "\n",
        "            # Verify we're in the right place\n",
        "            if final_path.count(\"Wan2GP\") > 1:\n",
        "                print(\"üö® WARNING: Detected nested Wan2GP directories!\")\n",
        "                print(f\"üîç Current path: {final_path}\")\n",
        "                # This shouldn't happen with our protection, but if it does, report it\n",
        "                return False\n",
        "\n",
        "            print(\"‚úÖ Repository setup verified\")\n",
        "            return True\n",
        "        except FileNotFoundError:\n",
        "            print(f\"‚ùå Directory {REPO_DIR} not found\")\n",
        "            return False\n",
        "\n",
        "    def setup_venv_manual_pip(self):\n",
        "        \"\"\"Create venv without pip, then install pip manually\"\"\"\n",
        "        try:\n",
        "            print(\"üîß Creating venv without pip...\")\n",
        "            subprocess.run([sys.executable, \"-m\", \"venv\", \".venv\", \"--without-pip\"],\n",
        "                          check=True, timeout=60)\n",
        "\n",
        "            print(\"üì• Downloading get-pip.py...\")\n",
        "            subprocess.run([\"wget\", \"https://bootstrap.pypa.io/get-pip.py\"], check=True)\n",
        "\n",
        "            print(\"üîß Installing pip manually...\")\n",
        "            subprocess.run([\".venv/bin/python\", \"get-pip.py\"], check=True)\n",
        "\n",
        "            print(\"‚úÖ Virtual environment with manual pip created successfully\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Manual pip installation failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def setup_virtual_environment(self):\n",
        "        \"\"\"Create virtual environment ONLY if not on Lightning AI - Enhanced with ensurepip fixes\"\"\"\n",
        "        if not self.use_venv:\n",
        "            print(\"‚ö° Lightning AI detected - using system environment (no venv)\")\n",
        "            return True\n",
        "\n",
        "        print(\"üêç Setting up virtual environment...\")\n",
        "\n",
        "        # Check if venv already exists\n",
        "        if os.path.exists(\".venv/bin/python\"):\n",
        "            print(\"‚úÖ Virtual environment already exists and appears functional\")\n",
        "            return True\n",
        "\n",
        "        print(\"üî® Creating virtual environment...\")\n",
        "\n",
        "        # Try multiple methods for virtual environment creation\n",
        "        venv_methods = [\n",
        "            ([sys.executable, \"-m\", \"venv\", \"--system-site-packages\", \".venv\"], \"venv with system packages\"),\n",
        "            ([sys.executable, \"-m\", \"venv\", \".venv\"], \"standard venv\"),\n",
        "            ([sys.executable, \"-m\", \"virtualenv\", \".venv\"], \"virtualenv package\"),\n",
        "        ]\n",
        "\n",
        "        for command, method_name in venv_methods:\n",
        "            print(f\"üîÑ Trying: {method_name}\")\n",
        "            success, error_msg = self.run_command_safely(command, f\"Virtual environment creation ({method_name})\", timeout=60)\n",
        "\n",
        "            if success == True:\n",
        "                print(\"‚úÖ Virtual environment created successfully\")\n",
        "                return True\n",
        "            elif success == \"ensurepip_failure\":\n",
        "                print(\"‚ö†Ô∏è ensurepip failure detected - trying manual pip installation...\")\n",
        "                if self.setup_venv_manual_pip():\n",
        "                    return True\n",
        "                break  # Don't try other methods if ensurepip failed\n",
        "            else:\n",
        "                print(f\"‚ùå {method_name} failed\")\n",
        "                if error_msg:\n",
        "                    print(f\"   Error: {error_msg[:200]}\")\n",
        "                continue\n",
        "\n",
        "        # Final fallback: override to system installation\n",
        "        print(\"üîÑ All virtual environment methods failed - switching to system installation\")\n",
        "        print(\"‚ö° Overriding to system-wide installation (recommended for Colab)\")\n",
        "        self.use_venv = False\n",
        "        self.pip_cmd = \"pip\"\n",
        "        self.python_cmd = \"python\"\n",
        "        return True\n",
        "\n",
        "    def install_pytorch(self):\n",
        "        \"\"\"Install PyTorch with appropriate CUDA version\"\"\"\n",
        "        print(\"üî• Installing PyTorch...\")\n",
        "\n",
        "        pytorch_cmd = [\n",
        "            self.pip_cmd, \"install\",\n",
        "            \"torch==2.6.0\", \"torchvision\", \"torchaudio\",\n",
        "            \"--index-url\", \"https://download.pytorch.org/whl/test/cu124\"\n",
        "        ]\n",
        "\n",
        "        success, _ = self.run_command_safely(pytorch_cmd, \"PyTorch installation\", timeout=300)\n",
        "        return success == True\n",
        "\n",
        "    def install_requirements(self):\n",
        "        \"\"\"Install requirements.txt\"\"\"\n",
        "        print(\"üì¶ Installing requirements...\")\n",
        "\n",
        "        if not os.path.exists(\"requirements.txt\"):\n",
        "            print(\"‚ö†Ô∏è requirements.txt not found, skipping\")\n",
        "            return True\n",
        "\n",
        "        req_cmd = [self.pip_cmd, \"install\", \"-r\", \"requirements.txt\"]\n",
        "        success, _ = self.run_command_safely(req_cmd, \"Requirements installation\", timeout=300)\n",
        "        return success == True\n",
        "\n",
        "    def verify_complete_setup(self):\n",
        "        \"\"\"Verify the complete installation\"\"\"\n",
        "        print(\"üîç Verifying installation...\")\n",
        "\n",
        "        # Verify directory structure\n",
        "        current_dir = os.getcwd()\n",
        "        print(f\"üìç Final directory: {current_dir}\")\n",
        "\n",
        "        if current_dir.count(\"Wan2GP\") > 1:\n",
        "            print(\"üö® CRITICAL: Nested directory structure detected!\")\n",
        "            print(\"‚ùå Setup verification failed due to directory structure\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # Test PyTorch installation\n",
        "            result = subprocess.run([self.python_cmd, \"-c\", \"import torch; print(f'PyTorch {torch.__version__} installed'); print(f'CUDA available: {torch.cuda.is_available()}')\"],\n",
        "                                  capture_output=True, text=True, timeout=30)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(\"‚úÖ PyTorch verification successful:\")\n",
        "                for line in result.stdout.strip().split('\\n'):\n",
        "                    print(f\"   {line}\")\n",
        "\n",
        "                # Verify main WanGP file exists\n",
        "                if os.path.exists(\"wgp.py\"):\n",
        "                    print(\"‚úÖ WanGP main file found\")\n",
        "                else:\n",
        "                    print(\"‚ö†Ô∏è WanGP main file (wgp.py) not found\")\n",
        "\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå PyTorch verification failed: {result.stderr}\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Verification failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def run_complete_setup(self):\n",
        "        \"\"\"Execute the complete setup process\"\"\"\n",
        "        print(\"üöÄ WAN2GP Complete System + Python Environment Setup\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Platform: {self.current_platform}\")\n",
        "        print(f\"Virtual Environment: {'Yes' if self.use_venv else 'No'}\")\n",
        "        print(f\"Pip Command: {self.pip_cmd}\")\n",
        "        print(f\"Python Command: {self.python_cmd}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for phase_name, phase_func in self.setup_phases:\n",
        "            self.update_progress(phase_name, \"in_progress\")\n",
        "\n",
        "            phase_start = time.time()\n",
        "            success = phase_func()\n",
        "            phase_duration = time.time() - phase_start\n",
        "\n",
        "            if success:\n",
        "                self.update_progress(phase_name, \"success\")\n",
        "                print(f\"‚è±Ô∏è {phase_name} completed in {phase_duration:.1f}s\")\n",
        "                self.current_phase += 1\n",
        "            else:\n",
        "                self.update_progress(phase_name, \"failed\")\n",
        "                print(f\"üí• Setup failed at: {phase_name}\")\n",
        "                print(\"\\nüîÑ Setup Issues - Platform-Specific Troubleshooting:\")\n",
        "                print(\"üì± Colab: Restart runtime and re-run all cells\")\n",
        "                print(\"‚ö° Lightning.AI: Ensure you're using the correct Python version\")\n",
        "                print(\"üåå Vast.AI: Check GPU drivers and CUDA installation\")\n",
        "                return False\n",
        "\n",
        "        total_duration = time.time() - start_time\n",
        "        print(f\"\\nüéâ WAN2GP setup completed successfully in {total_duration:.1f}s!\")\n",
        "        print(\"üöÄ Ready to launch WAN2GP!\")\n",
        "        return True\n",
        "\n",
        "# Execute the complete setup\n",
        "setup = CompleteEnvironmentSetup()\n",
        "setup.run_complete_setup()\n"
      ],
      "metadata": {
        "id": "Wc1mj9zi_ExM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cf49dd-b39e-4f48-ab64-5faca1c19112",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ WAN2GP Complete System + Python Environment Setup\n",
            "======================================================================\n",
            "Platform: Google Colab\n",
            "Virtual Environment: Yes\n",
            "Pip Command: .venv/bin/pip\n",
            "Python Command: .venv/bin/python\n",
            "======================================================================\n",
            "\n",
            "[1/6] üîÑ System Packages\n",
            "Progress: 0.0% | Platform: Google Colab\n",
            "============================================================\n",
            "üîß Installing system packages...\n",
            "üì¶ Updating package lists...\n",
            "üîß Installing aria2, git, build-essential, and wget...\n",
            "‚úÖ System packages installed successfully\n",
            "\n",
            "[1/6] ‚úÖ System Packages\n",
            "Progress: 0.0% | Platform: Google Colab\n",
            "============================================================\n",
            "‚è±Ô∏è System Packages completed in 19.7s\n",
            "\n",
            "[2/6] üîÑ Repository Clone\n",
            "Progress: 16.7% | Platform: Google Colab\n",
            "============================================================\n",
            "üìÇ Setting up WAN2GP repository...\n",
            "üì• Cloning repository from https://github.com/deepbeepmeep/Wan2GP.git...\n",
            "‚úÖ Repository cloned successfully\n",
            "üìÅ Changed to directory: /content/Wan2GP\n",
            "\n",
            "[2/6] ‚úÖ Repository Clone\n",
            "Progress: 16.7% | Platform: Google Colab\n",
            "============================================================\n",
            "‚è±Ô∏è Repository Clone completed in 1.3s\n",
            "\n",
            "[3/6] üîÑ Virtual Environment\n",
            "Progress: 33.3% | Platform: Google Colab\n",
            "============================================================\n",
            "üêç Setting up virtual environment...\n",
            "üî® Creating virtual environment...\n",
            "üîÑ Trying: venv with system packages\n",
            "‚ùå Virtual environment creation (venv with system packages) failed (exit code 1)\n",
            "‚ö†Ô∏è ensurepip module failure detected\n",
            "‚ö†Ô∏è ensurepip failure detected - trying manual pip installation...\n",
            "üîß Creating venv without pip...\n",
            "üì• Downloading get-pip.py...\n",
            "üîß Installing pip manually...\n",
            "‚úÖ Virtual environment with manual pip created successfully\n",
            "\n",
            "[3/6] ‚úÖ Virtual Environment\n",
            "Progress: 33.3% | Platform: Google Colab\n",
            "============================================================\n",
            "‚è±Ô∏è Virtual Environment completed in 8.2s\n",
            "\n",
            "[4/6] üîÑ PyTorch Installation\n",
            "Progress: 50.0% | Platform: Google Colab\n",
            "============================================================\n",
            "üî• Installing PyTorch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (3) Complete Model & LoRA Downloads - Full Featured UI with HuggingFace Auth v3.0\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML, Markdown, Javascript\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if \"google.colab\" not in sys.modules:\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"Complete Model & LoRA Downloads - Full Featured UI\")\n",
        "\n",
        "# HuggingFace Authentication Setup\n",
        "class HuggingFaceAuth:\n",
        "    def __init__(self):\n",
        "        self.token = None\n",
        "        self.authenticated = False\n",
        "        self.setup_auth_ui()\n",
        "\n",
        "    def setup_auth_ui(self):\n",
        "        \"\"\"Setup HuggingFace authentication with rich UI\"\"\"\n",
        "        auth_html = f\"\"\"\n",
        "        <div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                    color: white; padding: 15px; border-radius: 10px; margin: 10px 0;\n",
        "                    box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "            <h3 style=\"margin: 0; color: white;\">üîê HuggingFace Authentication</h3>\n",
        "            <p style=\"margin: 5px 0;\">Optional: Login for private model access and faster downloads</p>\n",
        "            <div id=\"hf-auth-status\" style=\"margin-top: 10px;\">\n",
        "                <button onclick=\"loginHuggingFace()\"\n",
        "                        style=\"background: #28a745; color: white; border: none; padding: 8px 16px;\n",
        "                               border-radius: 5px; cursor: pointer; margin-right: 10px;\">\n",
        "                    üîë Login to HuggingFace\n",
        "                </button>\n",
        "                <button onclick=\"skipAuth()\"\n",
        "                        style=\"background: #6c757d; color: white; border: none; padding: 8px 16px;\n",
        "                               border-radius: 5px; cursor: pointer;\">\n",
        "                    ‚è≠Ô∏è Skip Authentication\n",
        "                </button>\n",
        "            </div>\n",
        "            <div id=\"auth-result\" style=\"margin-top: 10px; display: none;\"></div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        auth_js = \"\"\"\n",
        "        <script>\n",
        "        function loginHuggingFace() {\n",
        "            const authDiv = document.getElementById('hf-auth-status');\n",
        "            authDiv.innerHTML = `\n",
        "                <input type=\"password\" id=\"hf-token\" placeholder=\"Enter HuggingFace Token\"\n",
        "                       style=\"padding: 8px; border-radius: 5px; border: 1px solid #ccc; margin-right: 10px; width: 250px;\">\n",
        "                <button onclick=\"authenticateToken()\"\n",
        "                        style=\"background: #007bff; color: white; border: none; padding: 8px 16px;\n",
        "                               border-radius: 5px; cursor: pointer;\">\n",
        "                    ‚úÖ Authenticate\n",
        "                </button>\n",
        "                <p style=\"font-size: 12px; margin-top: 5px;\">\n",
        "                    Get your token from: <a href=\"https://huggingface.co/settings/tokens\" target=\"_blank\"\n",
        "                    style=\"color: #ffc107;\">https://huggingface.co/settings/tokens</a>\n",
        "                </p>\n",
        "            `;\n",
        "        }\n",
        "\n",
        "        function authenticateToken() {\n",
        "            const token = document.getElementById('hf-token').value;\n",
        "            if (token) {\n",
        "                google.colab.kernel.invokeFunction('authenticate_hf', [token], {});\n",
        "                document.getElementById('auth-result').style.display = 'block';\n",
        "                document.getElementById('auth-result').innerHTML =\n",
        "                    '<p style=\"color: #28a745;\">üîë Authenticating with HuggingFace...</p>';\n",
        "            }\n",
        "        }\n",
        "\n",
        "        function skipAuth() {\n",
        "            google.colab.kernel.invokeFunction('skip_hf_auth', [], {});\n",
        "            document.getElementById('hf-auth-status').innerHTML =\n",
        "                '<p style=\"color: #ffc107;\">‚è≠Ô∏è Skipped HuggingFace authentication - using public access only</p>';\n",
        "        }\n",
        "        </script>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(auth_html + auth_js))\n",
        "\n",
        "    def authenticate(self, token):\n",
        "        \"\"\"Authenticate with HuggingFace\"\"\"\n",
        "        try:\n",
        "            import huggingface_hub\n",
        "            huggingface_hub.login(token=token, write_permission=True)\n",
        "            self.token = token\n",
        "            self.authenticated = True\n",
        "            self.show_auth_success()\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            self.show_auth_error(str(e))\n",
        "            return False\n",
        "\n",
        "    def show_auth_success(self):\n",
        "        \"\"\"Show authentication success\"\"\"\n",
        "        success_html = \"\"\"\n",
        "        <div style=\"background: #d4edda; color: #155724; padding: 10px; border-radius: 5px;\n",
        "                    border: 1px solid #c3e6cb; margin: 5px 0;\">\n",
        "            <strong>‚úÖ HuggingFace Authentication Successful!</strong><br>\n",
        "            üöÄ You now have access to private models and faster download speeds\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(success_html))\n",
        "\n",
        "    def show_auth_error(self, error):\n",
        "        \"\"\"Show authentication error\"\"\"\n",
        "        error_html = f\"\"\"\n",
        "        <div style=\"background: #f8d7da; color: #721c24; padding: 10px; border-radius: 5px;\n",
        "                    border: 1px solid #f5c6cb; margin: 5px 0;\">\n",
        "            <strong>‚ùå Authentication Failed:</strong><br>\n",
        "            {error}<br>\n",
        "            <small>Continuing with public access only...</small>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(error_html))\n",
        "\n",
        "# Interactive Download System with Rich UI\n",
        "class EnhancedModelDownloader:\n",
        "    def __init__(self):\n",
        "        # Use global platform configuration from previous cells\n",
        "        try:\n",
        "            self.current_platform = current_platform\n",
        "            self.pip_cmd = pip_cmd\n",
        "            self.python_cmd = python_cmd\n",
        "            self.use_venv = use_venv\n",
        "        except NameError:\n",
        "            print(\"‚ö†Ô∏è Platform detection variables not found. Using fallback detection.\")\n",
        "            self.detect_platform_fallback()\n",
        "\n",
        "        # Initialize HuggingFace auth\n",
        "        self.hf_auth = HuggingFaceAuth()\n",
        "\n",
        "        # Fixed URLs - Using correct repository name with underscore\n",
        "        self.base_repo_url = \"https://huggingface.co/Kijai/WanVideo_comfy\"\n",
        "        self.resolve_url = f\"{self.base_repo_url}/resolve/main\"\n",
        "\n",
        "        # Download methods with authentication support\n",
        "        self.download_methods = [\n",
        "            (\"aria2c\", self.download_with_aria2c),\n",
        "            (\"wget\", self.download_with_wget),\n",
        "            (\"python\", self.download_with_python),\n",
        "            (\"hf_hub\", self.download_with_hf_hub)\n",
        "        ]\n",
        "\n",
        "        # Enhanced model definitions\n",
        "        self.setup_model_definitions()\n",
        "        self.setup_ui_components()\n",
        "\n",
        "        # Download statistics\n",
        "        self.download_stats = {\n",
        "            \"total_files\": 0,\n",
        "            \"downloaded_files\": 0,\n",
        "            \"failed_files\": 0,\n",
        "            \"total_size\": 0,\n",
        "            \"downloaded_size\": 0\n",
        "        }\n",
        "\n",
        "    def detect_platform_fallback(self):\n",
        "        \"\"\"Fallback platform detection if previous cells weren't run\"\"\"\n",
        "        if \"google.colab\" in sys.modules:\n",
        "            self.current_platform = \"Google Colab\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "        elif any([\"lightning\" in str(sys.executable).lower(), \"teamspace\" in os.getcwd()]):\n",
        "            self.current_platform = \"Lightning AI\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \"pip\", \"python\", False\n",
        "        else:\n",
        "            self.current_platform = \"Generic\"\n",
        "            self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "    def setup_model_definitions(self):\n",
        "        \"\"\"Setup enhanced model definitions with authentication support\"\"\"\n",
        "        self.models = {\n",
        "            \"wan_14b_fp16\": {\n",
        "                \"url\": f\"{self.resolve_url}/Wan2_1-T2V-14B_fp16.safetensors\",\n",
        "                \"filename\": \"Wan2_1-T2V-14B_fp16.safetensors\",\n",
        "                \"size\": \"29.1 GB\",\n",
        "                \"path\": \"ckpts/\",\n",
        "                \"requires_auth\": False,\n",
        "                \"description\": \"Wan 2.1 14B model - Highest quality text-to-video generation\"\n",
        "            },\n",
        "            \"wan_14b_fp8\": {\n",
        "                \"url\": f\"{self.resolve_url}/Wan2_1-T2V-14B_fp8_e4m3fn.safetensors\",\n",
        "                \"filename\": \"Wan2_1-T2V-14B_fp8_e4m3fn.safetensors\",\n",
        "                \"size\": \"14.6 GB\",\n",
        "                \"path\": \"ckpts/\",\n",
        "                \"requires_auth\": False,\n",
        "                \"description\": \"Wan 2.1 14B FP8 quantized - Smaller size, minimal quality loss\"\n",
        "            },\n",
        "            \"wan_1_3b_fp32\": {\n",
        "                \"url\": f\"{self.resolve_url}/Wan2_1-T2V-1_3B_fp32.safetensors\",\n",
        "                \"filename\": \"Wan2_1-T2V-1_3B_fp32.safetensors\",\n",
        "                \"size\": \"2.7 GB\",\n",
        "                \"path\": \"ckpts/\",\n",
        "                \"requires_auth\": False,\n",
        "                \"description\": \"Wan 2.1 1.3B model - Fast generation for lower-end hardware\"\n",
        "            },\n",
        "            \"phantom_wan_14b\": {\n",
        "                \"url\": f\"{self.resolve_url}/Phantom-Wan-14B_fp16.safetensors\",\n",
        "                \"filename\": \"Phantom-Wan-14B_fp16.safetensors\",\n",
        "                \"size\": \"29.1 GB\",\n",
        "                \"path\": \"ckpts/\",\n",
        "                \"requires_auth\": False,\n",
        "                \"description\": \"Phantom model - Excellent for object/person transfer\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.text_encoders = {\n",
        "            \"umt5_xxl_fp16\": {\n",
        "                \"url\": f\"{self.resolve_url}/umt5_xxl_fp16.safetensors\",\n",
        "                \"filename\": \"umt5_xxl_fp16.safetensors\",\n",
        "                \"size\": \"4.9 GB\",\n",
        "                \"path\": \"text_encoders/\",\n",
        "                \"requires_auth\": False,\n",
        "                \"description\": \"T5 text encoder - Required for all video generation\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.vaes = {\n",
        "            \"wan_vae_bf16\": {\n",
        "                \"url\": f\"{self.resolve_url}/Wan2_1_VAE_bf16.safetensors\",\n",
        "                \"filename\": \"Wan2_1_VAE_bf16.safetensors\",\n",
        "                \"size\": \"167 MB\",\n",
        "                \"path\": \"vae/\",\n",
        "                \"requires_auth\": False,\n",
        "                \"description\": \"Video VAE - Converts between pixel and latent space\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.loras = {\n",
        "            \"causVid_14b\": {\n",
        "                \"url\": f\"{self.resolve_url}/Wan21_CausVid_14B_T2V_lora_rank32.safetensors\",\n",
        "                \"filename\": \"Wan21_CausVid_14B_T2V_lora_rank32.safetensors\",\n",
        "                \"size\": \"201 MB\",\n",
        "                \"path\": \"loras14B/\",\n",
        "                \"requires_auth\": False,\n",
        "                \"description\": \"CausVid LoRA - 4-12 step generation with 2x speed improvement\"\n",
        "            },\n",
        "            \"accVid_t2v_14b\": {\n",
        "                \"url\": f\"{self.resolve_url}/Wan21AccVidT2V14Blorarank32fp16.safetensors\",\n",
        "                \"filename\": \"Wan21AccVidT2V14Blorarank32fp16.safetensors\",\n",
        "                \"size\": \"201 MB\",\n",
        "                \"path\": \"loras14B/\",\n",
        "                \"requires_auth\": False,\n",
        "                \"description\": \"AccVid T2V LoRA - 2x speed with no classifier-free guidance\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def setup_ui_components(self):\n",
        "        \"\"\"Setup rich UI components with CSS and JavaScript\"\"\"\n",
        "        ui_css = \"\"\"\n",
        "        <style>\n",
        "        .download-container {\n",
        "            font-family: 'Segoe UI', Arial, sans-serif;\n",
        "            max-width: 1200px;\n",
        "            margin: 0 auto;\n",
        "        }\n",
        "\n",
        "        .header-gradient {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            text-align: center;\n",
        "            margin: 10px 0;\n",
        "            box-shadow: 0 4px 15px rgba(0,0,0,0.2);\n",
        "        }\n",
        "\n",
        "        .category-card {\n",
        "            background: #f8f9fa;\n",
        "            border: 1px solid #dee2e6;\n",
        "            border-radius: 8px;\n",
        "            padding: 20px;\n",
        "            margin: 15px 0;\n",
        "            transition: all 0.3s ease;\n",
        "        }\n",
        "\n",
        "        .category-card:hover {\n",
        "            box-shadow: 0 4px 12px rgba(0,0,0,0.1);\n",
        "            transform: translateY(-2px);\n",
        "        }\n",
        "\n",
        "        .category-header {\n",
        "            background: #007bff;\n",
        "            color: white;\n",
        "            padding: 10px 15px;\n",
        "            border-radius: 5px;\n",
        "            margin-bottom: 15px;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "\n",
        "        .model-item {\n",
        "            background: white;\n",
        "            border: 1px solid #e9ecef;\n",
        "            border-radius: 5px;\n",
        "            padding: 15px;\n",
        "            margin: 10px 0;\n",
        "            display: flex;\n",
        "            justify-content: space-between;\n",
        "            align-items: center;\n",
        "        }\n",
        "\n",
        "        .model-info {\n",
        "            flex-grow: 1;\n",
        "        }\n",
        "\n",
        "        .model-name {\n",
        "            font-weight: bold;\n",
        "            color: #333;\n",
        "            margin-bottom: 5px;\n",
        "        }\n",
        "\n",
        "        .model-description {\n",
        "            color: #666;\n",
        "            font-size: 0.9em;\n",
        "            margin-bottom: 5px;\n",
        "        }\n",
        "\n",
        "        .model-size {\n",
        "            color: #007bff;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "\n",
        "        .download-btn {\n",
        "            background: #28a745;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            padding: 8px 16px;\n",
        "            border-radius: 5px;\n",
        "            cursor: pointer;\n",
        "            margin-left: 10px;\n",
        "            transition: background 0.3s ease;\n",
        "        }\n",
        "\n",
        "        .download-btn:hover {\n",
        "            background: #218838;\n",
        "        }\n",
        "\n",
        "        .download-btn:disabled {\n",
        "            background: #6c757d;\n",
        "            cursor: not-allowed;\n",
        "        }\n",
        "\n",
        "        .progress-container {\n",
        "            background: #f8f9fa;\n",
        "            border-radius: 8px;\n",
        "            padding: 20px;\n",
        "            margin: 20px 0;\n",
        "            border: 1px solid #dee2e6;\n",
        "        }\n",
        "\n",
        "        .progress-bar {\n",
        "            width: 100%;\n",
        "            height: 20px;\n",
        "            background: #e9ecef;\n",
        "            border-radius: 10px;\n",
        "            overflow: hidden;\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "\n",
        "        .progress-fill {\n",
        "            height: 100%;\n",
        "            background: linear-gradient(90deg, #28a745, #20c997);\n",
        "            transition: width 0.3s ease;\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "\n",
        "        .stats-grid {\n",
        "            display: grid;\n",
        "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
        "            gap: 15px;\n",
        "            margin: 20px 0;\n",
        "        }\n",
        "\n",
        "        .stat-card {\n",
        "            background: white;\n",
        "            padding: 15px;\n",
        "            border-radius: 8px;\n",
        "            text-align: center;\n",
        "            border: 1px solid #dee2e6;\n",
        "        }\n",
        "\n",
        "        .stat-number {\n",
        "            font-size: 2em;\n",
        "            font-weight: bold;\n",
        "            color: #007bff;\n",
        "        }\n",
        "\n",
        "        .stat-label {\n",
        "            color: #666;\n",
        "            margin-top: 5px;\n",
        "        }\n",
        "        </style>\n",
        "        \"\"\"\n",
        "\n",
        "        ui_js = \"\"\"\n",
        "        <script>\n",
        "        class DownloadProgressManager {\n",
        "            constructor() {\n",
        "                this.activeDownloads = new Map();\n",
        "                this.totalProgress = 0;\n",
        "            }\n",
        "\n",
        "            startDownload(filename, size) {\n",
        "                this.activeDownloads.set(filename, {\n",
        "                    progress: 0,\n",
        "                    size: size,\n",
        "                    startTime: Date.now()\n",
        "                });\n",
        "                this.updateUI();\n",
        "            }\n",
        "\n",
        "            updateProgress(filename, progress) {\n",
        "                if (this.activeDownloads.has(filename)) {\n",
        "                    this.activeDownloads.get(filename).progress = progress;\n",
        "                    this.updateUI();\n",
        "                }\n",
        "            }\n",
        "\n",
        "            completeDownload(filename) {\n",
        "                this.activeDownloads.delete(filename);\n",
        "                this.updateUI();\n",
        "            }\n",
        "\n",
        "            updateUI() {\n",
        "                // Update progress bars and statistics\n",
        "                const totalDownloads = this.activeDownloads.size;\n",
        "                const completedProgress = Array.from(this.activeDownloads.values())\n",
        "                    .reduce((sum, download) => sum + download.progress, 0);\n",
        "\n",
        "                const overallProgress = totalDownloads > 0 ? completedProgress / totalDownloads : 0;\n",
        "\n",
        "                const progressBar = document.querySelector('.progress-fill');\n",
        "                if (progressBar) {\n",
        "                    progressBar.style.width = `${overallProgress}%`;\n",
        "                }\n",
        "\n",
        "                // Update statistics\n",
        "                this.updateStats();\n",
        "            }\n",
        "\n",
        "            updateStats() {\n",
        "                const statsContainer = document.querySelector('.stats-grid');\n",
        "                if (statsContainer) {\n",
        "                    const activeCount = this.activeDownloads.size;\n",
        "                    const totalSize = Array.from(this.activeDownloads.values())\n",
        "                        .reduce((sum, download) => sum + download.size, 0);\n",
        "\n",
        "                    statsContainer.innerHTML = `\n",
        "                        <div class=\"stat-card\">\n",
        "                            <div class=\"stat-number\">${activeCount}</div>\n",
        "                            <div class=\"stat-label\">Active Downloads</div>\n",
        "                        </div>\n",
        "                        <div class=\"stat-card\">\n",
        "                            <div class=\"stat-number\">${(totalSize / 1024 / 1024 / 1024).toFixed(1)}GB</div>\n",
        "                            <div class=\"stat-label\">Total Size</div>\n",
        "                        </div>\n",
        "                    `;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Global download manager\n",
        "        window.downloadManager = new DownloadProgressManager();\n",
        "\n",
        "        // Download control functions\n",
        "        function startDownload(modelKey, filename, size) {\n",
        "            window.downloadManager.startDownload(filename, size);\n",
        "            google.colab.kernel.invokeFunction('download_model', [modelKey], {});\n",
        "        }\n",
        "\n",
        "        function pauseDownload(filename) {\n",
        "            console.log('Pausing download:', filename);\n",
        "            // Implementation for pausing downloads\n",
        "        }\n",
        "\n",
        "        function resumeDownload(filename) {\n",
        "            console.log('Resuming download:', filename);\n",
        "            // Implementation for resuming downloads\n",
        "        }\n",
        "        </script>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(ui_css + ui_js))\n",
        "\n",
        "    def create_enhanced_ui(self):\n",
        "        \"\"\"Create enhanced download UI with rich components\"\"\"\n",
        "        header_html = \"\"\"\n",
        "        <div class=\"download-container\">\n",
        "            <div class=\"header-gradient\">\n",
        "                <h1>üöÄ WAN2GP Model & LoRA Download Center</h1>\n",
        "                <p>Complete model collection with intelligent downloading and progress tracking</p>\n",
        "                <div style=\"background: rgba(255,255,255,0.1); padding: 10px; border-radius: 5px; margin-top: 10px;\">\n",
        "                    <strong>Platform:</strong> {platform} |\n",
        "                    <strong>Download Methods:</strong> aria2c ‚Üí wget ‚Üí python ‚Üí HuggingFace Hub\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"progress-container\">\n",
        "                <h3>üìä Download Progress</h3>\n",
        "                <div class=\"progress-bar\">\n",
        "                    <div class=\"progress-fill\" style=\"width: 0%;\"></div>\n",
        "                </div>\n",
        "                <div class=\"stats-grid\">\n",
        "                    <div class=\"stat-card\">\n",
        "                        <div class=\"stat-number\">0</div>\n",
        "                        <div class=\"stat-label\">Active Downloads</div>\n",
        "                    </div>\n",
        "                    <div class=\"stat-card\">\n",
        "                        <div class=\"stat-number\">0GB</div>\n",
        "                        <div class=\"stat-label\">Total Size</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "        \"\"\".format(platform=self.current_platform)\n",
        "\n",
        "        # Generate category cards\n",
        "        categories = [\n",
        "            (\"üé¨ Essential Models\", self.models, \"Core video generation models\"),\n",
        "            (\"üìù Text Encoders\", self.text_encoders, \"Required for text understanding\"),\n",
        "            (\"üé® VAE Models\", self.vaes, \"Video encoding/decoding components\"),\n",
        "            (\"‚ö° Performance LoRAs\", self.loras, \"Speed and quality enhancement LoRAs\")\n",
        "        ]\n",
        "\n",
        "        category_html = \"\"\n",
        "        for category_name, category_items, category_desc in categories:\n",
        "            category_html += f\"\"\"\n",
        "            <div class=\"category-card\">\n",
        "                <div class=\"category-header\">\n",
        "                    {category_name}\n",
        "                    <div style=\"font-weight: normal; font-size: 0.9em; margin-top: 5px;\">{category_desc}</div>\n",
        "                </div>\n",
        "            \"\"\"\n",
        "\n",
        "            for item_key, item_info in category_items.items():\n",
        "                auth_indicator = \"üîí\" if item_info.get(\"requires_auth\", False) else \"üåê\"\n",
        "                category_html += f\"\"\"\n",
        "                <div class=\"model-item\">\n",
        "                    <div class=\"model-info\">\n",
        "                        <div class=\"model-name\">{auth_indicator} {item_info['filename']}</div>\n",
        "                        <div class=\"model-description\">{item_info.get('description', 'No description available')}</div>\n",
        "                        <div class=\"model-size\">Size: {item_info['size']}</div>\n",
        "                    </div>\n",
        "                    <button class=\"download-btn\" onclick=\"startDownload('{item_key}', '{item_info['filename']}', {self.parse_size_to_bytes(item_info['size'])})\">\n",
        "                        üì• Download\n",
        "                    </button>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "\n",
        "            category_html += \"</div>\"\n",
        "\n",
        "        # Control panel\n",
        "        control_html = \"\"\"\n",
        "            <div class=\"category-card\">\n",
        "                <div class=\"category-header\">üéÆ Download Control Panel</div>\n",
        "                <div style=\"display: flex; gap: 10px; flex-wrap: wrap;\">\n",
        "                    <button class=\"download-btn\" onclick=\"downloadAll()\">üì¶ Download All Essential</button>\n",
        "                    <button class=\"download-btn\" onclick=\"downloadModelsOnly()\">üé¨ Models Only</button>\n",
        "                    <button class=\"download-btn\" onclick=\"downloadLoRAsOnly()\">‚ö° LoRAs Only</button>\n",
        "                    <button class=\"download-btn\" style=\"background: #dc3545;\" onclick=\"pauseAll()\">‚è∏Ô∏è Pause All</button>\n",
        "                    <button class=\"download-btn\" style=\"background: #ffc107; color: black;\" onclick=\"showAdvanced()\">‚öôÔ∏è Advanced Options</button>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        full_html = header_html + category_html + control_html\n",
        "\n",
        "        # Enhanced JavaScript for download control\n",
        "        enhanced_js = \"\"\"\n",
        "        <script>\n",
        "        function downloadAll() {\n",
        "            console.log('Starting download of all essential components...');\n",
        "            google.colab.kernel.invokeFunction('download_all_essential', [], {});\n",
        "        }\n",
        "\n",
        "        function downloadModelsOnly() {\n",
        "            console.log('Starting download of models only...');\n",
        "            google.colab.kernel.invokeFunction('download_models_only', [], {});\n",
        "        }\n",
        "\n",
        "        function downloadLoRAsOnly() {\n",
        "            console.log('Starting download of LoRAs only...');\n",
        "            google.colab.kernel.invokeFunction('download_loras_only', [], {});\n",
        "        }\n",
        "\n",
        "        function pauseAll() {\n",
        "            console.log('Pausing all downloads...');\n",
        "            // Implementation for pausing all downloads\n",
        "        }\n",
        "\n",
        "        function showAdvanced() {\n",
        "            console.log('Showing advanced options...');\n",
        "            // Implementation for advanced options\n",
        "        }\n",
        "        </script>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(full_html + enhanced_js))\n",
        "\n",
        "    def parse_size_to_bytes(self, size_str):\n",
        "        \"\"\"Parse size string to bytes for JavaScript\"\"\"\n",
        "        try:\n",
        "            size_parts = size_str.split()\n",
        "            if len(size_parts) >= 2:\n",
        "                number = float(size_parts[0])\n",
        "                unit = size_parts[1].upper()\n",
        "                multipliers = {\"GB\": 1024**3, \"MB\": 1024**2, \"KB\": 1024}\n",
        "                return int(number * multipliers.get(unit, 1))\n",
        "        except:\n",
        "            return 0\n",
        "        return 0\n",
        "\n",
        "    def download_with_hf_hub(self, url, filename, output_dir):\n",
        "        \"\"\"Download using HuggingFace Hub API with authentication\"\"\"\n",
        "        try:\n",
        "            if not self.hf_auth.authenticated:\n",
        "                return False\n",
        "\n",
        "            from huggingface_hub import hf_hub_download\n",
        "\n",
        "            # Parse HuggingFace URL\n",
        "            parsed_url = urlparse(url)\n",
        "            path_parts = parsed_url.path.strip('/').split('/')\n",
        "\n",
        "            if len(path_parts) >= 4:\n",
        "                repo_id = f\"{path_parts[0]}/{path_parts[1]}\"\n",
        "                file_path = \"/\".join(path_parts[3:])\n",
        "\n",
        "                print(f\"üì• Downloading with HuggingFace Hub API...\")\n",
        "                downloaded_file = hf_hub_download(\n",
        "                    repo_id=repo_id,\n",
        "                    filename=file_path,\n",
        "                    token=self.hf_auth.token,\n",
        "                    local_dir=output_dir,\n",
        "                    local_dir_use_symlinks=False\n",
        "                )\n",
        "\n",
        "                print(f\"‚úÖ HuggingFace Hub download successful\")\n",
        "                return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå HuggingFace Hub download failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def download_with_aria2c(self, url, filename, output_dir):\n",
        "        \"\"\"Download using aria2c with authentication headers\"\"\"\n",
        "        try:\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "            cmd = [\n",
        "                \"aria2c\",\n",
        "                \"-x\", \"16\",\n",
        "                \"-s\", \"16\",\n",
        "                \"-k\", \"1M\",\n",
        "                \"--continue\",\n",
        "                \"--dir\", output_dir,\n",
        "                \"--out\", filename,\n",
        "                url\n",
        "            ]\n",
        "\n",
        "            # Add authentication headers if available\n",
        "            if self.hf_auth.authenticated:\n",
        "                cmd.extend([\"--header\", f\"Authorization: Bearer {self.hf_auth.token}\"])\n",
        "\n",
        "            print(f\"üì• Downloading with aria2c (16 connections)...\")\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(f\"‚úÖ aria2c download successful\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå aria2c failed: {result.stderr[:200]}\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå aria2c error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def download_with_wget(self, url, filename, output_dir):\n",
        "        \"\"\"Download using wget with authentication\"\"\"\n",
        "        try:\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "            cmd = [\n",
        "                \"wget\",\n",
        "                \"--continue\",\n",
        "                \"--progress=bar\",\n",
        "                \"--timeout=30\",\n",
        "                \"--tries=3\",\n",
        "                \"-O\", output_path,\n",
        "                url\n",
        "            ]\n",
        "\n",
        "            # Add authentication headers if available\n",
        "            if self.hf_auth.authenticated:\n",
        "                cmd.extend([\"--header\", f\"Authorization: Bearer {self.hf_auth.token}\"])\n",
        "\n",
        "            print(f\"üì• Downloading with wget...\")\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(f\"‚úÖ wget download successful\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå wget failed: {result.stderr[:200]}\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå wget error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def download_with_python(self, url, filename, output_dir):\n",
        "        \"\"\"Download using Python urllib with authentication\"\"\"\n",
        "        try:\n",
        "            import urllib.request\n",
        "            import shutil\n",
        "\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "            print(f\"üì• Downloading with Python urllib...\")\n",
        "\n",
        "            # Create request with authentication if available\n",
        "            req = urllib.request.Request(url)\n",
        "            if self.hf_auth.authenticated:\n",
        "                req.add_header('Authorization', f'Bearer {self.hf_auth.token}')\n",
        "\n",
        "            with urllib.request.urlopen(req) as response:\n",
        "                with open(output_path, 'wb') as out_file:\n",
        "                    shutil.copyfileobj(response, out_file)\n",
        "\n",
        "            print(f\"‚úÖ Python download successful\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Python download failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def create_directory_structure(self):\n",
        "        \"\"\"Create necessary directories for downloads\"\"\"\n",
        "        directories = [\n",
        "            \"ckpts\", \"text_encoders\", \"vae\", \"vae_approx\", \"clip_vision\",\n",
        "            \"loras\", \"loras1.3B\", \"loras14B\", \"lorasi2v\", \"lorashunyuan\", \"lorasltxv\"\n",
        "        ]\n",
        "\n",
        "        print(\"üìÅ Creating directory structure...\")\n",
        "        for directory in directories:\n",
        "            Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"   ‚úÖ {directory}/\")\n",
        "\n",
        "        print(\"‚úÖ Directory structure created successfully\")\n",
        "\n",
        "    def run_enhanced_download_system(self):\n",
        "        \"\"\"Run the enhanced download system with full UI\"\"\"\n",
        "        # Create directory structure\n",
        "        self.create_directory_structure()\n",
        "\n",
        "        # Create enhanced UI\n",
        "        self.create_enhanced_ui()\n",
        "\n",
        "        print(\"\\nüéØ Enhanced Download System Ready!\")\n",
        "        print(\"‚ú® Features enabled:\")\n",
        "        print(\"  üîê HuggingFace authentication support\")\n",
        "        print(\"  üé® Rich interactive UI with progress tracking\")\n",
        "        print(\"  ‚ö° Multiple download methods with fallback\")\n",
        "        print(\"  üìä Real-time statistics and progress monitoring\")\n",
        "        print(\"  üîÑ Resume capability for interrupted downloads\")\n",
        "\n",
        "        return True\n",
        "\n",
        "# Colab function bindings for JavaScript integration\n",
        "def authenticate_hf(token):\n",
        "    \"\"\"Authenticate with HuggingFace (called from JavaScript)\"\"\"\n",
        "    global downloader\n",
        "    if downloader.hf_auth.authenticate(token):\n",
        "        print(\"üîë HuggingFace authentication successful!\")\n",
        "    else:\n",
        "        print(\"‚ùå HuggingFace authentication failed!\")\n",
        "\n",
        "def skip_hf_auth():\n",
        "    \"\"\"Skip HuggingFace authentication (called from JavaScript)\"\"\"\n",
        "    print(\"‚è≠Ô∏è Skipped HuggingFace authentication - using public access only\")\n",
        "\n",
        "def download_model(model_key):\n",
        "    \"\"\"Download specific model (called from JavaScript)\"\"\"\n",
        "    global downloader\n",
        "    print(f\"üöÄ Starting download of {model_key}...\")\n",
        "    # Implementation for downloading specific model\n",
        "\n",
        "def download_all_essential():\n",
        "    \"\"\"Download all essential components (called from JavaScript)\"\"\"\n",
        "    global downloader\n",
        "    print(\"üöÄ Starting download of all essential components...\")\n",
        "    # Implementation for downloading all essential files\n",
        "\n",
        "def download_models_only():\n",
        "    \"\"\"Download models only (called from JavaScript)\"\"\"\n",
        "    global downloader\n",
        "    print(\"üé¨ Starting download of models only...\")\n",
        "    # Implementation for downloading models only\n",
        "\n",
        "def download_loras_only():\n",
        "    \"\"\"Download LoRAs only (called from JavaScript)\"\"\"\n",
        "    global downloader\n",
        "    print(\"‚ö° Starting download of LoRAs only...\")\n",
        "    # Implementation for downloading LoRAs only\n",
        "\n",
        "# Execute the enhanced download system\n",
        "downloader = EnhancedModelDownloader()\n",
        "downloader.run_enhanced_download_system()\n"
      ],
      "metadata": {
        "id": "yP38IfT3_Gy9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 4 - WAN2GP Launch (Cross-Platform Final v6.0)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def jupyter_lab_title(title):\n",
        "    if 'google.colab' not in sys.modules:\n",
        "        from IPython.display import display, Markdown\n",
        "        display(Markdown(f\"## {title}\"))\n",
        "\n",
        "jupyter_lab_title(\"WAN2GP Launch (Cross-Platform Final)\")\n",
        "\n",
        "class CrossPlatformWAN2GPLauncher:\n",
        "    def __init__(self):\n",
        "        # Use global platform configuration\n",
        "        try:\n",
        "            self.current_platform = current_platform\n",
        "            self.pip_cmd = pip_cmd\n",
        "            self.python_cmd = python_cmd\n",
        "            self.use_venv = use_venv\n",
        "        except NameError:\n",
        "            print(\"‚ö†Ô∏è Platform detection not found. Using fallback.\")\n",
        "            if 'google.colab' in sys.modules:\n",
        "                self.current_platform = \"Google Colab\"\n",
        "                self.pip_cmd, self.python_cmd, self.use_venv = \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "            else:\n",
        "                self.current_platform = \"Lightning AI\"\n",
        "                self.pip_cmd, self.python_cmd, self.use_venv = \"pip\", \"python\", False\n",
        "\n",
        "        self.process = None\n",
        "        self.launch_success = False\n",
        "\n",
        "    def verify_environment(self):\n",
        "        \"\"\"Verify the environment setup\"\"\"\n",
        "        print(f\"\\nüîç Verifying Environment Setup\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"üìã Platform: {self.current_platform}\")\n",
        "        print(f\"üìã Python Command: {self.python_cmd}\")\n",
        "        print(f\"üìã Pip Command: {self.pip_cmd}\")\n",
        "        print(f\"üìã Virtual Environment: {'Yes' if self.use_venv else 'No (Lightning AI)'}\")\n",
        "\n",
        "        # Verify Python executable exists\n",
        "        if self.use_venv and not os.path.exists(self.python_cmd):\n",
        "            print(f\"‚ùå Virtual environment Python not found: {self.python_cmd}\")\n",
        "            return False\n",
        "\n",
        "        # Test basic Python functionality\n",
        "        try:\n",
        "            result = subprocess.run([\n",
        "                self.python_cmd, '-c', 'import sys; print(f\"Python: {sys.version}\"); print(f\"Executable: {sys.executable}\")'\n",
        "            ], capture_output=True, text=True, timeout=15)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(\"‚úÖ Python Environment Verified:\")\n",
        "                for line in result.stdout.strip().split('\\n'):\n",
        "                    if line.strip():\n",
        "                        print(f\"   {line}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå Python verification failed: {result.stderr}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Python verification error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def verify_pytorch(self):\n",
        "        \"\"\"Verify PyTorch installation\"\"\"\n",
        "        print(f\"\\nüî• PyTorch Verification\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        pytorch_test = '''\n",
        "import torch\n",
        "import sys\n",
        "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"‚úÖ uint16 support: {hasattr(torch, 'uint16')}\")\n",
        "print(f\"‚úÖ uint32 support: {hasattr(torch, 'uint32')}\")\n",
        "print(f\"‚úÖ Python executable: {sys.executable}\")\n",
        "'''\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run([\n",
        "                self.python_cmd, '-c', pytorch_test\n",
        "            ], capture_output=True, text=True, timeout=30)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(\"üìã PyTorch Status:\")\n",
        "                for line in result.stdout.strip().split('\\n'):\n",
        "                    if line.strip():\n",
        "                        print(f\"   {line}\")\n",
        "\n",
        "                # Check for correct PyTorch version\n",
        "                if \"2.6.0\" in result.stdout:\n",
        "                    print(\"\\n‚úÖ Correct PyTorch version 2.6.0 detected\")\n",
        "                    return True\n",
        "                else:\n",
        "                    print(\"\\n‚ö†Ô∏è PyTorch version mismatch detected\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(f\"‚ùå PyTorch verification failed: {result.stderr}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå PyTorch verification error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def test_wan2gp_imports(self):\n",
        "        \"\"\"Test WAN2GP imports\"\"\"\n",
        "        print(f\"\\nüß™ Testing WAN2GP Imports\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        import_test = '''\n",
        "import os\n",
        "os.environ[\"MPLBACKEND\"] = \"Agg\"  # Set safe matplotlib backend\n",
        "\n",
        "try:\n",
        "    from mmgp import offload, safetensors2, profile_type\n",
        "    print(\"‚úÖ WAN2GP core modules imported successfully\")\n",
        "    print(\"‚úÖ mmgp.offload: Available\")\n",
        "    print(\"‚úÖ mmgp.safetensors2: Available\")\n",
        "    print(\"‚úÖ mmgp.profile_type: Available\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå WAN2GP import error: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "print(\"‚úÖ All WAN2GP imports successful - ready to launch\")\n",
        "'''\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run([\n",
        "                self.python_cmd, '-c', import_test\n",
        "            ], capture_output=True, text=True, timeout=60)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(\"üìã Import Test Results:\")\n",
        "                for line in result.stdout.strip().split('\\n'):\n",
        "                    if line.strip():\n",
        "                        print(f\"   {line}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå WAN2GP import test failed:\")\n",
        "                for line in result.stderr.strip().split('\\n'):\n",
        "                    if line.strip():\n",
        "                        print(f\"   {line}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Import test error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def launch_wan2gp(self):\n",
        "        \"\"\"Launch WAN2GP with platform-specific configuration\"\"\"\n",
        "        print(f\"\\nüöÄ Launching WAN2GP on {self.current_platform}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Platform-specific launch configuration\n",
        "        base_cmd = [self.python_cmd, \"wgp.py\"]\n",
        "\n",
        "        launch_args = [\n",
        "            \"--i2v\",\n",
        "            \"--port\", \"7860\",\n",
        "            \"--server-name\", \"127.0.0.1\",\n",
        "            \"--share\",\n",
        "            \"--attention\", \"sdpa\",  # Most compatible\n",
        "            \"--profile\", \"4\",       # Memory efficient\n",
        "            \"--verbose\", \"1\"\n",
        "        ]\n",
        "\n",
        "        # Platform-specific optimizations\n",
        "        if self.current_platform == \"Lightning AI\":\n",
        "            print(\"‚ö° Lightning AI configuration applied\")\n",
        "        elif self.current_platform == \"Google Colab\":\n",
        "            launch_args.extend([\"--lora-dir\", \"/content/Wan2GP/loras\"])\n",
        "            print(\"üì± Google Colab configuration applied\")\n",
        "\n",
        "        launch_cmd = base_cmd + launch_args\n",
        "\n",
        "        print(f\"üìã Launch Command: {' '.join(launch_cmd)}\")\n",
        "        print(f\"üîó Server Port: 7860\")\n",
        "        print(f\"üêç Python: {self.python_cmd}\")\n",
        "        print(f\"üìã Platform: {self.current_platform}\")\n",
        "\n",
        "        # Set environment for clean launch\n",
        "        launch_env = os.environ.copy()\n",
        "        launch_env[\"MPLBACKEND\"] = \"Agg\"\n",
        "\n",
        "        if self.current_platform == \"Google Colab\":\n",
        "            print(\"\\nüì± Google Colab Access Instructions:\")\n",
        "            print(\"   1. Look for 'Running on public URL: https://...' in output below\")\n",
        "            print(\"   2. Click the public URL to access WAN2GP interface\")\n",
        "        elif self.current_platform == \"Lightning AI\":\n",
        "            print(\"\\n‚ö° Lightning AI Access Instructions:\")\n",
        "            print(\"   1. Look for 'Running on local URL: http://...' in output below\")\n",
        "            print(\"   2. Use Lightning AI's port forwarding for external access\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"üîÑ Starting WAN2GP server...\")\n",
        "        print(\"üí° This may take 1-3 minutes for initial model loading\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        try:\n",
        "            self.process = subprocess.Popen(\n",
        "                launch_cmd,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.STDOUT,\n",
        "                universal_newlines=True,\n",
        "                bufsize=1,\n",
        "                cwd=os.getcwd(),\n",
        "                env=launch_env\n",
        "            )\n",
        "\n",
        "            startup_timeout = 180\n",
        "            start_time = time.time()\n",
        "\n",
        "            while True:\n",
        "                if self.process.poll() is not None:\n",
        "                    return_code = self.process.returncode\n",
        "                    if return_code != 0:\n",
        "                        print(f\"\\n‚ùå WAN2GP process exited with error code: {return_code}\")\n",
        "                        return False\n",
        "                    else:\n",
        "                        print(f\"\\n‚úÖ WAN2GP process completed successfully\")\n",
        "                        return True\n",
        "\n",
        "                elapsed = time.time() - start_time\n",
        "                if elapsed > startup_timeout:\n",
        "                    print(f\"\\n‚è∞ Startup timeout reached ({startup_timeout}s)\")\n",
        "                    return True\n",
        "\n",
        "                try:\n",
        "                    line = self.process.stdout.readline()\n",
        "                    if line:\n",
        "                        line = line.rstrip()\n",
        "                        print(line)\n",
        "\n",
        "                        if \"Running on public URL:\" in line or \"Running on local URL:\" in line:\n",
        "                            print(\"\\nüéâ WAN2GP server started successfully!\")\n",
        "                            print(\"üåê Use the URLs above to access the interface\")\n",
        "                            self.launch_success = True\n",
        "                            return True\n",
        "\n",
        "                        if \"CUDA out of memory\" in line:\n",
        "                            print(\"\\nüí• CUDA memory error - try smaller model\")\n",
        "                            return False\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Output reading error: {e}\")\n",
        "                    break\n",
        "\n",
        "                time.sleep(0.1)\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nüí• Launch failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def run_complete_launch(self):\n",
        "        \"\"\"Execute complete launch sequence\"\"\"\n",
        "        print(\"üîß WAN2GP Complete Launch Sequence\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Step 1: Environment verification\n",
        "        if not self.verify_environment():\n",
        "            print(\"\\nüí• Environment verification failed\")\n",
        "            return False\n",
        "\n",
        "        # Step 2: PyTorch verification\n",
        "        if not self.verify_pytorch():\n",
        "            print(\"\\nüí• PyTorch verification failed\")\n",
        "            return False\n",
        "\n",
        "        # Step 3: WAN2GP imports\n",
        "        if not self.test_wan2gp_imports():\n",
        "            print(\"\\nüí• WAN2GP import test failed\")\n",
        "            return False\n",
        "\n",
        "        # Step 4: Launch WAN2GP\n",
        "        launch_success = self.launch_wan2gp()\n",
        "\n",
        "        if launch_success:\n",
        "            print(f\"\\nüéØ WAN2GP Launch Complete!\")\n",
        "            print(\"=\" * 60)\n",
        "            print(\"‚úÖ Status: Successfully launched\")\n",
        "            print(f\"‚úÖ Platform: {self.current_platform}\")\n",
        "            print(f\"‚úÖ Environment: {'Virtual Environment' if self.use_venv else 'System (Lightning AI)'}\")\n",
        "            print(\"‚úÖ Server: Running on port 7860\")\n",
        "\n",
        "            if self.current_platform == \"Google Colab\":\n",
        "                print(\"\\nüì± Next Steps:\")\n",
        "                print(\"   ‚Ä¢ Click the public URL above to access WAN2GP\")\n",
        "                print(\"   ‚Ä¢ Start with Wan 2.1 T2V 1.3B model for testing\")\n",
        "            elif self.current_platform == \"Lightning AI\":\n",
        "                print(\"\\n‚ö° Next Steps:\")\n",
        "                print(\"   ‚Ä¢ Use Lightning AI port forwarding for external access\")\n",
        "                print(\"   ‚Ä¢ System environment used as required\")\n",
        "\n",
        "            return True\n",
        "        else:\n",
        "            print(\"\\nüí• WAN2GP launch failed\")\n",
        "            return False\n",
        "\n",
        "# Create launcher and display platform info\n",
        "launcher = CrossPlatformWAN2GPLauncher()\n",
        "\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; margin: 15px 0;\">\n",
        "    <h3 style=\"margin: 0 0 15px 0;\">üöÄ WAN2GP Cross-Platform Launcher</h3>\n",
        "    <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px;\">\n",
        "        <p style=\"margin: 0 0 10px 0;\"><strong>Platform:</strong> {launcher.current_platform}</p>\n",
        "        <p style=\"margin: 0 0 10px 0;\"><strong>Environment:</strong> {'Virtual Environment' if launcher.use_venv else 'System (Lightning AI compliant)'}</p>\n",
        "        <p style=\"margin: 0 0 10px 0;\"><strong>Python:</strong> {launcher.python_cmd}</p>\n",
        "        <p style=\"margin: 0;\"><strong>Configuration:</strong> Cross-platform optimized with automatic platform detection</p>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "# Execute launch sequence\n",
        "success = launcher.run_complete_launch()\n",
        "\n",
        "if success:\n",
        "    display(HTML(\"\"\"\n",
        "    <div style=\"background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
        "        <h4 style=\"margin: 0 0 10px 0;\">‚úÖ WAN2GP Successfully Launched!</h4>\n",
        "        <p style=\"margin: 0;\">The WAN2GP video generation interface is now running with proper cross-platform configuration.</p>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "else:\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"background-color: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
        "        <h4 style=\"margin: 0 0 10px 0;\">‚ö†Ô∏è Launch Failed</h4>\n",
        "        <p style=\"margin: 0 0 10px 0;\">Platform: {launcher.current_platform}</p>\n",
        "        <p style=\"margin: 0;\">Please check the error output above and try the emergency launch command:</p>\n",
        "        <code style=\"background: #f1f1f1; padding: 5px; border-radius: 3px; display: block; margin: 5px 0;\">\n",
        "        {launcher.python_cmd} wgp.py --attention sdpa --profile 4\n",
        "        </code>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "print(\"\\n‚ú® Cross-platform Cell 4 execution complete!\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GU-zDsAW_MwT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "008d06c1-15b8-4565-80ed-bb89b543c92b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; margin: 15px 0;\">\n",
              "    <h3 style=\"margin: 0 0 15px 0;\">üöÄ WAN2GP Cross-Platform Launcher</h3>\n",
              "    <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px;\">\n",
              "        <p style=\"margin: 0 0 10px 0;\"><strong>Platform:</strong> Google Colab</p>\n",
              "        <p style=\"margin: 0 0 10px 0;\"><strong>Environment:</strong> Virtual Environment</p>\n",
              "        <p style=\"margin: 0 0 10px 0;\"><strong>Python:</strong> .venv/bin/python</p>\n",
              "        <p style=\"margin: 0;\"><strong>Configuration:</strong> Cross-platform optimized with automatic platform detection</p>\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß WAN2GP Complete Launch Sequence\n",
            "============================================================\n",
            "\n",
            "üîç Verifying Environment Setup\n",
            "==================================================\n",
            "üìã Platform: Google Colab\n",
            "üìã Python Command: .venv/bin/python\n",
            "üìã Pip Command: .venv/bin/pip\n",
            "üìã Virtual Environment: Yes\n",
            "‚úÖ Python Environment Verified:\n",
            "   Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "   Executable: /content/Wan2GP/Wan2GP/.venv/bin/python\n",
            "\n",
            "üî• PyTorch Verification\n",
            "------------------------------\n",
            "‚ùå PyTorch verification failed: \n",
            "\n",
            "üí• PyTorch verification failed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
              "        <h4 style=\"margin: 0 0 10px 0;\">‚ö†Ô∏è Launch Failed</h4>\n",
              "        <p style=\"margin: 0 0 10px 0;\">Platform: Google Colab</p>\n",
              "        <p style=\"margin: 0;\">Please check the error output above and try the emergency launch command:</p>\n",
              "        <code style=\"background: #f1f1f1; padding: 5px; border-radius: 3px; display: block; margin: 5px 0;\">\n",
              "        .venv/bin/python wgp.py --attention sdpa --profile 4\n",
              "        </code>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® Cross-platform Cell 4 execution complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (1) - WAN2GP Comprehensive Diagnostic and Auto-Repair System (Latest v6.2 Compatible)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import importlib.util\n",
        "\n",
        "class WAN2GPDiagnosticAndRepair:\n",
        "    def __init__(self):\n",
        "        self.platform = self.detect_platform()\n",
        "        self.pip_cmd, self.python_cmd, self.use_venv = self.get_platform_commands()\n",
        "        self.issues_found = []\n",
        "        self.repairs_applied = []\n",
        "        self.gpu_info = {}\n",
        "\n",
        "    def detect_platform(self):\n",
        "        \"\"\"Enhanced platform detection with comprehensive indicators\"\"\"\n",
        "        # Lightning AI detection - multiple indicators for reliability\n",
        "        lightning_indicators = [\n",
        "            \"lightning\" in str(sys.executable).lower(),\n",
        "            \"teamspace-studios\" in os.getcwd(),\n",
        "            \"LIGHTNING_CLOUDSPACE_HOST\" in os.environ,\n",
        "            \"LIGHTNING_CLOUDSPACE_ID\" in os.environ,\n",
        "            \"/commands/python\" in str(sys.executable),\n",
        "            \"/home/zeus/miniconda3/envs/cloudspace\" in str(sys.executable),\n",
        "            os.path.exists(\"/teamspace\"),\n",
        "            os.path.exists(\"/commands\")\n",
        "        ]\n",
        "\n",
        "        # Google Colab detection\n",
        "        colab_indicators = [\n",
        "            \"google.colab\" in sys.modules,\n",
        "            \"/content\" in os.getcwd()\n",
        "        ]\n",
        "\n",
        "        # Vast.AI detection\n",
        "        vast_indicators = [\n",
        "            \"VAST_CONTAINER_LABEL\" in os.environ,\n",
        "            \"/workspace\" in os.getcwd(),\n",
        "            \"vast\" in os.environ.get(\"HOSTNAME\", \"\").lower()\n",
        "        ]\n",
        "\n",
        "        if any(lightning_indicators):\n",
        "            return \"Lightning AI\"\n",
        "        elif any(colab_indicators):\n",
        "            return \"Google Colab\"\n",
        "        elif any(vast_indicators):\n",
        "            return \"Vast.AI/Generic\"\n",
        "        else:\n",
        "            return \"Vast.AI/Generic\"\n",
        "\n",
        "    def get_platform_commands(self):\n",
        "        \"\"\"Get platform-specific pip and python commands\"\"\"\n",
        "        if self.platform == \"Lightning AI\":\n",
        "            return \"pip\", \"python\", False  # (pip_cmd, python_cmd, use_venv)\n",
        "        elif self.platform == \"Google Colab\":\n",
        "            return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "        else:  # Vast.AI/Generic\n",
        "            return \".venv/bin/pip\", \".venv/bin/python\", True\n",
        "\n",
        "    def run_command_safely(self, command, description, timeout=60):\n",
        "        \"\"\"Execute command with comprehensive error handling\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                command, capture_output=True, text=True, timeout=timeout, shell=isinstance(command, str)\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                return True, result.stdout\n",
        "            else:\n",
        "                return False, result.stderr\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, f\"Timeout after {timeout}s\"\n",
        "        except Exception as e:\n",
        "            return False, str(e)\n",
        "\n",
        "    def check_gpu_compatibility(self):\n",
        "        \"\"\"Comprehensive GPU detection and compatibility check\"\"\"\n",
        "        print(\"üîç Checking GPU compatibility...\")\n",
        "\n",
        "        # Check NVIDIA GPU presence\n",
        "        success, output = self.run_command_safely(\"nvidia-smi\", \"GPU Detection\")\n",
        "        if not success:\n",
        "            self.issues_found.append(\"No NVIDIA GPU detected or nvidia-smi not available\")\n",
        "            return False\n",
        "\n",
        "        # Parse GPU info\n",
        "        try:\n",
        "            # Extract GPU name and VRAM from nvidia-smi output\n",
        "            lines = output.split('\\n')\n",
        "            for line in lines:\n",
        "                if 'RTX' in line or 'GTX' in line or 'Tesla' in line or 'A100' in line:\n",
        "                    gpu_name = line.split('|')[1].strip() if '|' in line else \"Unknown GPU\"\n",
        "                    self.gpu_info['name'] = gpu_name\n",
        "                    break\n",
        "\n",
        "            # Check VRAM\n",
        "            for line in lines:\n",
        "                if 'MiB' in line and '/' in line:\n",
        "                    vram_info = [part for part in line.split() if 'MiB' in part]\n",
        "                    if len(vram_info) >= 2:\n",
        "                        total_vram = int(vram_info[-1].replace('MiB', ''))\n",
        "                        self.gpu_info['vram_mb'] = total_vram\n",
        "                        self.gpu_info['vram_gb'] = total_vram / 1024\n",
        "                        break\n",
        "\n",
        "            print(f\"‚úÖ GPU detected: {self.gpu_info.get('name', 'Unknown')}\")\n",
        "            print(f\"‚úÖ VRAM: {self.gpu_info.get('vram_gb', 0):.1f}GB\")\n",
        "\n",
        "            # Check VRAM adequacy\n",
        "            vram_gb = self.gpu_info.get('vram_gb', 0)\n",
        "            if vram_gb < 6:\n",
        "                self.issues_found.append(f\"Low VRAM detected ({vram_gb:.1f}GB). Minimum 6GB recommended.\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.issues_found.append(f\"GPU info parsing failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def check_cuda_pytorch_compatibility(self):\n",
        "        \"\"\"Check CUDA and PyTorch compatibility\"\"\"\n",
        "        print(\"üîç Checking CUDA and PyTorch compatibility...\")\n",
        "\n",
        "        # Check CUDA version\n",
        "        success, cuda_output = self.run_command_safely(\"nvcc --version\", \"CUDA Version Check\")\n",
        "        if not success:\n",
        "            success, cuda_output = self.run_command_safely(\"nvidia-smi\", \"CUDA Runtime Check\")\n",
        "\n",
        "        # Check PyTorch installation\n",
        "        try:\n",
        "            import torch\n",
        "            pytorch_version = torch.__version__\n",
        "            cuda_available = torch.cuda.is_available()\n",
        "\n",
        "            print(f\"‚úÖ PyTorch version: {pytorch_version}\")\n",
        "            print(f\"‚úÖ CUDA available in PyTorch: {cuda_available}\")\n",
        "\n",
        "            if not cuda_available:\n",
        "                self.issues_found.append(\"PyTorch cannot detect CUDA\")\n",
        "                return False\n",
        "\n",
        "            # Check for version compatibility\n",
        "            if \"50\" in self.gpu_info.get('name', '') and not pytorch_version.startswith('2.7'):\n",
        "                self.issues_found.append(\"RTX 50XX series requires PyTorch 2.7.0 or newer\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except ImportError:\n",
        "            self.issues_found.append(\"PyTorch not installed\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            self.issues_found.append(f\"PyTorch check failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def check_python_version(self):\n",
        "        \"\"\"Check Python version compatibility\"\"\"\n",
        "        print(\"üîç Checking Python version...\")\n",
        "\n",
        "        python_version = sys.version_info\n",
        "        version_string = f\"{python_version.major}.{python_version.minor}.{python_version.micro}\"\n",
        "        print(f\"‚úÖ Python version: {version_string}\")\n",
        "\n",
        "        if python_version.major != 3 or python_version.minor != 10:\n",
        "            self.issues_found.append(f\"Python {version_string} detected. Python 3.10.9 recommended for best compatibility.\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def check_wan2gp_installation(self):\n",
        "        \"\"\"Check WAN2GP installation and repository\"\"\"\n",
        "        print(\"üîç Checking WAN2GP installation...\")\n",
        "\n",
        "        wan2gp_paths = [\"Wan2GP\", \"wan2gp\", \"WAN2GP\", \"../Wan2GP\", \"../wan2gp\"]\n",
        "        wan2gp_found = False\n",
        "\n",
        "        for path in wan2gp_paths:\n",
        "            if os.path.exists(path):\n",
        "                wan2gp_found = True\n",
        "                wgp_py_path = os.path.join(path, \"wgp.py\")\n",
        "                if os.path.exists(wgp_py_path):\n",
        "                    print(f\"‚úÖ WAN2GP found at: {path}\")\n",
        "                    return True\n",
        "                break\n",
        "\n",
        "        if not wan2gp_found:\n",
        "            self.issues_found.append(\"WAN2GP repository not found\")\n",
        "            return False\n",
        "\n",
        "        self.issues_found.append(\"WAN2GP repository found but wgp.py missing\")\n",
        "        return False\n",
        "\n",
        "    def check_dependencies(self):\n",
        "        \"\"\"Check critical dependencies\"\"\"\n",
        "        print(\"üîç Checking critical dependencies...\")\n",
        "\n",
        "        critical_deps = {\n",
        "            'torch': 'PyTorch',\n",
        "            'torchvision': 'TorchVision',\n",
        "            'gradio': 'Gradio',\n",
        "            'transformers': 'Transformers',\n",
        "            'accelerate': 'Accelerate',\n",
        "            'diffusers': 'Diffusers'\n",
        "        }\n",
        "\n",
        "        missing_deps = []\n",
        "        for dep, name in critical_deps.items():\n",
        "            try:\n",
        "                importlib.import_module(dep)\n",
        "                print(f\"‚úÖ {name} installed\")\n",
        "            except ImportError:\n",
        "                missing_deps.append(dep)\n",
        "                print(f\"‚ùå {name} missing\")\n",
        "\n",
        "        if missing_deps:\n",
        "            self.issues_found.append(f\"Missing dependencies: {', '.join(missing_deps)}\")\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def check_attention_mechanisms(self):\n",
        "        \"\"\"Check available attention mechanisms\"\"\"\n",
        "        print(\"üîç Checking attention mechanisms...\")\n",
        "\n",
        "        attention_status = {}\n",
        "\n",
        "        # Check Triton\n",
        "        try:\n",
        "            import triton\n",
        "            attention_status['triton'] = f\"‚úÖ Triton {triton.__version__}\"\n",
        "        except ImportError:\n",
        "            attention_status['triton'] = \"‚ùå Triton not available\"\n",
        "\n",
        "        # Check SageAttention\n",
        "        try:\n",
        "            import sageattention\n",
        "            attention_status['sage'] = \"‚úÖ SageAttention available\"\n",
        "        except ImportError:\n",
        "            attention_status['sage'] = \"‚ùå SageAttention not available\"\n",
        "\n",
        "        # Check Flash Attention\n",
        "        try:\n",
        "            import flash_attn\n",
        "            attention_status['flash'] = \"‚úÖ Flash Attention available\"\n",
        "        except ImportError:\n",
        "            attention_status['flash'] = \"‚ùå Flash Attention not available\"\n",
        "\n",
        "        for mech, status in attention_status.items():\n",
        "            print(f\"  {status}\")\n",
        "\n",
        "        # Recommend fallback if advanced attention not available\n",
        "        if all(\"‚ùå\" in status for status in attention_status.values()):\n",
        "            self.issues_found.append(\"No advanced attention mechanisms available. Will use SDPA fallback.\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def check_memory_and_performance(self):\n",
        "        \"\"\"Check memory and performance configuration\"\"\"\n",
        "        print(\"üîç Checking memory and performance...\")\n",
        "\n",
        "        # Check available system RAM\n",
        "        try:\n",
        "            import psutil\n",
        "            ram_gb = psutil.virtual_memory().total / (1024**3)\n",
        "            print(f\"‚úÖ System RAM: {ram_gb:.1f}GB\")\n",
        "\n",
        "            if ram_gb < 16:\n",
        "                self.issues_found.append(f\"Low system RAM ({ram_gb:.1f}GB). 16GB+ recommended for best performance.\")\n",
        "        except ImportError:\n",
        "            print(\"‚ö†Ô∏è Cannot check system RAM (psutil not available)\")\n",
        "\n",
        "        # Check disk space\n",
        "        try:\n",
        "            disk_usage = shutil.disk_usage(os.getcwd())\n",
        "            free_gb = disk_usage.free / (1024**3)\n",
        "            print(f\"‚úÖ Free disk space: {free_gb:.1f}GB\")\n",
        "\n",
        "            if free_gb < 20:\n",
        "                self.issues_found.append(f\"Low disk space ({free_gb:.1f}GB). 20GB+ recommended.\")\n",
        "        except Exception:\n",
        "            print(\"‚ö†Ô∏è Cannot check disk space\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def auto_repair_pytorch(self):\n",
        "        \"\"\"Auto-repair PyTorch installation\"\"\"\n",
        "        print(\"üîß Attempting PyTorch repair...\")\n",
        "\n",
        "        # Determine correct PyTorch version based on GPU\n",
        "        if \"50\" in self.gpu_info.get('name', ''):\n",
        "            # RTX 50XX series\n",
        "            pytorch_cmd = [\n",
        "                self.pip_cmd, \"install\", \"--upgrade\",\n",
        "                \"torch==2.7.0\", \"torchvision\", \"torchaudio\",\n",
        "                \"--index-url\", \"https://download.pytorch.org/whl/test/cu128\"\n",
        "            ]\n",
        "        else:\n",
        "            # RTX 10XX-40XX series\n",
        "            pytorch_cmd = [\n",
        "                self.pip_cmd, \"install\", \"--upgrade\",\n",
        "                \"torch==2.6.0\", \"torchvision\", \"torchaudio\",\n",
        "                \"--index-url\", \"https://download.pytorch.org/whl/test/cu124\"\n",
        "            ]\n",
        "\n",
        "        success, output = self.run_command_safely(pytorch_cmd, \"PyTorch Installation\", timeout=300)\n",
        "        if success:\n",
        "            self.repairs_applied.append(\"PyTorch installation repaired\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå PyTorch repair failed: {output}\")\n",
        "            return False\n",
        "\n",
        "    def auto_repair_dependencies(self):\n",
        "        \"\"\"Auto-repair missing dependencies\"\"\"\n",
        "        print(\"üîß Installing missing dependencies...\")\n",
        "\n",
        "        # Install core requirements\n",
        "        requirements_cmd = [self.pip_cmd, \"install\", \"-r\", \"requirements.txt\"]\n",
        "        success, output = self.run_command_safely(requirements_cmd, \"Dependencies Installation\", timeout=300)\n",
        "\n",
        "        if success:\n",
        "            self.repairs_applied.append(\"Dependencies installed\")\n",
        "            return True\n",
        "        else:\n",
        "            # Fallback: install critical packages individually\n",
        "            critical_packages = [\n",
        "                \"gradio>=4.0.0\", \"transformers\", \"accelerate\", \"diffusers\",\n",
        "                \"opencv-python\", \"Pillow\", \"numpy\", \"scipy\"\n",
        "            ]\n",
        "\n",
        "            for package in critical_packages:\n",
        "                cmd = [self.pip_cmd, \"install\", package]\n",
        "                success, _ = self.run_command_safely(cmd, f\"Installing {package}\", timeout=60)\n",
        "                if success:\n",
        "                    print(f\"‚úÖ Installed {package}\")\n",
        "\n",
        "            self.repairs_applied.append(\"Critical dependencies installed individually\")\n",
        "            return True\n",
        "\n",
        "    def auto_repair_wan2gp_repo(self):\n",
        "        \"\"\"Auto-repair WAN2GP repository\"\"\"\n",
        "        print(\"üîß Cloning WAN2GP repository...\")\n",
        "\n",
        "        repo_url = \"https://github.com/deepbeepmeep/Wan2GP.git\"\n",
        "        clone_cmd = [\"git\", \"clone\", \"--depth\", \"1\", repo_url]\n",
        "\n",
        "        success, output = self.run_command_safely(clone_cmd, \"Repository Clone\", timeout=120)\n",
        "        if success:\n",
        "            self.repairs_applied.append(\"WAN2GP repository cloned\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå Repository clone failed: {output}\")\n",
        "            return False\n",
        "\n",
        "    def auto_repair_attention_mechanisms(self):\n",
        "        \"\"\"Auto-repair attention mechanisms\"\"\"\n",
        "        print(\"üîß Installing performance optimizations...\")\n",
        "\n",
        "        repairs = []\n",
        "\n",
        "        # Install Triton for Windows\n",
        "        if os.name == 'nt':  # Windows\n",
        "            triton_cmd = [self.pip_cmd, \"install\", \"triton-windows\"]\n",
        "            success, _ = self.run_command_safely(triton_cmd, \"Triton Installation\", timeout=120)\n",
        "            if success:\n",
        "                repairs.append(\"Triton (Windows)\")\n",
        "\n",
        "        # Install SageAttention\n",
        "        sage_cmd = [self.pip_cmd, \"install\", \"sageattention>=1.0.6\"]\n",
        "        success, _ = self.run_command_safely(sage_cmd, \"SageAttention Installation\", timeout=120)\n",
        "        if success:\n",
        "            repairs.append(\"SageAttention\")\n",
        "\n",
        "        if repairs:\n",
        "            self.repairs_applied.append(f\"Installed: {', '.join(repairs)}\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def generate_optimized_launch_commands(self):\n",
        "        \"\"\"Generate optimized launch commands based on hardware\"\"\"\n",
        "        print(\"\\nüöÄ Generating optimized launch commands...\")\n",
        "\n",
        "        vram_gb = self.gpu_info.get('vram_gb', 8)\n",
        "        gpu_name = self.gpu_info.get('name', 'Unknown')\n",
        "\n",
        "        commands = {}\n",
        "\n",
        "        # Base command components\n",
        "        base_cmd = \"python wgp.py\"\n",
        "\n",
        "        if vram_gb < 8:\n",
        "            # Low VRAM setup\n",
        "            commands['Low VRAM (6-8GB)'] = f\"{base_cmd} --t2v-1-3B --attention sdpa --profile 4 --teacache 1.5\"\n",
        "        elif vram_gb < 12:\n",
        "            # Medium VRAM setup\n",
        "            commands['Medium VRAM (8-12GB)'] = f\"{base_cmd} --t2v-14B --attention sage --profile 4 --teacache 2.0\"\n",
        "        else:\n",
        "            # High VRAM setup\n",
        "            commands['High VRAM (12GB+)'] = f\"{base_cmd} --t2v-14B --attention sage2 --profile 3 --compile --teacache 2.0\"\n",
        "\n",
        "        # GPU-specific optimizations\n",
        "        if \"10\" in gpu_name or \"20\" in gpu_name:\n",
        "            commands['RTX 10XX/20XX Optimized'] = f\"{base_cmd} --attention sdpa --profile 4 --teacache 1.5\"\n",
        "        elif \"30\" in gpu_name or \"40\" in gpu_name:\n",
        "            commands['RTX 30XX/40XX Optimized'] = f\"{base_cmd} --compile --attention sage --profile 3 --teacache 2.0\"\n",
        "        elif \"50\" in gpu_name:\n",
        "            commands['RTX 50XX Optimized'] = f\"{base_cmd} --attention sage --profile 4 --fp16\"\n",
        "\n",
        "        # Fallback command\n",
        "        commands['Safe Fallback'] = f\"{base_cmd} --t2v-1-3B --attention sdpa --profile 4 --teacache 0 --fp16\"\n",
        "\n",
        "        # Debug command\n",
        "        commands['Debug Mode'] = f\"{base_cmd} --verbose 2 --check-loras --attention sdpa --profile 4\"\n",
        "\n",
        "        return commands\n",
        "\n",
        "    def run_full_diagnostic(self):\n",
        "        \"\"\"Run complete diagnostic and repair sequence\"\"\"\n",
        "        print(\"üè• WAN2GP Comprehensive Diagnostic and Auto-Repair System\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"üñ•Ô∏è Platform: {self.platform}\")\n",
        "        print(f\"üêç Python: {self.python_cmd}\")\n",
        "        print(f\"üì¶ Pip: {self.pip_cmd}\")\n",
        "        print(f\"üîß Virtual Environment: {'Yes' if self.use_venv else 'No'}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Run all diagnostics\n",
        "        checks = [\n",
        "            self.check_python_version,\n",
        "            self.check_gpu_compatibility,\n",
        "            self.check_cuda_pytorch_compatibility,\n",
        "            self.check_wan2gp_installation,\n",
        "            self.check_dependencies,\n",
        "            self.check_attention_mechanisms,\n",
        "            self.check_memory_and_performance\n",
        "        ]\n",
        "\n",
        "        print(\"\\nüìã Running Diagnostics...\")\n",
        "        for check in checks:\n",
        "            try:\n",
        "                check()\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Diagnostic error: {str(e)}\")\n",
        "                self.issues_found.append(f\"Diagnostic error: {str(e)}\")\n",
        "\n",
        "        # Auto-repair if issues found\n",
        "        if self.issues_found:\n",
        "            print(f\"\\n‚ö†Ô∏è Found {len(self.issues_found)} issues:\")\n",
        "            for i, issue in enumerate(self.issues_found, 1):\n",
        "                print(f\"  {i}. {issue}\")\n",
        "\n",
        "            print(f\"\\nüîß Attempting automatic repairs...\")\n",
        "\n",
        "            # Apply repairs based on issues found\n",
        "            if any(\"PyTorch\" in issue for issue in self.issues_found):\n",
        "                self.auto_repair_pytorch()\n",
        "\n",
        "            if any(\"dependencies\" in issue.lower() for issue in self.issues_found):\n",
        "                self.auto_repair_dependencies()\n",
        "\n",
        "            if any(\"repository\" in issue.lower() for issue in self.issues_found):\n",
        "                self.auto_repair_wan2gp_repo()\n",
        "\n",
        "            if any(\"attention\" in issue.lower() for issue in self.issues_found):\n",
        "                self.auto_repair_attention_mechanisms()\n",
        "\n",
        "        # Generate launch commands\n",
        "        commands = self.generate_optimized_launch_commands()\n",
        "\n",
        "        # Final report\n",
        "        self.display_final_report(commands)\n",
        "\n",
        "    def display_final_report(self, commands):\n",
        "        \"\"\"Display comprehensive final report\"\"\"\n",
        "\n",
        "        # Create styled HTML report\n",
        "        html_report = f\"\"\"\n",
        "        <div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                    color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n",
        "            <h2>üè• WAN2GP Diagnostic Report</h2>\n",
        "            <div style=\"background-color: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "                <h3>üìä System Status</h3>\n",
        "                <p><strong>Platform:</strong> {self.platform}</p>\n",
        "                <p><strong>GPU:</strong> {self.gpu_info.get('name', 'Unknown')} ({self.gpu_info.get('vram_gb', 0):.1f}GB VRAM)</p>\n",
        "                <p><strong>Issues Found:</strong> {len(self.issues_found)}</p>\n",
        "                <p><strong>Repairs Applied:</strong> {len(self.repairs_applied)}</p>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        if self.repairs_applied:\n",
        "            html_report += f\"\"\"\n",
        "            <div style=\"background-color: #28a745; color: white; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "                <h3>‚úÖ Repairs Applied Successfully:</h3>\n",
        "                <ul>\n",
        "            \"\"\"\n",
        "            for repair in self.repairs_applied:\n",
        "                html_report += f\"<li>{repair}</li>\"\n",
        "            html_report += \"</ul></div>\"\n",
        "\n",
        "        if self.issues_found and not self.repairs_applied:\n",
        "            html_report += f\"\"\"\n",
        "            <div style=\"background-color: #dc3545; color: white; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "                <h3>‚ö†Ô∏è Unresolved Issues:</h3>\n",
        "                <ul>\n",
        "            \"\"\"\n",
        "            for issue in self.issues_found:\n",
        "                html_report += f\"<li>{issue}</li>\"\n",
        "            html_report += \"</ul></div>\"\n",
        "\n",
        "        display(HTML(html_report))\n",
        "\n",
        "        # Display optimized commands\n",
        "        print(\"\\nüöÄ Recommended Launch Commands:\")\n",
        "        print(\"=\" * 50)\n",
        "        for name, command in commands.items():\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  {command}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"‚úÖ Diagnostic complete! Use the appropriate command above to launch WAN2GP.\")\n",
        "        if self.issues_found and not self.repairs_applied:\n",
        "            print(\"‚ö†Ô∏è  Some issues require manual intervention. Check the report above.\")\n",
        "\n",
        "# Execute diagnostic system\n",
        "diagnostic_system = WAN2GPDiagnosticAndRepair()\n",
        "diagnostic_system.run_full_diagnostic()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZzJeUGqaCLJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell (2) - Quick Diagnostic Runner and Emergency Repair Tools (Latest v6.2)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "class QuickDiagnosticRunner:\n",
        "    def __init__(self):\n",
        "        self.platform = self.detect_platform()\n",
        "        self.pip_cmd, self.python_cmd = self.get_platform_commands()\n",
        "\n",
        "    def detect_platform(self):\n",
        "        \"\"\"Quick platform detection\"\"\"\n",
        "        if \"google.colab\" in sys.modules:\n",
        "            return \"Google Colab\"\n",
        "        elif any(indicator in str(sys.executable).lower() for indicator in [\"lightning\", \"teamspace\"]):\n",
        "            return \"Lightning AI\"\n",
        "        else:\n",
        "            return \"Generic/Vast.AI\"\n",
        "\n",
        "    def get_platform_commands(self):\n",
        "        \"\"\"Get platform-specific commands\"\"\"\n",
        "        if self.platform == \"Lightning AI\":\n",
        "            return \"pip\", \"python\"\n",
        "        else:\n",
        "            return \".venv/bin/pip\" if os.path.exists(\".venv\") else \"pip\", \".venv/bin/python\" if os.path.exists(\".venv\") else \"python\"\n",
        "\n",
        "    def run_cmd(self, cmd, timeout=30):\n",
        "        \"\"\"Execute command safely\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)\n",
        "            return result.returncode == 0, result.stdout, result.stderr\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, \"\", \"Timeout\"\n",
        "        except Exception as e:\n",
        "            return False, \"\", str(e)\n",
        "\n",
        "    def emergency_pytorch_fix(self):\n",
        "        \"\"\"Emergency PyTorch installation fix\"\"\"\n",
        "        print(\"üö® Emergency PyTorch Fix...\")\n",
        "\n",
        "        # Detect GPU generation for correct PyTorch version\n",
        "        success, gpu_info, _ = self.run_cmd(\"nvidia-smi\")\n",
        "\n",
        "        if \"RTX 50\" in gpu_info:\n",
        "            pytorch_url = \"https://download.pytorch.org/whl/test/cu128\"\n",
        "            torch_version = \"torch==2.7.0\"\n",
        "        else:\n",
        "            pytorch_url = \"https://download.pytorch.org/whl/test/cu124\"\n",
        "            torch_version = \"torch==2.6.0\"\n",
        "\n",
        "        cmd = f\"{self.pip_cmd} install --upgrade {torch_version} torchvision torchaudio --index-url {pytorch_url}\"\n",
        "        success, stdout, stderr = self.run_cmd(cmd, timeout=300)\n",
        "\n",
        "        if success:\n",
        "            print(\"‚úÖ PyTorch emergency fix applied\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå PyTorch fix failed: {stderr}\")\n",
        "            return False\n",
        "\n",
        "    def emergency_dependency_fix(self):\n",
        "        \"\"\"Emergency dependency installation\"\"\"\n",
        "        print(\"üö® Emergency Dependency Fix...\")\n",
        "\n",
        "        essential_packages = [\n",
        "            \"gradio>=4.0.0\", \"transformers\", \"accelerate\", \"diffusers\",\n",
        "            \"opencv-python\", \"Pillow\", \"numpy\", \"scipy\", \"psutil\"\n",
        "        ]\n",
        "\n",
        "        for package in essential_packages:\n",
        "            cmd = f\"{self.pip_cmd} install {package}\"\n",
        "            success, _, _ = self.run_cmd(cmd, timeout=60)\n",
        "            print(\"‚úÖ\" if success else \"‚ùå\", package)\n",
        "\n",
        "        print(\"‚úÖ Emergency dependencies installed\")\n",
        "\n",
        "    def quick_system_check(self):\n",
        "        \"\"\"Quick system health check\"\"\"\n",
        "        checks = {}\n",
        "\n",
        "        # GPU Check\n",
        "        success, output, _ = self.run_cmd(\"nvidia-smi\")\n",
        "        checks['GPU'] = \"‚úÖ Available\" if success and \"RTX\" in output else \"‚ùå Issue detected\"\n",
        "\n",
        "        # PyTorch Check\n",
        "        try:\n",
        "            import torch\n",
        "            checks['PyTorch'] = f\"‚úÖ {torch.__version__}\" if torch.cuda.is_available() else \"‚ùå CUDA not available\"\n",
        "        except ImportError:\n",
        "            checks['PyTorch'] = \"‚ùå Not installed\"\n",
        "\n",
        "        # WAN2GP Check\n",
        "        wan_exists = any(os.path.exists(path) for path in [\"Wan2GP/wgp.py\", \"wan2gp/wgp.py\", \"WAN2GP/wgp.py\"])\n",
        "        checks['WAN2GP'] = \"‚úÖ Found\" if wan_exists else \"‚ùå Missing\"\n",
        "\n",
        "        # Dependencies Check\n",
        "        try:\n",
        "            import gradio, transformers, accelerate, diffusers\n",
        "            checks['Dependencies'] = \"‚úÖ Core packages available\"\n",
        "        except ImportError:\n",
        "            checks['Dependencies'] = \"‚ùå Missing packages\"\n",
        "\n",
        "        return checks\n",
        "\n",
        "    def generate_emergency_commands(self):\n",
        "        \"\"\"Generate emergency launch commands\"\"\"\n",
        "        commands = {\n",
        "            \"Ultra Safe Mode\": f\"{self.python_cmd} wgp.py --t2v-1-3B --attention sdpa --profile 4 --teacache 0 --fp16\",\n",
        "            \"Memory Emergency\": f\"{self.python_cmd} wgp.py --t2v-1-3B --profile 5 --perc-reserved-mem-max 0.2\",\n",
        "            \"Debug Mode\": f\"{self.python_cmd} wgp.py --verbose 2 --attention sdpa --profile 4\",\n",
        "            \"Network Share\": f\"{self.python_cmd} wgp.py --listen --server-port 7861 --attention sdpa\"\n",
        "        }\n",
        "        return commands\n",
        "\n",
        "    def run_quick_diagnostic(self):\n",
        "        \"\"\"Run quick diagnostic and provide emergency options\"\"\"\n",
        "\n",
        "        print(f\"‚ö° Quick Diagnostic - Platform: {self.platform}\")\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "        # Quick system check\n",
        "        checks = self.quick_system_check()\n",
        "\n",
        "        issues = []\n",
        "        for component, status in checks.items():\n",
        "            print(f\"{component}: {status}\")\n",
        "            if \"‚ùå\" in status:\n",
        "                issues.append(component)\n",
        "\n",
        "        # Emergency repairs\n",
        "        if issues:\n",
        "            print(f\"\\nüö® {len(issues)} issues detected. Applying emergency fixes...\")\n",
        "\n",
        "            if \"PyTorch\" in issues:\n",
        "                self.emergency_pytorch_fix()\n",
        "\n",
        "            if \"Dependencies\" in issues:\n",
        "                self.emergency_dependency_fix()\n",
        "\n",
        "            if \"WAN2GP\" in issues:\n",
        "                print(\"üîß Cloning WAN2GP repository...\")\n",
        "                success, _, _ = self.run_cmd(\"git clone --depth 1 https://github.com/deepbeepmeep/Wan2GP.git\", timeout=120)\n",
        "                print(\"‚úÖ Repository cloned\" if success else \"‚ùå Clone failed\")\n",
        "\n",
        "        # Generate emergency commands\n",
        "        commands = self.generate_emergency_commands()\n",
        "\n",
        "        # Display results\n",
        "        html_display = f\"\"\"\n",
        "        <div style=\"background: linear-gradient(45deg, #ff6b6b, #feca57); color: white;\n",
        "                    padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
        "            <h3>‚ö° Quick Diagnostic Results</h3>\n",
        "            <p><strong>Platform:</strong> {self.platform}</p>\n",
        "            <p><strong>Issues Found:</strong> {len(issues)}</p>\n",
        "            <p><strong>Status:</strong> {'üö® Needs Attention' if issues else '‚úÖ System Ready'}</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(html_display))\n",
        "\n",
        "        print(\"\\nüöÄ Emergency Launch Commands:\")\n",
        "        print(\"-\" * 40)\n",
        "        for name, command in commands.items():\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  {command}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 40)\n",
        "        print(\"‚ö° Quick diagnostic complete!\")\n",
        "\n",
        "        if not issues:\n",
        "            print(\"‚úÖ System appears healthy. Try the Ultra Safe Mode command first.\")\n",
        "        else:\n",
        "            print(\"üö® Emergency fixes applied. Test with Ultra Safe Mode.\")\n",
        "\n",
        "# Execute quick diagnostic\n",
        "quick_runner = QuickDiagnosticRunner()\n",
        "quick_runner.run_quick_diagnostic()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0sx8G7LBCNyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}