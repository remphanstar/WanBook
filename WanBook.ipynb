{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pvyQBxXksCx0",
        "outputId": "683ae9d4-1e5a-4f78-ca15-08431d438a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üéÆ WANGP v5.41 ROBUST INSTALLATION\n",
            "================================================================================\n",
            "Workspace: WanGP_Workspace\n",
            "Clean Install: NO - Will reuse/update\n",
            "Auto-fix: ENABLED\n",
            "Debug Level: 2 (Verbose)\n",
            "Ngrok: DISABLED\n",
            "Ngrok Token: ‚ùå NOT SET (will use Gradio share)\n",
            "================================================================================\n",
            "================================================================================\n",
            "üìÅ WORKSPACE MANAGEMENT\n",
            "================================================================================\n",
            "Current directory: /content\n",
            "Target workspace: /content/WanGP_Workspace\n",
            "\n",
            "üìÅ Creating new workspace: WanGP_Workspace\n",
            "\n",
            "‚úÖ Working in: /content/WanGP_Workspace\n",
            "Action: clone\n",
            "================================================================================\n",
            "================================================================================\n",
            "üîç COMPREHENSIVE SYSTEM DIAGNOSTICS\n",
            "================================================================================\n",
            "Timestamp: 2025-06-29 08:19:57\n",
            "Platform: Linux 6.1.123+\n",
            "Python: 3.11.13\n",
            "Workspace: /content/WanGP_Workspace\n",
            "Environment: Google Colab\n",
            "\n",
            "[RESOURCES]\n",
            "CPU Cores: 1\n",
            "RAM: 12.7 GB total, 11.4 GB available\n",
            "\n",
            "[GPU DETECTION]\n",
            "‚úÖ CUDA Available: True\n",
            "GPU Count: 1\n",
            "CUDA Version: 12.4\n",
            "Primary GPU: Tesla T4\n",
            "VRAM: 14.74 GB\n",
            "Generation: standard\n",
            "================================================================================\n",
            "================================================================================\n",
            "üì¶ REPOSITORY MANAGEMENT\n",
            "================================================================================\n",
            "‚ùå Repository setup failed: cannot access local variable 'action' where it is not associated with a value\n",
            "\n",
            "üîß Manual steps:\n",
            "1. Check internet connection\n",
            "2. Try: !git clone https://github.com/remphanostar/WanBook.git\n",
            "3. Or download ZIP manually\n"
          ]
        },
        {
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'action' where it is not associated with a value",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2830685962.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;31m# Execute repository setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mclone_or_update_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚ùå Repository setup failed: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-2830685962.py\u001b[0m in \u001b[0;36mclone_or_update_repo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mrepo_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://github.com/remphanostar/WanBook.git\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"update\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[1/3] Updating existing repository...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'action' where it is not associated with a value"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# %% [markdown]\n",
        "# # WanGP v5.41 - Complete Cloud Installation with Enhanced Debugging & Dual Share\n",
        "#\n",
        "# ## üé¨ ALL Features from v5.41 Including:\n",
        "# - **Dual Public Access**: Gradio --share + ngrok for maximum reliability\n",
        "# - **Full Debug Output**: Complete verbose logging of all operations\n",
        "# - **Robust Directory Management**: Error-proof workspace handling\n",
        "# - **All Models**: Wan, Hunyuan, LTX, VACE (1.3B & 14B), MoviiGen, etc.\n",
        "# - **Queue System**: Stack multiple generation tasks\n",
        "# - **Video Settings Management**: Save/load/reuse video settings (v5.3)\n",
        "# - **Complete Error Handling**: Bulletproof against common issues\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 1. Workspace Setup & Configuration\n",
        "\n",
        "# %%\n",
        "# ====================================\n",
        "# üîß USER CONFIGURATION SECTION\n",
        "# ====================================\n",
        "\n",
        "# NGROK CONFIGURATION (Get token from: https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "NGROK_AUTH_TOKEN = \"\"  # <- PASTE YOUR NGROK TOKEN HERE (Leave empty to use Gradio share only)\n",
        "\n",
        "# WORKSPACE CONFIGURATION\n",
        "WORKSPACE_NAME = \"WanGP_Workspace\"  # Main workspace directory\n",
        "FORCE_CLEAN_INSTALL = False  # Set True to delete existing workspace\n",
        "AUTO_FIX_CONFLICTS = True  # Automatically resolve directory conflicts\n",
        "\n",
        "# ADVANCED SETTINGS\n",
        "DEBUG_LEVEL = 2  # 0=minimal, 1=normal, 2=verbose (shows everything)\n",
        "ENABLE_NGROK = True  # Use ngrok as backup/primary share method\n",
        "NGROK_REGION = \"us\"  # us, eu, ap, au, sa, jp, in\n",
        "MONITOR_RESOURCES = True  # Show real-time GPU/CPU/RAM usage\n",
        "AUTO_RESTART_ON_FAIL = True  # Automatically retry if launch fails\n",
        "ENABLE_UPSAMPLING = True  # Enable temporal/spatial upsampling features\n",
        "DOWNLOAD_ALL_LORAS = True  # Download all essential loras\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üéÆ WANGP v5.41 ROBUST INSTALLATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Workspace: {WORKSPACE_NAME}\")\n",
        "print(f\"Clean Install: {'YES - Will delete existing' if FORCE_CLEAN_INSTALL else 'NO - Will reuse/update'}\")\n",
        "print(f\"Auto-fix: {'ENABLED' if AUTO_FIX_CONFLICTS else 'DISABLED'}\")\n",
        "print(f\"Debug Level: {DEBUG_LEVEL} ({'Verbose' if DEBUG_LEVEL == 2 else 'Normal' if DEBUG_LEVEL == 1 else 'Minimal'})\")\n",
        "print(f\"Ngrok: {'ENABLED' if ENABLE_NGROK and NGROK_AUTH_TOKEN else 'DISABLED'}\")\n",
        "print(f\"Ngrok Token: {'‚úÖ SET' if NGROK_AUTH_TOKEN else '‚ùå NOT SET (will use Gradio share)'}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 2. Robust Directory Management System\n",
        "\n",
        "# %%\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import torch\n",
        "import platform\n",
        "import psutil\n",
        "import json\n",
        "import time\n",
        "import socket\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "def safe_remove_directory(path):\n",
        "    \"\"\"Safely remove directory with error handling\"\"\"\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            if os.path.islink(path):\n",
        "                os.unlink(path)\n",
        "            else:\n",
        "                shutil.rmtree(path)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not remove {path}: {e}\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def ensure_clean_workspace():\n",
        "    \"\"\"Create a clean workspace directory\"\"\"\n",
        "    current_dir = os.getcwd()\n",
        "    workspace_path = os.path.join(current_dir, WORKSPACE_NAME)\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"üìÅ WORKSPACE MANAGEMENT\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Current directory: {current_dir}\")\n",
        "    print(f\"Target workspace: {workspace_path}\")\n",
        "\n",
        "    # Handle existing workspace\n",
        "    if os.path.exists(workspace_path):\n",
        "        if FORCE_CLEAN_INSTALL:\n",
        "            print(f\"\\nüßπ Force clean enabled - removing existing workspace...\")\n",
        "            if safe_remove_directory(workspace_path):\n",
        "                print(\"‚úÖ Existing workspace removed\")\n",
        "            else:\n",
        "                print(\"‚ùå Could not remove workspace - will work around it\")\n",
        "        else:\n",
        "            print(f\"\\nüìÅ Workspace exists - checking contents...\")\n",
        "\n",
        "            # Check if it contains WanGP\n",
        "            wangp_path = os.path.join(workspace_path, \"Wan2GP\")\n",
        "            if os.path.exists(wangp_path):\n",
        "                print(f\"‚úÖ Found existing WanGP installation\")\n",
        "\n",
        "                # Check if it's a valid repo\n",
        "                if os.path.exists(os.path.join(wangp_path, \".git\")):\n",
        "                    print(\"‚úÖ Valid git repository found\")\n",
        "                    return workspace_path, wangp_path, \"update\"\n",
        "                else:\n",
        "                    print(\"‚ö†Ô∏è Directory exists but not a git repo\")\n",
        "                    if AUTO_FIX_CONFLICTS:\n",
        "                        print(\"üîß Auto-fix enabled - will clean and re-clone\")\n",
        "                        safe_remove_directory(wangp_path)\n",
        "                        return workspace_path, wangp_path, \"clone\"\n",
        "            else:\n",
        "                print(\"üìÇ Empty workspace - will create WanGP inside\")\n",
        "                return workspace_path, os.path.join(workspace_path, \"Wan2GP\"), \"clone\"\n",
        "\n",
        "    # Create new workspace\n",
        "    print(f\"\\nüìÅ Creating new workspace: {WORKSPACE_NAME}\")\n",
        "    os.makedirs(workspace_path, exist_ok=True)\n",
        "\n",
        "    return workspace_path, os.path.join(workspace_path, \"Wan2GP\"), \"clone\"\n",
        "\n",
        "# Setup workspace\n",
        "workspace_dir, repo_path, action = ensure_clean_workspace()\n",
        "\n",
        "# Change to workspace\n",
        "os.chdir(workspace_dir)\n",
        "print(f\"\\n‚úÖ Working in: {os.getcwd()}\")\n",
        "print(f\"Action: {action}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3. System Diagnostics with Error Handling\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"üîç COMPREHENSIVE SYSTEM DIAGNOSTICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def safe_get_info(func, default=\"Unknown\"):\n",
        "    \"\"\"Safely get system info with fallback\"\"\"\n",
        "    try:\n",
        "        return func()\n",
        "    except:\n",
        "        return default\n",
        "\n",
        "# Basic system info\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Platform: {safe_get_info(lambda: f'{platform.system()} {platform.release()}')}\")\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"Workspace: {workspace_dir}\")\n",
        "\n",
        "# Detect environment\n",
        "env_indicators = {\n",
        "    'Google Colab': lambda: 'google.colab' in str(get_ipython()),\n",
        "    'Kaggle': lambda: 'KAGGLE_URL_BASE' in os.environ,\n",
        "    'Lightning.ai': lambda: 'LIGHTNING_CLOUD_URL' in os.environ,\n",
        "    'Vast.ai': lambda: os.path.exists('/opt/bin/nvidia-smi'),\n",
        "    'Paperspace': lambda: 'PS_API_KEY' in os.environ\n",
        "}\n",
        "\n",
        "detected_env = \"Unknown\"\n",
        "for env_name, check_func in env_indicators.items():\n",
        "    if safe_get_info(check_func, False):\n",
        "        detected_env = env_name\n",
        "        break\n",
        "\n",
        "print(f\"Environment: {detected_env}\")\n",
        "\n",
        "# Resource info\n",
        "print(f\"\\n[RESOURCES]\")\n",
        "print(f\"CPU Cores: {safe_get_info(lambda: psutil.cpu_count(logical=False), 'Unknown')}\")\n",
        "mem = safe_get_info(lambda: psutil.virtual_memory(), None)\n",
        "if mem:\n",
        "    print(f\"RAM: {mem.total/(1024**3):.1f} GB total, {mem.available/(1024**3):.1f} GB available\")\n",
        "else:\n",
        "    print(\"RAM: Could not detect\")\n",
        "\n",
        "# GPU Detection with comprehensive error handling\n",
        "print(f\"\\n[GPU DETECTION]\")\n",
        "gpu_available = False\n",
        "gpu_info = \"No GPU\"\n",
        "gpu_memory = 0\n",
        "gpu_generation = 'none'\n",
        "\n",
        "try:\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        print(f\"‚úÖ CUDA Available: True\")\n",
        "        print(f\"GPU Count: {gpu_count}\")\n",
        "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "\n",
        "        # Get primary GPU info\n",
        "        gpu_info = torch.cuda.get_device_name(0)\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        gpu_memory = props.total_memory / (1024**3)\n",
        "\n",
        "        print(f\"Primary GPU: {gpu_info}\")\n",
        "        print(f\"VRAM: {gpu_memory:.2f} GB\")\n",
        "\n",
        "        # Determine generation\n",
        "        gpu_name_lower = gpu_info.lower()\n",
        "        if any(x in gpu_name_lower for x in ['5090', '5080', '5070', '5060', '5050']):\n",
        "            gpu_generation = 'rtx50xx'\n",
        "            pytorch_version = \"2.7.0\"\n",
        "            cuda_index = \"cu128\"\n",
        "        elif any(x in gpu_name_lower for x in ['a100', 'a6000', 'a40', 'v100']):\n",
        "            gpu_generation = 'datacenter'\n",
        "            pytorch_version = \"2.6.0\"\n",
        "            cuda_index = \"cu124\"\n",
        "        else:\n",
        "            gpu_generation = 'standard'\n",
        "            pytorch_version = \"2.6.0\"\n",
        "            cuda_index = \"cu124\"\n",
        "\n",
        "        print(f\"Generation: {gpu_generation}\")\n",
        "        gpu_available = True\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå CUDA Not Available\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå GPU Detection Error: {e}\")\n",
        "\n",
        "if not gpu_available:\n",
        "    print(\"\\nüîß GPU TROUBLESHOOTING:\")\n",
        "    print(\"1. Google Colab: Runtime > Change runtime type > GPU\")\n",
        "    print(\"2. Other platforms: Ensure GPU instance selected\")\n",
        "    print(\"3. Try: !nvidia-smi to check GPU status\")\n",
        "\n",
        "    # Still allow CPU execution for testing\n",
        "    print(\"\\n‚ö†Ô∏è Continuing with CPU mode (very slow)\")\n",
        "    gpu_info = \"CPU Mode\"\n",
        "    gpu_memory = 0\n",
        "    pytorch_version = \"2.6.0\"\n",
        "    cuda_index = \"cu124\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4. Repository Management with Conflict Resolution\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"üì¶ REPOSITORY MANAGEMENT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def run_command_safe(cmd, shell=True, capture_output=True, timeout=300):\n",
        "    \"\"\"Run command with timeout and error handling\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            shell=shell,\n",
        "            capture_output=capture_output,\n",
        "            text=True,\n",
        "            timeout=timeout\n",
        "        )\n",
        "        return result.returncode, result.stdout, result.stderr\n",
        "    except subprocess.TimeoutExpired:\n",
        "        return -1, \"\", \"Command timed out\"\n",
        "    except Exception as e:\n",
        "        return -1, \"\", str(e)\n",
        "\n",
        "def clone_or_update_repo():\n",
        "    \"\"\"Handle repository cloning/updating with conflict resolution\"\"\"\n",
        "    repo_url = \"https://github.com/remphanostar/WanBook.git\"\n",
        "\n",
        "    if action == \"update\":\n",
        "        print(f\"[1/3] Updating existing repository...\")\n",
        "        os.chdir(repo_path)\n",
        "\n",
        "        # Check git status\n",
        "        ret, stdout, stderr = run_command_safe(\"git status --porcelain\")\n",
        "        if ret == 0 and stdout.strip():\n",
        "            print(\"‚ö†Ô∏è Local changes detected\")\n",
        "            if AUTO_FIX_CONFLICTS:\n",
        "                print(\"üîß Auto-fix: Stashing local changes...\")\n",
        "                run_command_safe(\"git stash\")\n",
        "\n",
        "        # Pull updates\n",
        "        ret, stdout, stderr = run_command_safe(\"git pull\")\n",
        "        if ret == 0:\n",
        "            print(\"‚úÖ Repository updated\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Update failed: {stderr}\")\n",
        "            print(\"Will attempt fresh clone...\")\n",
        "            os.chdir(workspace_dir)\n",
        "            safe_remove_directory(repo_path)\n",
        "            action = \"clone\"\n",
        "\n",
        "    if action == \"clone\":\n",
        "        print(f\"[1/3] Cloning repository from GitHub...\")\n",
        "        print(f\"URL: {repo_url}\")\n",
        "\n",
        "        # Ensure target doesn't exist\n",
        "        if os.path.exists(repo_path):\n",
        "            print(f\"‚ö†Ô∏è Target exists, removing: {repo_path}\")\n",
        "            safe_remove_directory(repo_path)\n",
        "\n",
        "        # Clone with progress\n",
        "        start_time = time.time()\n",
        "        ret, stdout, stderr = run_command_safe(\n",
        "            f\"git clone {repo_url} {os.path.basename(repo_path)}\",\n",
        "            timeout=600  # 10 minutes max\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        if ret == 0:\n",
        "            print(f\"‚úÖ Repository cloned in {elapsed:.1f}s\")\n",
        "        else:\n",
        "            print(f\"‚ùå Clone failed: {stderr}\")\n",
        "\n",
        "            # Fallback: try wget\n",
        "            print(\"üîÑ Trying alternative download method...\")\n",
        "            zip_url = \"https://github.com/remphanostar/WanBook/archive/refs/heads/main.zip\"\n",
        "            ret, stdout, stderr = run_command_safe(f\"wget -O wangp.zip {zip_url}\")\n",
        "\n",
        "            if ret == 0:\n",
        "                print(\"üì¶ Downloaded as ZIP, extracting...\")\n",
        "                ret, stdout, stderr = run_command_safe(\"unzip -q wangp.zip\")\n",
        "                if ret == 0:\n",
        "                    # Rename extracted folder\n",
        "                    extracted_name = \"Wan2GP-main\"\n",
        "                    if os.path.exists(extracted_name):\n",
        "                        os.rename(extracted_name, os.path.basename(repo_path))\n",
        "                        print(\"‚úÖ Repository extracted successfully\")\n",
        "                    else:\n",
        "                        raise RuntimeError(\"Could not extract repository\")\n",
        "                else:\n",
        "                    raise RuntimeError(\"Failed to extract ZIP\")\n",
        "            else:\n",
        "                raise RuntimeError(\"All download methods failed\")\n",
        "\n",
        "# Execute repository setup\n",
        "try:\n",
        "    clone_or_update_repo()\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Repository setup failed: {e}\")\n",
        "    print(\"\\nüîß Manual steps:\")\n",
        "    print(\"1. Check internet connection\")\n",
        "    print(\"2. Try: !git clone https://github.com/remphanostar/WanBook.git\")\n",
        "    print(\"3. Or download ZIP manually\")\n",
        "    raise\n",
        "\n",
        "# Change to repo directory\n",
        "print(f\"\\n[2/3] Entering repository directory...\")\n",
        "os.chdir(repo_path)\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Verify repository\n",
        "print(f\"\\n[3/3] Verifying repository integrity...\")\n",
        "required_files = {\n",
        "    'wgp.py': 'Main application',\n",
        "    'requirements.txt': 'Dependencies',\n",
        "    'CHANGELOG.md': 'Version history'\n",
        "}\n",
        "\n",
        "missing_files = []\n",
        "for file, desc in required_files.items():\n",
        "    if os.path.exists(file):\n",
        "        size = os.path.getsize(file) / 1024\n",
        "        print(f\"  ‚úÖ {file:<20} ({size:>6.1f} KB)\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå {file:<20} MISSING\")\n",
        "        missing_files.append(file)\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"\\n‚ùå Repository incomplete! Missing: {', '.join(missing_files)}\")\n",
        "    if AUTO_FIX_CONFLICTS:\n",
        "        print(\"üîß Auto-fix: Attempting re-download...\")\n",
        "        os.chdir(workspace_dir)\n",
        "        safe_remove_directory(repo_path)\n",
        "        # Try again\n",
        "        clone_or_update_repo()\n",
        "        os.chdir(repo_path)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Missing critical files: {missing_files}\")\n",
        "\n",
        "print(\"\\n‚úÖ Repository ready\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5. Install PyTorch with Version Management\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"üîß PYTORCH INSTALLATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def check_pytorch_compatibility():\n",
        "    \"\"\"Check if current PyTorch is compatible\"\"\"\n",
        "    try:\n",
        "        import torch as existing_torch\n",
        "        current_version = existing_torch.__version__\n",
        "        current_cuda = existing_torch.version.cuda\n",
        "\n",
        "        print(f\"Current PyTorch: {current_version}\")\n",
        "        print(f\"Current CUDA: {current_cuda}\")\n",
        "\n",
        "        # Check compatibility\n",
        "        needs_reinstall = False\n",
        "\n",
        "        if gpu_generation == 'rtx50xx':\n",
        "            if not current_version.startswith('2.7'):\n",
        "                print(\"‚ö†Ô∏è RTX 50XX requires PyTorch 2.7.0\")\n",
        "                needs_reinstall = True\n",
        "        else:\n",
        "            if not current_version.startswith('2.6'):\n",
        "                print(\"‚ÑπÔ∏è Stable PyTorch 2.6.0 recommended\")\n",
        "                needs_reinstall = True\n",
        "\n",
        "        if not torch.cuda.is_available() and gpu_available:\n",
        "            print(\"‚ö†Ô∏è PyTorch doesn't detect CUDA\")\n",
        "            needs_reinstall = True\n",
        "\n",
        "        return needs_reinstall, current_version\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"No PyTorch found\")\n",
        "        return True, None\n",
        "\n",
        "# Check current installation\n",
        "needs_install, current_version = check_pytorch_compatibility()\n",
        "\n",
        "if needs_install:\n",
        "    print(f\"\\n[Installing PyTorch {pytorch_version}]\")\n",
        "\n",
        "    # Uninstall existing if needed\n",
        "    if current_version:\n",
        "        print(\"Removing existing PyTorch...\")\n",
        "        ret, _, _ = run_command_safe(\"pip uninstall torch torchvision torchaudio -y\", timeout=120)\n",
        "        if ret == 0:\n",
        "            print(\"‚úÖ Removed existing PyTorch\")\n",
        "\n",
        "    # Install new version\n",
        "    install_cmd = f\"pip install torch=={pytorch_version} torchvision torchaudio --index-url https://download.pytorch.org/whl/test/{cuda_index}\"\n",
        "    print(f\"Installing: {install_cmd}\")\n",
        "    print(\"This may take 5-10 minutes...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    ret, stdout, stderr = run_command_safe(install_cmd, timeout=900)  # 15 minutes max\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    if ret == 0:\n",
        "        print(f\"‚úÖ PyTorch installed in {elapsed/60:.1f} minutes\")\n",
        "    else:\n",
        "        print(f\"‚ùå Installation failed: {stderr}\")\n",
        "        print(\"üîÑ Trying with pip upgrade...\")\n",
        "        ret, _, _ = run_command_safe(\"pip install --upgrade pip\", timeout=60)\n",
        "        ret, _, stderr = run_command_safe(install_cmd, timeout=900)\n",
        "        if ret != 0:\n",
        "            raise RuntimeError(f\"PyTorch installation failed: {stderr}\")\n",
        "else:\n",
        "    print(\"‚úÖ PyTorch already compatible\")\n",
        "\n",
        "# Verify installation\n",
        "print(\"\\nVerifying PyTorch...\")\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"‚úÖ PyTorch {torch.__version__}\")\n",
        "    print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"‚úÖ GPU accessible: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "        # Quick GPU test\n",
        "        try:\n",
        "            test_tensor = torch.rand(100, 100).cuda()\n",
        "            result = test_tensor @ test_tensor\n",
        "            print(\"‚úÖ GPU operations working\")\n",
        "            del test_tensor, result\n",
        "            torch.cuda.empty_cache()\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è GPU test failed: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå PyTorch verification failed: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6. Dependencies with Retry Logic\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"üì¶ DEPENDENCY INSTALLATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def install_requirements_with_retry(max_retries=3):\n",
        "    \"\"\"Install requirements with retry logic\"\"\"\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        print(f\"\\nAttempt {attempt + 1}/{max_retries}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        ret, stdout, stderr = run_command_safe(\n",
        "            \"pip install -r requirements.txt\",\n",
        "            timeout=1200  # 20 minutes\n",
        "        )\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        if ret == 0:\n",
        "            print(f\"‚úÖ Dependencies installed in {elapsed/60:.1f} minutes\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå Attempt {attempt + 1} failed: {stderr}\")\n",
        "\n",
        "            if attempt < max_retries - 1:\n",
        "                print(\"üîÑ Retrying with pip upgrade...\")\n",
        "                run_command_safe(\"pip install --upgrade pip\", timeout=60)\n",
        "                time.sleep(5)\n",
        "\n",
        "    return False\n",
        "\n",
        "# Install dependencies\n",
        "print(\"Installing all dependencies...\")\n",
        "print(\"This includes: Gradio, Diffusers, Transformers, Accelerate...\")\n",
        "\n",
        "if not install_requirements_with_retry():\n",
        "    print(\"‚ùå All installation attempts failed\")\n",
        "    print(\"üîß Manual fallback:\")\n",
        "    print(\"Try running: !pip install gradio diffusers accelerate transformers\")\n",
        "    raise RuntimeError(\"Dependency installation failed\")\n",
        "\n",
        "# Verify key packages\n",
        "print(\"\\n[PACKAGE VERIFICATION]\")\n",
        "critical_packages = ['gradio', 'diffusers', 'accelerate', 'transformers']\n",
        "missing_packages = []\n",
        "\n",
        "for package in critical_packages:\n",
        "    try:\n",
        "        module = __import__(package)\n",
        "        version = getattr(module, '__version__', 'unknown')\n",
        "        print(f\"  ‚úÖ {package}: {version}\")\n",
        "    except ImportError:\n",
        "        print(f\"  ‚ùå {package}: MISSING\")\n",
        "        missing_packages.append(package)\n",
        "\n",
        "if missing_packages:\n",
        "    print(f\"\\n‚ö†Ô∏è Missing critical packages: {missing_packages}\")\n",
        "    print(\"Attempting individual installation...\")\n",
        "    for package in missing_packages:\n",
        "        ret, _, _ = run_command_safe(f\"pip install {package}\", timeout=300)\n",
        "        if ret == 0:\n",
        "            print(f\"‚úÖ Installed {package}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Failed to install {package}\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 7. Performance Optimization (Safe)\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"‚ö° PERFORMANCE OPTIMIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Determine safe defaults\n",
        "attention_mode = \"sdpa\"  # Always safe\n",
        "compile_enabled = False\n",
        "teacache_multiplier = \"2.0\"\n",
        "profile = 4\n",
        "\n",
        "print(f\"GPU: {gpu_info}\")\n",
        "print(f\"VRAM: {gpu_memory:.1f} GB\")\n",
        "\n",
        "# Optimization strategy based on VRAM\n",
        "if gpu_memory >= 24:\n",
        "    print(\"üèÜ Ultra High VRAM: All optimizations available\")\n",
        "    profile = 3\n",
        "    teacache_multiplier = \"2.5\"\n",
        "    target_attention = \"sage2\"\n",
        "elif gpu_memory >= 16:\n",
        "    print(\"üí™ High VRAM: Advanced optimizations\")\n",
        "    profile = 4\n",
        "    target_attention = \"sage2\"\n",
        "elif gpu_memory >= 12:\n",
        "    print(\"‚úÖ Medium VRAM: Standard optimizations\")\n",
        "    target_attention = \"sage\"\n",
        "elif gpu_memory >= 8:\n",
        "    print(\"‚ö° Standard VRAM: Basic optimizations\")\n",
        "    teacache_multiplier = \"1.75\"\n",
        "    target_attention = \"sage\"\n",
        "else:\n",
        "    print(\"üîã Low VRAM: Conservative settings\")\n",
        "    teacache_multiplier = \"1.5\"\n",
        "    target_attention = \"sdpa\"\n",
        "\n",
        "# Try to install optimizations safely\n",
        "if target_attention in [\"sage\", \"sage2\"] and gpu_memory >= 8:\n",
        "    print(f\"\\n[INSTALLING {target_attention.upper()} ATTENTION]\")\n",
        "\n",
        "    # Install triton first\n",
        "    triton_cmd = \"pip install triton\" if platform.system() == \"Linux\" else \"pip install triton-windows\"\n",
        "    ret, _, stderr = run_command_safe(triton_cmd, timeout=300)\n",
        "\n",
        "    if ret == 0:\n",
        "        print(\"‚úÖ Triton installed\")\n",
        "\n",
        "        # Install SageAttention\n",
        "        ret, _, stderr = run_command_safe(\"pip install sageattention==1.0.6\", timeout=300)\n",
        "        if ret == 0:\n",
        "            attention_mode = \"sage\"\n",
        "            print(\"‚úÖ Sage Attention installed (+30% speed)\")\n",
        "\n",
        "            # Try Sage2 for high VRAM\n",
        "            if target_attention == \"sage2\" and gpu_memory >= 12:\n",
        "                print(\"Attempting Sage2 installation...\")\n",
        "                # Only try pre-built wheels for safety\n",
        "                if gpu_generation == 'rtx50xx' and platform.system() == \"Windows\":\n",
        "                    sage2_url = \"https://github.com/woct0rdho/SageAttention/releases/download/v2.1.1-windows/sageattention-2.1.1+cu128torch2.7.0-cp310-cp310-win_amd64.whl\"\n",
        "                    ret, _, _ = run_command_safe(f\"pip install {sage2_url}\", timeout=300)\n",
        "                    if ret == 0:\n",
        "                        attention_mode = \"sage2\"\n",
        "                        compile_enabled = True\n",
        "                        print(\"‚úÖ Sage2 installed (+40% speed)\")\n",
        "                elif gpu_generation == 'standard' and platform.system() == \"Windows\":\n",
        "                    sage2_url = \"https://github.com/woct0rdho/SageAttention/releases/download/v2.1.1-windows/sageattention-2.1.1+cu126torch2.6.0-cp310-cp310-win_amd64.whl\"\n",
        "                    ret, _, _ = run_command_safe(f\"pip install {sage2_url}\", timeout=300)\n",
        "                    if ret == 0:\n",
        "                        attention_mode = \"sage2\"\n",
        "                        compile_enabled = True\n",
        "                        print(\"‚úÖ Sage2 installed (+40% speed)\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Sage installation failed: {stderr}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Triton installation failed: {stderr}\")\n",
        "\n",
        "print(f\"\\n[FINAL SETTINGS]\")\n",
        "print(f\"Attention: {attention_mode}\")\n",
        "print(f\"Profile: {profile}\")\n",
        "print(f\"TeaCache: {teacache_multiplier}x\")\n",
        "print(f\"Compilation: {'Yes' if compile_enabled else 'No'}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 8. Ngrok Setup (Safe)\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"üåê NGROK CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ngrok_available = False\n",
        "\n",
        "if ENABLE_NGROK and NGROK_AUTH_TOKEN:\n",
        "    try:\n",
        "        # Install pyngrok safely\n",
        "        ret, _, stderr = run_command_safe(\"pip install pyngrok\", timeout=120)\n",
        "        if ret == 0:\n",
        "            print(\"‚úÖ pyngrok installed\")\n",
        "\n",
        "            # Import and configure\n",
        "            from pyngrok import ngrok, conf\n",
        "\n",
        "            # Set token\n",
        "            ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "            print(\"‚úÖ Ngrok token configured\")\n",
        "\n",
        "            # Configure region\n",
        "            config = conf.get_default()\n",
        "            config.region = NGROK_REGION\n",
        "            config.monitor_thread = False\n",
        "\n",
        "            # Test connection\n",
        "            print(\"Testing ngrok...\")\n",
        "            test_tunnel = ngrok.connect(7860, \"http\")\n",
        "            print(f\"‚úÖ Test successful: {test_tunnel.public_url}\")\n",
        "            ngrok.disconnect(test_tunnel.public_url)\n",
        "\n",
        "            ngrok_available = True\n",
        "\n",
        "        else:\n",
        "            print(f\"‚ùå pyngrok installation failed: {stderr}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Ngrok setup error: {e}\")\n",
        "        print(\"Will use Gradio share only\")\n",
        "else:\n",
        "    print(\"Ngrok disabled or no token provided\")\n",
        "\n",
        "print(f\"Share methods: Gradio {'+ Ngrok' if ngrok_available else ' only'}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 9. Directory Structure Creation\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"üìÅ CREATING DIRECTORY STRUCTURE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create all necessary directories\n",
        "directories = [\n",
        "    'loras', 'loras/1.3B', 'loras/14B',\n",
        "    'loras_i2v', 'loras_hunyuan', 'loras_hunyuan_i2v', 'loras_ltxv',\n",
        "    'settings', 'presets', 'output', 'output/videos', 'output/gallery',\n",
        "    'temp', 'cache', 'cache/models'\n",
        "]\n",
        "\n",
        "created = 0\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "        created += 1\n",
        "        print(f\"‚úÖ Created: {directory}\")\n",
        "    else:\n",
        "        print(f\"üìÅ Exists: {directory}\")\n",
        "\n",
        "print(f\"\\nCreated {created} new directories\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 10. Essential Loras Download\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"üé® ESSENTIAL LORAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if DOWNLOAD_ALL_LORAS:\n",
        "    loras = [\n",
        "        {\n",
        "            \"name\": \"CausVid T2V\",\n",
        "            \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_CausVid_14B_T2V_lora_rank32.safetensors\",\n",
        "            \"path\": \"loras/\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"AccVid T2V\",\n",
        "            \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_AccVid_T2V_14B_lora_rank32_fp16.safetensors\",\n",
        "            \"path\": \"loras/\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"AccVid I2V\",\n",
        "            \"url\": \"https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan21_AccVid_I2V_480P_14B_lora_rank32_fp16.safetensors\",\n",
        "            \"path\": \"loras_i2v/\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    total_size = 0\n",
        "    for lora in loras:\n",
        "        filename = os.path.basename(lora[\"url\"])\n",
        "        filepath = os.path.join(lora[\"path\"], filename)\n",
        "\n",
        "        print(f\"\\n{lora['name']}:\")\n",
        "\n",
        "        if os.path.exists(filepath):\n",
        "            size = os.path.getsize(filepath) / (1024**2)\n",
        "            total_size += size\n",
        "            print(f\"  ‚úÖ Already exists ({size:.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"  üì• Downloading...\")\n",
        "            ret, _, stderr = run_command_safe(f\"wget -q -P {lora['path']} {lora['url']}\", timeout=600)\n",
        "\n",
        "            if ret == 0 and os.path.exists(filepath):\n",
        "                size = os.path.getsize(filepath) / (1024**2)\n",
        "                total_size += size\n",
        "                print(f\"  ‚úÖ Downloaded ({size:.1f} MB)\")\n",
        "            else:\n",
        "                print(f\"  ‚ùå Download failed: {stderr}\")\n",
        "\n",
        "    print(f\"\\nTotal Lora size: {total_size:.1f} MB\")\n",
        "else:\n",
        "    print(\"Lora downloads skipped\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 11. Configuration Files\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"‚öôÔ∏è CONFIGURATION FILES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create default settings\n",
        "settings = {\n",
        "    'settings/t2v_settings.json': {\n",
        "        \"prompt\": \"A beautiful cinematic scene, high quality, detailed\",\n",
        "        \"frames\": 49,\n",
        "        \"steps\": 20,\n",
        "        \"guidance_scale\": 7.0,\n",
        "        \"seed\": -1,\n",
        "        \"teacache_multiplier\": float(teacache_multiplier)\n",
        "    },\n",
        "    'settings/i2v_settings.json': {\n",
        "        \"prompt\": \"Natural motion, smooth animation\",\n",
        "        \"frames\": 49,\n",
        "        \"steps\": 20,\n",
        "        \"guidance_scale\": 7.0,\n",
        "        \"seed\": -1\n",
        "    }\n",
        "}\n",
        "\n",
        "for filepath, config in settings.items():\n",
        "    with open(filepath, 'w') as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "    print(f\"‚úÖ Created: {filepath}\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 12. Launch Script Creation\n",
        "\n",
        "# %%\n",
        "print(\"=\"*80)\n",
        "print(\"üöÄ CREATING LAUNCH SCRIPT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Build launch command\n",
        "launch_command = [\n",
        "    \"python\", \"wgp.py\",\n",
        "    \"--share\",  # CRITICAL for cloud access\n",
        "    \"--server-port\", \"7860\",\n",
        "    \"--attention\", attention_mode,\n",
        "    \"--profile\", str(profile),\n",
        "    \"--teacache\", teacache_multiplier,\n",
        "    \"--verbose\", str(DEBUG_LEVEL)\n",
        "]\n",
        "\n",
        "# Add model selection based on VRAM\n",
        "if gpu_memory < 8:\n",
        "    launch_command.extend([\"--t2v-1-3B\"])\n",
        "    print(\"Default model: 1.3B (Low VRAM)\")\n",
        "elif gpu_memory >= 16:\n",
        "    print(\"Default model: User choice (All available)\")\n",
        "else:\n",
        "    print(\"Default model: User choice (1.3B/14B)\")\n",
        "\n",
        "if compile_enabled:\n",
        "    launch_command.append(\"--compile\")\n",
        "\n",
        "print(f\"Launch command: {' '.join(launch_command)}\")\n",
        "\n",
        "# Create launch script with error handling\n",
        "launch_script = f'''#!/usr/bin/env python3\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Configuration\n",
        "ENABLE_NGROK = {ngrok_available}\n",
        "MONITOR_RESOURCES = {MONITOR_RESOURCES}\n",
        "DEBUG_LEVEL = {DEBUG_LEVEL}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üé¨ WANGP v5.41 LAUNCHER\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Time: {{datetime.now()}}\")\n",
        "print(f\"GPU: {gpu_info}\")\n",
        "print(f\"VRAM: {gpu_memory:.1f} GB\")\n",
        "print(f\"Share: Gradio{'+ Ngrok' if ngrok_available else ''}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Environment setup\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "os.environ['GRADIO_ANALYTICS_ENABLED'] = 'False'\n",
        "\n",
        "# Setup ngrok if available\n",
        "ngrok_tunnel = None\n",
        "if ENABLE_NGROK:\n",
        "    try:\n",
        "        from pyngrok import ngrok\n",
        "        ngrok_tunnel = ngrok.connect(7860, \"http\")\n",
        "        print(f\"üåê Ngrok URL: {{ngrok_tunnel.public_url}}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Ngrok failed: {{e}}\")\n",
        "\n",
        "# Launch command\n",
        "params = {launch_command}\n",
        "print(f\"Command: {{' '.join(params)}}\\\\n\")\n",
        "\n",
        "try:\n",
        "    # Launch process\n",
        "    process = subprocess.Popen(\n",
        "        params,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        bufsize=1\n",
        "    )\n",
        "\n",
        "    # Monitor output\n",
        "    while True:\n",
        "        line = process.stdout.readline()\n",
        "        if not line and process.poll() is not None:\n",
        "            break\n",
        "        if line:\n",
        "            print(line.rstrip())\n",
        "\n",
        "            # Detect URLs\n",
        "            if 'Running on public URL:' in line:\n",
        "                url = line.split('public URL:')[1].strip()\n",
        "                print(\"\\\\n\" + \"üåü\" * 40)\n",
        "                print(f\"‚úÖ GRADIO URL: {{url}}\")\n",
        "                if ngrok_tunnel:\n",
        "                    print(f\"‚úÖ NGROK URL: {{ngrok_tunnel.public_url}}\")\n",
        "                print(\"üåü\" * 40 + \"\\\\n\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\\\n‚ö†Ô∏è Stopped by user\")\n",
        "finally:\n",
        "    if ngrok_tunnel:\n",
        "        try:\n",
        "            ngrok.disconnect(ngrok_tunnel.public_url)\n",
        "        except:\n",
        "            pass\n",
        "'''\n",
        "\n",
        "with open('launch_wangp.py', 'w') as f:\n",
        "    f.write(launch_script)\n",
        "\n",
        "print(\"‚úÖ Launch script created: launch_wangp.py\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 13. üöÄ LAUNCH WANGP\n",
        "\n",
        "# %%\n",
        "print(f\"\"\"\n",
        "üé¨ LAUNCHING WANGP v5.41\n",
        "========================\n",
        "\n",
        "üîß CONFIGURATION:\n",
        "- GPU: {gpu_info}\n",
        "- VRAM: {gpu_memory:.1f} GB\n",
        "- Attention: {attention_mode}\n",
        "- Share: Gradio {'+ Ngrok' if ngrok_available else 'only'}\n",
        "- Debug: Level {DEBUG_LEVEL}\n",
        "\n",
        "üìå LOOK FOR:\n",
        "- \"Running on public URL:\" in output below\n",
        "- Click any public URL to access WanGP\n",
        "- First model download may take 5-15 minutes\n",
        "\n",
        "üöÄ Starting now...\n",
        "\"\"\")\n",
        "\n",
        "# Execute launch with auto-restart\n",
        "max_retries = 3 if AUTO_RESTART_ON_FAIL else 1\n",
        "for attempt in range(max_retries):\n",
        "    if attempt > 0:\n",
        "        print(f\"\\nüîÑ Retry {attempt}/{max_retries-1}\")\n",
        "        if gpu_available:\n",
        "            torch.cuda.empty_cache()\n",
        "        time.sleep(5)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"LAUNCH ATTEMPT {attempt + 1}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Launch the script\n",
        "    try:\n",
        "        result = subprocess.run([sys.executable, 'launch_wangp.py'])\n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ Exited normally\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Exit code: {result.returncode}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Launch error: {e}\")\n",
        "\n",
        "    if attempt < max_retries - 1:\n",
        "        print(\"Preparing to restart...\")\n",
        "\n",
        "print(\"\\nüéâ Launch sequence complete!\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 14. Alternative Launch Commands\n",
        "\n",
        "# %%\n",
        "print(f\"\"\"\n",
        "üîß ALTERNATIVE LAUNCH COMMANDS\n",
        "==============================\n",
        "\n",
        "All commands include --share for public access:\n",
        "\n",
        "üöÄ BASIC LAUNCHES:\n",
        "!python wgp.py --share --verbose {DEBUG_LEVEL}\n",
        "!python wgp.py --t2v-1-3B --share --verbose {DEBUG_LEVEL}\n",
        "!python wgp.py --i2v-14B --share --verbose {DEBUG_LEVEL}\n",
        "!python wgp.py --vace-1-3B --share --verbose {DEBUG_LEVEL}\n",
        "\n",
        "‚ö° OPTIMIZED:\n",
        "!python wgp.py --attention {attention_mode} --profile {profile} --teacache {teacache_multiplier} --share --verbose {DEBUG_LEVEL}\n",
        "\n",
        "üîß MINIMAL (if issues):\n",
        "!python wgp.py --t2v-1-3B --attention sdpa --profile 4 --teacache 0 --share --verbose {DEBUG_LEVEL}\n",
        "\n",
        "üìä FEATURES:\n",
        "!python wgp.py --i2v --multiple-images --share --verbose {DEBUG_LEVEL}\n",
        "!python wgp.py --advanced --share --verbose {DEBUG_LEVEL}\n",
        "\n",
        "üåê The --share flag ensures public access on ALL cloud platforms!\n",
        "\"\"\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 15. Feature Reference\n",
        "\n",
        "# %%\n",
        "# Fixed f-string syntax by removing problematic characters\n",
        "feature_text = f\"\"\"\n",
        "üìö WANGP v5.41 COMPLETE FEATURES\n",
        "================================\n",
        "\n",
        "üé¨ ALL MODELS AVAILABLE:\n",
        "\n",
        "TEXT-TO-VIDEO:\n",
        "- Wan 2.1 T2V 1.3B (6GB VRAM, fastest)\n",
        "- Wan 2.1 T2V 14B (12GB+ VRAM, best quality)\n",
        "- Hunyuan Video (best overall quality)\n",
        "- LTX Video 13B (long videos, optimized)\n",
        "- LTX Video Distilled (under 1 min generation)\n",
        "\n",
        "IMAGE-TO-VIDEO:\n",
        "- Wan Fun InP 1.3B (entry level)\n",
        "- Wan Fun InP 14B (better quality)\n",
        "- Wan I2V 14B (standard)\n",
        "- FLF2V (start/end frame specialist)\n",
        "- Hunyuan Custom (identity preservation)\n",
        "\n",
        "CONTROLNET:\n",
        "- VACE 1.3B (6GB VRAM control)\n",
        "- VACE 14B (professional control)\n",
        "\n",
        "SPECIALIZED:\n",
        "- Hunyuan Avatar (15s speech/song video, 10GB VRAM)\n",
        "- FantasySpeaking (voice animation)\n",
        "- Phantom (person/object transfer)\n",
        "- Recam Master (viewpoint change)\n",
        "- Sky Reels v2 (infinite length)\n",
        "- MoviiGen (experimental 1080p, 20GB+)\n",
        "\n",
        "‚ö° PERFORMANCE (YOUR SETUP):\n",
        "Attention: {attention_mode}\n",
        "Speed boost: {'+40%' if attention_mode == 'sage2' else '+30%' if attention_mode == 'sage' else 'baseline'}\n",
        "TeaCache: {teacache_multiplier}x\n",
        "Profile: {profile}\n",
        "\n",
        "üé® v5.41 FEATURES:\n",
        "‚úÖ AccVideo Lora (2x speed)\n",
        "‚úÖ Video Settings Management\n",
        "‚úÖ Queue System\n",
        "‚úÖ Gallery Management\n",
        "‚úÖ Matanyone Integration\n",
        "‚úÖ Prompt Enhancer\n",
        "‚úÖ Multi-image Support\n",
        "\n",
        "üåê ACCESS METHODS:\n",
        "‚úÖ Gradio Share (always enabled)\n",
        "{'‚úÖ Ngrok Tunnel' if ngrok_available else '‚ùå Ngrok (not configured)'}\n",
        "\n",
        "üìä YOUR HARDWARE:\n",
        "GPU: {gpu_info}\n",
        "VRAM: {gpu_memory:.1f} GB\n",
        "Workspace: {workspace_dir}\n",
        "\"\"\"\n",
        "\n",
        "print(feature_text)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## üéâ Setup Complete!\n",
        "#\n",
        "# Your WanGP v5.41 installation is complete with:\n",
        "#\n",
        "# ‚úÖ **Robust Directory Management** - No more nesting issues\n",
        "# ‚úÖ **Error-Proof Installation** - Handles conflicts automatically\n",
        "# ‚úÖ **Dual Share Methods** - Gradio + Ngrok for reliable access\n",
        "# ‚úÖ **Complete Debug Output** - Full visibility into all operations\n",
        "# ‚úÖ **All v5.41 Features** - Every model and feature available\n",
        "#\n",
        "# **Look for the public URLs in the output above and start creating amazing videos!** üöÄ\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Quick Reference\n",
        "#\n",
        "# üìã **First Video Test:**\n",
        "# 1. Click any public URL from output above\n",
        "# 2. Select \"Wan 2.1 T2V 1.3B\" from dropdown\n",
        "# 3. Enter: \"A serene lake at sunset, cinematic\"\n",
        "# 4. Set frames: 49, steps: 20\n",
        "# 5. Click Generate!\n",
        "#\n",
        "# ‚ö° **Speed Modes:**\n",
        "# - CausVid: steps=12, guidance=1, shift=7, multiplier=0.3\n",
        "# - AccVid: guidance=1, shift=5\n",
        "#\n",
        "# üÜò **Help:**\n",
        "# - Discord: https://discord.gg/g7efUW9jGV\n",
        "# - Issues: Runtime > Restart runtime\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
