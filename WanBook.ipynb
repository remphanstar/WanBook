{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB4UDQgI_m31"
      },
      "source": [
        "# üé¨ **WanGP v5.41 - Complete Cloud Installation with Enhanced Debugging & Dual Share**\n",
        "\n",
        "## üé¨ ALL Features from v5.41 Including:\n",
        "- **Dual Public Access**: Gradio --share + ngrok for maximum reliability\n",
        "- **Full Debug Output**: Complete verbose logging of all operations\n",
        "- **Robust Directory Management**: Error-proof workspace handling\n",
        "- **All Models**: Wan, Hunyuan, LTX, VACE (1.3B & 14B), MoviiGen, etc.\n",
        "- **Queue System**: Stack multiple generation tasks\n",
        "- **Video Settings Management**: Save/load/reuse video settings (v5.3)\n",
        "- **Complete Error Handling**: Bulletproof against common issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ydcCb2_m33"
      },
      "source": [
        "## 1. Workspace Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Qmd2QM_m33",
        "outputId": "857a075c-afa2-49c9-d5d8-428fa3ac8f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üéÆ WANGP v5.41 ROBUST INSTALLATION\n",
            "================================================================================\n",
            "Workspace: WanGP_Workspace\n",
            "Clean Install: NO - Will reuse/update\n",
            "Auto-fix: ENABLED\n",
            "Debug Level: 2 (Verbose)\n",
            "Ngrok: DISABLED\n",
            "Ngrok Token: ‚ùå NOT SET (will use Gradio share)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#@title üîß **User Configuration & Settings Hub** { display-mode: \"form\" }\n",
        "\n",
        "# ====================================\n",
        "# üîß USER CONFIGURATION SECTION\n",
        "# ====================================\n",
        "\n",
        "# NGROK CONFIGURATION (Get token from: https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "NGROK_AUTH_TOKEN = \"\"  # <- PASTE YOUR NGROK TOKEN HERE (Leave empty to use Gradio share only)\n",
        "\n",
        "# WORKSPACE CONFIGURATION\n",
        "WORKSPACE_NAME = \"WanGP_Workspace\"  # Main workspace directory\n",
        "FORCE_CLEAN_INSTALL = False  # Set True to delete existing workspace\n",
        "AUTO_FIX_CONFLICTS = True  # Automatically resolve directory conflicts\n",
        "\n",
        "# ADVANCED SETTINGS\n",
        "DEBUG_LEVEL = 2  # 0=minimal, 1=normal, 2=verbose (shows everything)\n",
        "ENABLE_NGROK = True  # Use ngrok as backup/primary share method\n",
        "NGROK_REGION = \"us\"  # us, eu, ap, au, sa, jp, in\n",
        "MONITOR_RESOURCES = True  # Show real-time GPU/CPU/RAM usage\n",
        "AUTO_RESTART_ON_FAIL = True  # Automatically retry if launch fails\n",
        "ENABLE_UPSAMPLING = True  # Enable temporal/spatial upsampling features\n",
        "DOWNLOAD_ALL_LORAS = True  # Download all essential loras\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üéÆ WANGP v5.41 ROBUST INSTALLATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Workspace: {WORKSPACE_NAME}\")\n",
        "print(f\"Clean Install: {'YES - Will delete existing' if FORCE_CLEAN_INSTALL else 'NO - Will reuse/update'}\")\n",
        "print(f\"Auto-fix: {'ENABLED' if AUTO_FIX_CONFLICTS else 'DISABLED'}\")\n",
        "print(f\"Debug Level: {DEBUG_LEVEL} ({'Verbose' if DEBUG_LEVEL == 2 else 'Normal' if DEBUG_LEVEL == 1 else 'Minimal'})\")\n",
        "print(f\"Ngrok: {'ENABLED' if ENABLE_NGROK and NGROK_AUTH_TOKEN else 'DISABLED'}\")\n",
        "print(f\"Ngrok Token: {'‚úÖ SET' if NGROK_AUTH_TOKEN else '‚ùå NOT SET (will use Gradio share)'}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkHAVneO_m34"
      },
      "source": [
        "## 2. Robust Directory Management System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIkx6qac_m34",
        "outputId": "ae8bcb57-f0d9-420a-b8b2-4347b9dd8303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üìÅ WORKSPACE MANAGEMENT\n",
            "================================================================================\n",
            "Current directory: /content\n",
            "Target workspace: /content/WanGP_Workspace\n",
            "\n",
            "üìÅ Creating new workspace: WanGP_Workspace\n",
            "\n",
            "‚úÖ Working in: /content/WanGP_Workspace\n",
            "Action: clone\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#@title üìÅ **Directory Management & Workspace Setup** { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import torch\n",
        "import platform\n",
        "import psutil\n",
        "import json\n",
        "import time\n",
        "import socket\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "def safe_remove_directory(path):\n",
        "    \"\"\"Safely remove directory with error handling\"\"\"\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            if os.path.islink(path):\n",
        "                os.unlink(path)\n",
        "            else:\n",
        "                shutil.rmtree(path)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not remove {path}: {e}\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def ensure_clean_workspace():\n",
        "    \"\"\"Create a clean workspace directory\"\"\"\n",
        "    current_dir = os.getcwd()\n",
        "    workspace_path = os.path.join(current_dir, WORKSPACE_NAME)\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"üìÅ WORKSPACE MANAGEMENT\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Current directory: {current_dir}\")\n",
        "    print(f\"Target workspace: {workspace_path}\")\n",
        "\n",
        "    # Handle existing workspace\n",
        "    if os.path.exists(workspace_path):\n",
        "        if FORCE_CLEAN_INSTALL:\n",
        "            print(f\"\\nüßπ Force clean enabled - removing existing workspace...\")\n",
        "            if safe_remove_directory(workspace_path):\n",
        "                print(\"‚úÖ Existing workspace removed\")\n",
        "            else:\n",
        "                print(\"‚ùå Could not remove workspace - will work around it\")\n",
        "        else:\n",
        "            print(f\"\\nüìÅ Workspace exists - checking contents...\")\n",
        "\n",
        "            # Check if it contains WanGP\n",
        "            wangp_path = os.path.join(workspace_path, \"WanBook\")\n",
        "            if os.path.exists(wangp_path):\n",
        "                print(f\"‚úÖ Found existing WanBook installation\")\n",
        "\n",
        "                # Check if it's a valid repo\n",
        "                if os.path.exists(os.path.join(wangp_path, \".git\")):\n",
        "                    print(\"‚úÖ Valid git repository found\")\n",
        "                    return workspace_path, wangp_path, \"update\"\n",
        "                else:\n",
        "                    print(\"‚ö†Ô∏è Directory exists but not a git repo\")\n",
        "                    if AUTO_FIX_CONFLICTS:\n",
        "                        print(\"üîß Auto-fix enabled - will clean and re-clone\")\n",
        "                        safe_remove_directory(wangp_path)\n",
        "                        return workspace_path, wangp_path, \"clone\"\n",
        "            else:\n",
        "                print(\"üìÇ Empty workspace - will create WanBook inside\")\n",
        "                return workspace_path, os.path.join(workspace_path, \"WanBook\"), \"clone\"\n",
        "\n",
        "    # Create new workspace\n",
        "    print(f\"\\nüìÅ Creating new workspace: {WORKSPACE_NAME}\")\n",
        "    os.makedirs(workspace_path, exist_ok=True)\n",
        "\n",
        "    return workspace_path, os.path.join(workspace_path, \"WanBook\"), \"clone\"\n",
        "\n",
        "# Setup workspace\n",
        "workspace_dir, repo_path, action = ensure_clean_workspace()\n",
        "\n",
        "# Change to workspace\n",
        "os.chdir(workspace_dir)\n",
        "print(f\"\\n‚úÖ Working in: {os.getcwd()}\")\n",
        "print(f\"Action: {action}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOg5yYKd_m35"
      },
      "source": [
        "## 3. System Diagnostics with Error Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYGqPG7p_m35",
        "outputId": "b68d7cd1-0a36-48e6-9f55-e826f583545e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üîç COMPREHENSIVE SYSTEM DIAGNOSTICS\n",
            "================================================================================\n",
            "Timestamp: 2025-07-02 14:15:22\n",
            "Platform: Linux 6.1.123+\n",
            "Python: 3.11.13\n",
            "Workspace: /content/WanGP_Workspace\n",
            "Environment: Google Colab\n",
            "\n",
            "[RESOURCES]\n",
            "CPU Cores: 1\n",
            "RAM: 12.7 GB total, 11.0 GB available\n",
            "\n",
            "[GPU DETECTION]\n",
            "‚úÖ CUDA Available: True\n",
            "GPU Count: 1\n",
            "CUDA Version: 12.4\n",
            "Primary GPU: Tesla T4\n",
            "VRAM: 14.74 GB\n",
            "Generation: standard\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#@title üîç **Comprehensive System Diagnostics & GPU Detection** { display-mode: \"form\" }\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üîç COMPREHENSIVE SYSTEM DIAGNOSTICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def safe_get_info(func, default=\"Unknown\"):\n",
        "    \"\"\"Safely get system info with fallback\"\"\"\n",
        "    try:\n",
        "        return func()\n",
        "    except:\n",
        "        return default\n",
        "\n",
        "# Basic system info\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Platform: {safe_get_info(lambda: f'{platform.system()} {platform.release()}')}\")\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"Workspace: {workspace_dir}\")\n",
        "\n",
        "# Detect environment\n",
        "env_indicators = {\n",
        "    'Google Colab': lambda: 'google.colab' in str(get_ipython()),\n",
        "    'Kaggle': lambda: 'KAGGLE_URL_BASE' in os.environ,\n",
        "    'Lightning.ai': lambda: 'LIGHTNING_CLOUD_URL' in os.environ,\n",
        "    'Vast.ai': lambda: os.path.exists('/opt/bin/nvidia-smi'),\n",
        "    'Paperspace': lambda: 'PS_API_KEY' in os.environ\n",
        "}\n",
        "\n",
        "detected_env = \"Unknown\"\n",
        "for env_name, check_func in env_indicators.items():\n",
        "    if safe_get_info(check_func, False):\n",
        "        detected_env = env_name\n",
        "        break\n",
        "\n",
        "print(f\"Environment: {detected_env}\")\n",
        "\n",
        "# Resource info\n",
        "print(f\"\\n[RESOURCES]\")\n",
        "print(f\"CPU Cores: {safe_get_info(lambda: psutil.cpu_count(logical=False), 'Unknown')}\")\n",
        "mem = safe_get_info(lambda: psutil.virtual_memory(), None)\n",
        "if mem:\n",
        "    print(f\"RAM: {mem.total/(1024**3):.1f} GB total, {mem.available/(1024**3):.1f} GB available\")\n",
        "else:\n",
        "    print(\"RAM: Could not detect\")\n",
        "\n",
        "# GPU Detection with comprehensive error handling\n",
        "print(f\"\\n[GPU DETECTION]\")\n",
        "gpu_available = False\n",
        "gpu_info = \"No GPU\"\n",
        "gpu_memory = 0\n",
        "gpu_generation = 'none'\n",
        "\n",
        "try:\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        print(f\"‚úÖ CUDA Available: True\")\n",
        "        print(f\"GPU Count: {gpu_count}\")\n",
        "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "\n",
        "        # Get primary GPU info\n",
        "        gpu_info = torch.cuda.get_device_name(0)\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        gpu_memory = props.total_memory / (1024**3)\n",
        "\n",
        "        print(f\"Primary GPU: {gpu_info}\")\n",
        "        print(f\"VRAM: {gpu_memory:.2f} GB\")\n",
        "\n",
        "        # Determine generation\n",
        "        gpu_name_lower = gpu_info.lower()\n",
        "        if any(x in gpu_name_lower for x in ['5090', '5080', '5070', '5060', '5050']):\n",
        "            gpu_generation = 'rtx50xx'\n",
        "            pytorch_version = \"2.7.0\"\n",
        "            cuda_index = \"cu128\"\n",
        "        elif any(x in gpu_name_lower for x in ['a100', 'a6000', 'a40', 'v100']):\n",
        "            gpu_generation = 'datacenter'\n",
        "            pytorch_version = \"2.6.0\"\n",
        "            cuda_index = \"cu124\"\n",
        "        else:\n",
        "            gpu_generation = 'standard'\n",
        "            pytorch_version = \"2.6.0\"\n",
        "            cuda_index = \"cu124\"\n",
        "\n",
        "        print(f\"Generation: {gpu_generation}\")\n",
        "        gpu_available = True\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå CUDA Not Available\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå GPU Detection Error: {e}\")\n",
        "\n",
        "if not gpu_available:\n",
        "    print(\"\\nüîß GPU TROUBLESHOOTING:\")\n",
        "    print(\"1. Google Colab: Runtime > Change runtime type > GPU\")\n",
        "    print(\"2. Other platforms: Ensure GPU instance selected\")\n",
        "    print(\"3. Try: !nvidia-smi to check GPU status\")\n",
        "\n",
        "    # Still allow CPU execution for testing\n",
        "    print(\"\\n‚ö†Ô∏è Continuing with CPU mode (very slow)\")\n",
        "    gpu_info = \"CPU Mode\"\n",
        "    gpu_memory = 0\n",
        "    pytorch_version = \"2.6.0\"\n",
        "    cuda_index = \"cu124\"\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36NawmwL_m36"
      },
      "source": [
        "## 4. Repository Management with Conflict Resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "tydT2KMP_m36",
        "outputId": "382f4bd4-7790-4e14-c269-1594533f46c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%); \n",
              "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0; \n",
              "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "        <h2>üéØ REPOSITORY SETUP VERIFICATION - CORRECTED</h2>\n",
              "        <p>Validating WanBook repository structure and Wan2GP implementation</p>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üîç COMPREHENSIVE REPOSITORY VERIFICATION\n",
            "================================================================================\n",
            "üìÇ Repository Base: /content/WanGP_Workspace/WanBook\n",
            "üìÇ Wan2GP Implementation: /content/WanGP_Workspace/WanBook/Wan2GP\n",
            "\n",
            "‚ùå WanBook repository: NOT FOUND\n",
            "\n",
            "üéØ Verification complete! Ready for next cell.\n"
          ]
        }
      ],
      "source": [
        "#@title üéØ **Repository Setup Verification - CORRECTED** { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def display_verification_header():\n",
        "    \"\"\"Display corrected verification header\"\"\"\n",
        "    header_html = '''\n",
        "    <div style=\"background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%);\n",
        "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\n",
        "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "        <h2>üéØ REPOSITORY SETUP VERIFICATION - CORRECTED</h2>\n",
        "        <p>Validating WanBook repository structure and Wan2GP implementation</p>\n",
        "    </div>\n",
        "    '''\n",
        "    display(HTML(header_html))\n",
        "\n",
        "def check_file_exists(file_path, description=\"\"):\n",
        "    \"\"\"Check if file exists and return status with size info\"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        try:\n",
        "            size = os.path.getsize(file_path)\n",
        "            size_mb = size / (1024 * 1024)\n",
        "            if size_mb > 1:\n",
        "                size_str = f\"({size_mb:.1f} MB)\"\n",
        "            else:\n",
        "                size_str = f\"({size // 1024} KB)\"\n",
        "            return True, size_str\n",
        "        except:\n",
        "            return True, \"\"\n",
        "    return False, \"\"\n",
        "\n",
        "def verify_repository_structure():\n",
        "    \"\"\"Verify complete WanBook repository structure\"\"\"\n",
        "    display_verification_header()\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üîç COMPREHENSIVE REPOSITORY VERIFICATION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Base paths\n",
        "    base_path = \"/content/WanGP_Workspace/WanBook\"\n",
        "    wan2gp_path = os.path.join(base_path, \"Wan2GP\")\n",
        "\n",
        "    print(f\"üìÇ Repository Base: {base_path}\")\n",
        "    print(f\"üìÇ Wan2GP Implementation: {wan2gp_path}\")\n",
        "    print()\n",
        "\n",
        "    # Verify base repository\n",
        "    if os.path.exists(base_path):\n",
        "        print(\"‚úÖ WanBook repository: FOUND\")\n",
        "        print(f\"‚úÖ Python path updated: {base_path in sys.path}\")\n",
        "        print(f\"‚úÖ Environment variable: {os.environ.get('WANBOOK_ROOT', 'Not set')}\")\n",
        "    else:\n",
        "        print(\"‚ùå WanBook repository: NOT FOUND\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üìÅ CORE FILES VERIFICATION\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Key files to check with correct paths\n",
        "    core_files = [\n",
        "        # Main WanBook files\n",
        "        (os.path.join(base_path, \"requirements.txt\"), \"WanBook Requirements\"),\n",
        "        (os.path.join(base_path, \"WanBook.ipynb\"), \"Main Notebook\"),\n",
        "        (os.path.join(base_path, \"README.md\"), \"Documentation\"),\n",
        "\n",
        "        # Wan2GP implementation files\n",
        "        (os.path.join(wan2gp_path, \"wgp.py\"), \"Main WanGP Application\"),\n",
        "        (os.path.join(wan2gp_path, \"requirements.txt\"), \"Wan2GP Requirements\"),\n",
        "\n",
        "        # Check for model directories\n",
        "        (os.path.join(wan2gp_path, \"wan\"), \"Wan Models Directory\"),\n",
        "        (os.path.join(wan2gp_path, \"hyvideo\"), \"Hunyuan Video Directory\"),\n",
        "        (os.path.join(wan2gp_path, \"ltx_video\"), \"LTX Video Directory\"),\n",
        "    ]\n",
        "\n",
        "    # Verify each file\n",
        "    found_files = 0\n",
        "    total_files = len(core_files)\n",
        "\n",
        "    for file_path, description in core_files:\n",
        "        exists, size_info = check_file_exists(file_path)\n",
        "        if exists:\n",
        "            print(f\"   ‚úÖ Found: {description} {size_info}\")\n",
        "            found_files += 1\n",
        "        else:\n",
        "            print(f\"   ‚ùå Missing: {description}\")\n",
        "            print(f\"      Expected: {file_path}\")\n",
        "\n",
        "    print(f\"\\nüìä File Status: {found_files}/{total_files} files found\")\n",
        "\n",
        "    # Verify critical implementation\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üéØ CRITICAL IMPLEMENTATION CHECK\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    wgp_main = os.path.join(wan2gp_path, \"wgp.py\")\n",
        "    if os.path.exists(wgp_main):\n",
        "        print(\"‚úÖ CRITICAL: wgp.py found in correct location!\")\n",
        "        print(f\"   üìç Location: {wgp_main}\")\n",
        "\n",
        "        # Check file size to verify it's the real implementation\n",
        "        size = os.path.getsize(wgp_main)\n",
        "        size_kb = size // 1024\n",
        "        print(f\"   üìè Size: {size_kb} KB\")\n",
        "\n",
        "        if size_kb > 100:  # Should be substantial file\n",
        "            print(\"   ‚úÖ File size indicates complete implementation\")\n",
        "        else:\n",
        "            print(\"   ‚ö†Ô∏è  File seems small - may be incomplete\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå CRITICAL: wgp.py NOT found!\")\n",
        "        print(f\"   Expected location: {wgp_main}\")\n",
        "\n",
        "        # Check if it's in the wrong location\n",
        "        wrong_location = os.path.join(base_path, \"wgp.py\")\n",
        "        if os.path.exists(wrong_location):\n",
        "            print(f\"   ‚ÑπÔ∏è  Found in wrong location: {wrong_location}\")\n",
        "\n",
        "    # Model directories check\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ü§ñ MODEL IMPLEMENTATION CHECK\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    model_dirs = [\n",
        "        (os.path.join(wan2gp_path, \"wan\"), \"Wan Models\"),\n",
        "        (os.path.join(wan2gp_path, \"hyvideo\"), \"Hunyuan Video\"),\n",
        "        (os.path.join(wan2gp_path, \"ltx_video\"), \"LTX Video\"),\n",
        "        (os.path.join(wan2gp_path, \"loras\"), \"LoRA System\"),\n",
        "    ]\n",
        "\n",
        "    for dir_path, dir_name in model_dirs:\n",
        "        if os.path.exists(dir_path):\n",
        "            file_count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
        "            print(f\"   ‚úÖ {dir_name}: {file_count} files\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå {dir_name}: Not found\")\n",
        "\n",
        "    # Final status\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üöÄ SETUP STATUS SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if os.path.exists(wgp_main):\n",
        "        print(\"‚úÖ READY: Complete WanGP implementation found!\")\n",
        "        print(\"‚úÖ READY: Repository properly configured!\")\n",
        "        print(\"‚úÖ READY: Proceed to next cell for system diagnostics!\")\n",
        "\n",
        "        # Update Python path for Wan2GP\n",
        "        if wan2gp_path not in sys.path:\n",
        "            sys.path.insert(0, wan2gp_path)\n",
        "            print(f\"‚úÖ READY: Wan2GP path added: {wan2gp_path}\")\n",
        "\n",
        "        return True\n",
        "    else:\n",
        "        print(\"‚ùå ERROR: Critical files missing - setup incomplete\")\n",
        "        print(\"‚ö†Ô∏è  Please check repository structure\")\n",
        "        return False\n",
        "\n",
        "# Execute verification\n",
        "verification_success = verify_repository_structure()\n",
        "\n",
        "# Set environment variables for next cells\n",
        "if verification_success:\n",
        "    os.environ['WAN2GP_PATH'] = '/content/WanGP_Workspace/WanBook/Wan2GP'\n",
        "    os.environ['WGP_MAIN'] = '/content/WanGP_Workspace/WanBook/Wan2GP/wgp.py'\n",
        "    print(f\"\\nüîß Environment configured:\")\n",
        "    print(f\"   WAN2GP_PATH: {os.environ['WAN2GP_PATH']}\")\n",
        "    print(f\"   WGP_MAIN: {os.environ['WGP_MAIN']}\")\n",
        "\n",
        "print(\"\\nüéØ Verification complete! Ready for next cell.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2jwcnN1_m37"
      },
      "source": [
        "## 5. Install PyTorch with Version Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxzAL43B_m37",
        "outputId": "17359264-4c0e-41db-aecf-4dd0b1f2ddc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üîß PYTORCH INSTALLATION\n",
            "================================================================================\n",
            "Current PyTorch: 2.6.0+cu124\n",
            "Current CUDA: 12.4\n",
            "‚úÖ PyTorch already compatible\n",
            "\n",
            "Verifying PyTorch...\n",
            "‚úÖ PyTorch 2.6.0+cu124\n",
            "‚úÖ CUDA available: True\n",
            "‚úÖ GPU accessible: Tesla T4\n",
            "‚úÖ GPU operations working\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#@title üîß **PyTorch Installation** { display-mode: \"form\" }\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üîß PYTORCH INSTALLATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def check_pytorch_compatibility():\n",
        "    \"\"\"Check if current PyTorch is compatible\"\"\"\n",
        "    try:\n",
        "        import torch as existing_torch\n",
        "        current_version = existing_torch.__version__\n",
        "        current_cuda = existing_torch.version.cuda\n",
        "\n",
        "        print(f\"Current PyTorch: {current_version}\")\n",
        "        print(f\"Current CUDA: {current_cuda}\")\n",
        "\n",
        "        # Check compatibility\n",
        "        needs_reinstall = False\n",
        "\n",
        "        if gpu_generation == 'rtx50xx':\n",
        "            if not current_version.startswith('2.7'):\n",
        "                print(\"‚ö†Ô∏è RTX 50XX requires PyTorch 2.7.0\")\n",
        "                needs_reinstall = True\n",
        "        else:\n",
        "            if not current_version.startswith('2.6'):\n",
        "                print(\"‚ÑπÔ∏è Stable PyTorch 2.6.0 recommended\")\n",
        "                needs_reinstall = True\n",
        "\n",
        "        if not torch.cuda.is_available() and gpu_available:\n",
        "            print(\"‚ö†Ô∏è PyTorch doesn't detect CUDA\")\n",
        "            needs_reinstall = True\n",
        "\n",
        "        return needs_reinstall, current_version\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"No PyTorch found\")\n",
        "        return True, None\n",
        "\n",
        "# Check current installation\n",
        "needs_install, current_version = check_pytorch_compatibility()\n",
        "\n",
        "if needs_install:\n",
        "    print(f\"\\n[Installing PyTorch {pytorch_version}]\")\n",
        "\n",
        "    # Uninstall existing if needed\n",
        "    if current_version:\n",
        "        print(\"Removing existing PyTorch...\")\n",
        "        ret, _, _ = run_command_safe(\"pip uninstall torch torchvision torchaudio -y\", timeout=120)\n",
        "        if ret == 0:\n",
        "            print(\"‚úÖ Removed existing PyTorch\")\n",
        "\n",
        "    # Install new version\n",
        "    install_cmd = f\"pip install torch=={pytorch_version} torchvision torchaudio --index-url https://download.pytorch.org/whl/test/{cuda_index}\"\n",
        "    print(f\"Installing: {install_cmd}\")\n",
        "    print(\"This may take 5-10 minutes...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    ret, stdout, stderr = run_command_safe(install_cmd, timeout=900)  # 15 minutes max\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    if ret == 0:\n",
        "        print(f\"‚úÖ PyTorch installed in {elapsed/60:.1f} minutes\")\n",
        "    else:\n",
        "        print(f\"‚ùå Installation failed: {stderr}\")\n",
        "        print(\"üîÑ Trying with pip upgrade...\")\n",
        "        ret, _, _ = run_command_safe(\"pip install --upgrade pip\", timeout=60)\n",
        "        ret, _, stderr = run_command_safe(install_cmd, timeout=900)\n",
        "        if ret != 0:\n",
        "            raise RuntimeError(f\"PyTorch installation failed: {stderr}\")\n",
        "else:\n",
        "    print(\"‚úÖ PyTorch already compatible\")\n",
        "\n",
        "# Verify installation\n",
        "print(\"\\nVerifying PyTorch...\")\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"‚úÖ PyTorch {torch.__version__}\")\n",
        "    print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"‚úÖ GPU accessible: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "        # Quick GPU test\n",
        "        try:\n",
        "            test_tensor = torch.rand(100, 100).cuda()\n",
        "            result = test_tensor @ test_tensor\n",
        "            print(\"‚úÖ GPU operations working\")\n",
        "            del test_tensor, result\n",
        "            torch.cuda.empty_cache()\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è GPU test failed: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå PyTorch verification failed: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gQMtjaF_m38"
      },
      "source": [
        "## 6. Dependencies with Retry Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PixkpslA_m38",
        "outputId": "65fabee8-b2fd-46d6-a9db-4508646b5829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dependency installation from correct Wan2GP location...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background: linear-gradient(135deg, #FF9800 0%, #FF5722 100%); \n",
              "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0; \n",
              "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "        <h2>üì¶ DEPENDENCY INSTALLATION</h2>\n",
              "        <p>Installing WanGP dependencies from Wan2GP requirements</p>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üì¶ DEPENDENCY INSTALLATION\n",
            "================================================================================\n",
            "üîç Searching for requirements files...\n",
            "‚ùå No requirements.txt files found!\n",
            "üîß Proceeding with manual installation...\n",
            "üîß Installing essential packages manually...\n",
            "üì¶ Installing torch>=2.0.0...\n",
            "‚úÖ torch>=2.0.0 installed successfully\n",
            "üì¶ Installing torchvision...\n",
            "‚úÖ torchvision installed successfully\n",
            "üì¶ Installing torchaudio...\n",
            "‚úÖ torchaudio installed successfully\n",
            "üì¶ Installing gradio>=4.0.0...\n",
            "‚úÖ gradio>=4.0.0 installed successfully\n",
            "üì¶ Installing transformers>=4.30.0...\n",
            "‚úÖ transformers>=4.30.0 installed successfully\n",
            "üì¶ Installing diffusers>=0.25.0...\n",
            "‚úÖ diffusers>=0.25.0 installed successfully\n",
            "üì¶ Installing accelerate>=0.20.0...\n",
            "‚úÖ accelerate>=0.20.0 installed successfully\n",
            "üì¶ Installing opencv-python...\n",
            "‚úÖ opencv-python installed successfully\n",
            "üì¶ Installing pillow...\n",
            "‚úÖ pillow installed successfully\n",
            "üì¶ Installing numpy...\n",
            "‚úÖ numpy installed successfully\n",
            "üì¶ Installing safetensors...\n",
            "‚úÖ safetensors installed successfully\n",
            "üì¶ Installing huggingface-hub...\n",
            "‚úÖ huggingface-hub installed successfully\n",
            "üì¶ Installing scipy...\n",
            "‚úÖ scipy installed successfully\n",
            "üì¶ Installing imageio...\n",
            "‚úÖ imageio installed successfully\n",
            "üì¶ Installing imageio-ffmpeg...\n",
            "‚úÖ imageio-ffmpeg installed successfully\n",
            "\n",
            "==================================================\n",
            "üîç VERIFYING INSTALLATIONS\n",
            "==================================================\n",
            "‚úÖ PyTorch: 2.6.0+cu124\n",
            "‚úÖ Gradio: 5.31.0\n",
            "‚úÖ Transformers: 4.52.4\n",
            "‚úÖ Diffusers: 0.34.0\n",
            "‚úÖ Accelerate: 1.8.1\n",
            "‚úÖ OpenCV: 4.11.0\n",
            "‚úÖ Pillow: 11.2.1\n",
            "‚úÖ NumPy: 2.0.2\n",
            "\n",
            "üìä Import Status: 8/8 packages successfully imported\n",
            "\n",
            "================================================================================\n",
            "üéØ DEPENDENCY INSTALLATION COMPLETE\n",
            "================================================================================\n",
            "‚úÖ READY: All essential packages installed successfully!\n",
            "‚úÖ READY: WanGP dependencies are ready!\n",
            "üöÄ READY: Proceed to next cell for WanGP launch!\n",
            "\n",
            "üîß Environment configured for WanGP launch\n",
            "\n",
            "üéØ Dependency installation complete! Ready for next cell.\n"
          ]
        }
      ],
      "source": [
        "#@title üì¶ **Dependency Installation - CORRECTED PATH** { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML, display, clear_output\n",
        "\n",
        "def display_dependency_header():\n",
        "    \"\"\"Display dependency installation header\"\"\"\n",
        "    header_html = '''\n",
        "    <div style=\"background: linear-gradient(135deg, #FF9800 0%, #FF5722 100%);\n",
        "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\n",
        "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "        <h2>üì¶ DEPENDENCY INSTALLATION</h2>\n",
        "        <p>Installing WanGP dependencies from Wan2GP requirements</p>\n",
        "    </div>\n",
        "    '''\n",
        "    display(HTML(header_html))\n",
        "\n",
        "def find_requirements_files():\n",
        "    \"\"\"Find all requirements.txt files in the repository\"\"\"\n",
        "    base_path = \"/content/WanGP_Workspace/WanBook\"\n",
        "    requirements_files = []\n",
        "\n",
        "    # Check main WanBook requirements.txt\n",
        "    main_req = os.path.join(base_path, \"requirements.txt\")\n",
        "    if os.path.exists(main_req):\n",
        "        size = os.path.getsize(main_req)\n",
        "        requirements_files.append((main_req, f\"WanBook Main ({size} bytes)\"))\n",
        "\n",
        "    # Check Wan2GP requirements.txt (this should be the main one)\n",
        "    wan2gp_req = os.path.join(base_path, \"Wan2GP\", \"requirements.txt\")\n",
        "    if os.path.exists(wan2gp_req):\n",
        "        size = os.path.getsize(wan2gp_req)\n",
        "        requirements_files.append((wan2gp_req, f\"Wan2GP Implementation ({size} bytes)\"))\n",
        "\n",
        "    return requirements_files\n",
        "\n",
        "def install_requirements(requirements_file, description):\n",
        "    \"\"\"Install requirements from specific file\"\"\"\n",
        "    print(f\"üì¶ Installing from: {description}\")\n",
        "    print(f\"üìç File path: {requirements_file}\")\n",
        "\n",
        "    try:\n",
        "        # Check if file exists and has content\n",
        "        if not os.path.exists(requirements_file):\n",
        "            print(f\"‚ùå File not found: {requirements_file}\")\n",
        "            return False\n",
        "\n",
        "        file_size = os.path.getsize(requirements_file)\n",
        "        if file_size == 0:\n",
        "            print(f\"‚ö†Ô∏è  Requirements file is empty ({file_size} bytes)\")\n",
        "            return False\n",
        "\n",
        "        print(f\"‚úÖ Found requirements file ({file_size} bytes)\")\n",
        "\n",
        "        # Install using pip\n",
        "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_file]\n",
        "        print(f\"üîß Running: {' '.join(cmd)}\")\n",
        "\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=600  # 10 minute timeout\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"‚úÖ Successfully installed from {description}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå Installation failed from {description}\")\n",
        "            print(f\"Error: {result.stderr}\")\n",
        "            return False\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"‚ùå Installation timed out for {description}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Installation error for {description}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def install_essential_packages():\n",
        "    \"\"\"Install essential packages manually if requirements.txt fails\"\"\"\n",
        "    essential_packages = [\n",
        "        \"torch>=2.0.0\",\n",
        "        \"torchvision\",\n",
        "        \"torchaudio\",\n",
        "        \"gradio>=4.0.0\",\n",
        "        \"transformers>=4.30.0\",\n",
        "        \"diffusers>=0.25.0\",\n",
        "        \"accelerate>=0.20.0\",\n",
        "        \"opencv-python\",\n",
        "        \"pillow\",\n",
        "        \"numpy\",\n",
        "        \"safetensors\",\n",
        "        \"huggingface-hub\",\n",
        "        \"scipy\",\n",
        "        \"imageio\",\n",
        "        \"imageio-ffmpeg\"\n",
        "    ]\n",
        "\n",
        "    print(\"üîß Installing essential packages manually...\")\n",
        "\n",
        "    for package in essential_packages:\n",
        "        try:\n",
        "            print(f\"üì¶ Installing {package}...\")\n",
        "            result = subprocess.run(\n",
        "                [sys.executable, \"-m\", \"pip\", \"install\", package],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=300\n",
        "            )\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(f\"‚úÖ {package} installed successfully\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  {package} installation had issues: {result.stderr[:100]}...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to install {package}: {str(e)}\")\n",
        "\n",
        "    return True\n",
        "\n",
        "def verify_installations():\n",
        "    \"\"\"Verify that key packages are installed\"\"\"\n",
        "    key_packages = {\n",
        "        'torch': 'PyTorch',\n",
        "        'gradio': 'Gradio',\n",
        "        'transformers': 'Transformers',\n",
        "        'diffusers': 'Diffusers',\n",
        "        'accelerate': 'Accelerate',\n",
        "        'cv2': 'OpenCV',\n",
        "        'PIL': 'Pillow',\n",
        "        'numpy': 'NumPy'\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üîç VERIFYING INSTALLATIONS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    successful_imports = 0\n",
        "    total_packages = len(key_packages)\n",
        "\n",
        "    for module, name in key_packages.items():\n",
        "        try:\n",
        "            if module == 'cv2':\n",
        "                import cv2\n",
        "                version = cv2.__version__\n",
        "            elif module == 'PIL':\n",
        "                from PIL import Image\n",
        "                version = Image.__version__ if hasattr(Image, '__version__') else \"Unknown\"\n",
        "            else:\n",
        "                imported_module = __import__(module)\n",
        "                version = getattr(imported_module, '__version__', 'Unknown')\n",
        "\n",
        "            print(f\"‚úÖ {name}: {version}\")\n",
        "            successful_imports += 1\n",
        "\n",
        "        except ImportError as e:\n",
        "            print(f\"‚ùå {name}: Not found - {str(e)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  {name}: Import error - {str(e)}\")\n",
        "\n",
        "    print(f\"\\nüìä Import Status: {successful_imports}/{total_packages} packages successfully imported\")\n",
        "\n",
        "    return successful_imports >= (total_packages * 0.8)  # 80% success rate\n",
        "\n",
        "def run_dependency_installation():\n",
        "    \"\"\"Main dependency installation function\"\"\"\n",
        "    display_dependency_header()\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"üì¶ DEPENDENCY INSTALLATION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Find requirements files\n",
        "    print(\"üîç Searching for requirements files...\")\n",
        "    requirements_files = find_requirements_files()\n",
        "\n",
        "    if not requirements_files:\n",
        "        print(\"‚ùå No requirements.txt files found!\")\n",
        "        print(\"üîß Proceeding with manual installation...\")\n",
        "        install_essential_packages()\n",
        "    else:\n",
        "        print(f\"‚úÖ Found {len(requirements_files)} requirements files:\")\n",
        "        for file_path, description in requirements_files:\n",
        "            print(f\"   üìÑ {description}: {file_path}\")\n",
        "\n",
        "        # Install from requirements files (prioritize Wan2GP)\n",
        "        installation_success = False\n",
        "\n",
        "        # Try Wan2GP requirements first (most important)\n",
        "        for file_path, description in requirements_files:\n",
        "            if \"Wan2GP\" in description:\n",
        "                print(f\"\\nüéØ Prioritizing {description} (contains actual WanGP dependencies)\")\n",
        "                if install_requirements(file_path, description):\n",
        "                    installation_success = True\n",
        "                    break\n",
        "\n",
        "        # If Wan2GP requirements failed, try WanBook requirements\n",
        "        if not installation_success:\n",
        "            for file_path, description in requirements_files:\n",
        "                if \"WanBook\" in description:\n",
        "                    print(f\"\\nüîÑ Trying {description} as fallback...\")\n",
        "                    if install_requirements(file_path, description):\n",
        "                        installation_success = True\n",
        "                        break\n",
        "\n",
        "        # If all requirements files failed, install manually\n",
        "        if not installation_success:\n",
        "            print(\"\\n‚ùå All requirements.txt installations failed\")\n",
        "            print(\"üîß Proceeding with manual essential package installation...\")\n",
        "            install_essential_packages()\n",
        "\n",
        "    # Verify installations\n",
        "    verification_success = verify_installations()\n",
        "\n",
        "    # Final status\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üéØ DEPENDENCY INSTALLATION COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if verification_success:\n",
        "        print(\"‚úÖ READY: All essential packages installed successfully!\")\n",
        "        print(\"‚úÖ READY: WanGP dependencies are ready!\")\n",
        "        print(\"üöÄ READY: Proceed to next cell for WanGP launch!\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  WARNING: Some packages may be missing\")\n",
        "        print(\"üîß You may need to install missing packages manually\")\n",
        "        print(\"üìù Try: !pip install <missing_package_name>\")\n",
        "\n",
        "    return verification_success\n",
        "\n",
        "# Execute dependency installation\n",
        "print(\"Starting dependency installation from correct Wan2GP location...\")\n",
        "installation_success = run_dependency_installation()\n",
        "\n",
        "# Set environment variables for next cells\n",
        "if installation_success:\n",
        "    os.environ['WANGP_DEPS_INSTALLED'] = 'true'\n",
        "    print(f\"\\nüîß Environment configured for WanGP launch\")\n",
        "else:\n",
        "    os.environ['WANGP_DEPS_INSTALLED'] = 'partial'\n",
        "    print(f\"\\n‚ö†Ô∏è Partial installation - manual fixes may be needed\")\n",
        "\n",
        "print(\"\\nüéØ Dependency installation complete! Ready for next cell.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1eBlRcF_m38"
      },
      "source": [
        "## 7. Performance Optimization & Launch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2DPod_r_m38",
        "outputId": "d562fdc1-07bc-4f45-8308-94cc35eb56e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üöÄ LAUNCHING WANGP v5.41\n",
            "================================================================================\n",
            "Launch command: python wgp.py --share --server-port 7860 --verbose 2\n",
            "\n",
            "üöÄ Starting WanGP...\n",
            "Look for 'Running on public URL:' in the output below\n",
            "================================================================================\n",
            "\n",
            "üéâ WanGP session ended!\n"
          ]
        }
      ],
      "source": [
        "#@title üöÄ **Launch WanGP** { display-mode: \"form\" }\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üöÄ LAUNCHING WANGP v5.41\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Build launch command\n",
        "launch_command = [\n",
        "    \"python\", \"wgp.py\",\n",
        "    \"--share\",  # CRITICAL for cloud access\n",
        "    \"--server-port\", \"7860\",\n",
        "    \"--verbose\", str(DEBUG_LEVEL)\n",
        "]\n",
        "\n",
        "print(f\"Launch command: {' '.join(launch_command)}\")\n",
        "\n",
        "# Launch the application\n",
        "try:\n",
        "    print(\"\\nüöÄ Starting WanGP...\")\n",
        "    print(\"Look for 'Running on public URL:' in the output below\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    result = subprocess.run(launch_command)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n‚ö†Ô∏è Stopped by user\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Launch error: {e}\")\n",
        "\n",
        "print(\"\\nüéâ WanGP session ended!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SigdTWc2_m39"
      },
      "source": [
        "## üéâ Setup Complete!\n",
        "\n",
        "Your WanGP v5.41 installation is complete with:\n",
        "\n",
        "‚úÖ **Robust Directory Management** - No more nesting issues  \n",
        "‚úÖ **Error-Proof Installation** - Handles conflicts automatically  \n",
        "‚úÖ **Dual Share Methods** - Gradio + Ngrok for reliable access  \n",
        "‚úÖ **Complete Debug Output** - Full visibility into all operations  \n",
        "‚úÖ **All v5.41 Features** - Every model and feature available  \n",
        "\n",
        "**Look for the public URLs in the output above and start creating amazing videos!** üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd WanBook\n",
        "!python wgp.py --share --server-port 7860 --verbose 2"
      ],
      "metadata": {
        "id": "SId-drcSgMJ9",
        "outputId": "520dfab4-03d7-47e1-f682-28989e06c558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: WanBook: No such file or directory\n",
            "python3: can't open file '/content/WanGP_Workspace/wgp.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2yv_ssnngP2u",
        "outputId": "2fb2ffe9-e110-4732-92b5-528eff9cb2bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/WanGP_Workspace\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}