{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB4UDQgI_m31"
      },
      "source": [
        "# 🎬 **WanGP v5.41 - Complete Cloud Installation with Enhanced Debugging & Dual Share**\n",
        "\n",
        "## 🎬 ALL Features from v5.41 Including:\n",
        "- **Dual Public Access**: Gradio --share + ngrok for maximum reliability\n",
        "- **Full Debug Output**: Complete verbose logging of all operations\n",
        "- **Robust Directory Management**: Error-proof workspace handling\n",
        "- **All Models**: Wan, Hunyuan, LTX, VACE (1.3B & 14B), MoviiGen, etc.\n",
        "- **Queue System**: Stack multiple generation tasks\n",
        "- **Video Settings Management**: Save/load/reuse video settings (v5.3)\n",
        "- **Complete Error Handling**: Bulletproof against common issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ydcCb2_m33"
      },
      "source": [
        "## 1. Workspace Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Qmd2QM_m33",
        "outputId": "3e16698b-5ae8-44e6-ca7b-3c196060b1bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "🎮 WANGP v5.41 ROBUST INSTALLATION\n",
            "================================================================================\n",
            "Workspace: WanGP_Workspace\n",
            "Clean Install: NO - Will reuse/update\n",
            "Auto-fix: ENABLED\n",
            "Debug Level: 2 (Verbose)\n",
            "Ngrok: ENABLED\n",
            "Ngrok Token: ✅ SET\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#@title 🔧 **User Configuration & Settings Hub** { display-mode: \"form\" }\n",
        "\n",
        "# ====================================\n",
        "# 🔧 USER CONFIGURATION SECTION\n",
        "# ====================================\n",
        "\n",
        "# NGROK CONFIGURATION (Get token from: https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "NGROK_AUTH_TOKEN = \"2tjxIXifSaGR3dMhkvhk6sZqbGo_6ZfBZLZHMbtAjfRmfoDW5\"  # <- PASTE YOUR NGROK TOKEN HERE (Leave empty to use Gradio share only)\n",
        "\n",
        "# WORKSPACE CONFIGURATION\n",
        "WORKSPACE_NAME = \"WanGP_Workspace\"  # Main workspace directory\n",
        "FORCE_CLEAN_INSTALL = False  # Set True to delete existing workspace\n",
        "AUTO_FIX_CONFLICTS = True  # Automatically resolve directory conflicts\n",
        "\n",
        "# ADVANCED SETTINGS\n",
        "DEBUG_LEVEL = 2  # 0=minimal, 1=normal, 2=verbose (shows everything)\n",
        "ENABLE_NGROK = True  # Use ngrok as backup/primary share method\n",
        "NGROK_REGION = \"us\"  # us, eu, ap, au, sa, jp, in\n",
        "MONITOR_RESOURCES = True  # Show real-time GPU/CPU/RAM usage\n",
        "AUTO_RESTART_ON_FAIL = True  # Automatically retry if launch fails\n",
        "ENABLE_UPSAMPLING = True  # Enable temporal/spatial upsampling features\n",
        "DOWNLOAD_ALL_LORAS = True  # Download all essential loras\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"🎮 WANGP v5.41 ROBUST INSTALLATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Workspace: {WORKSPACE_NAME}\")\n",
        "print(f\"Clean Install: {'YES - Will delete existing' if FORCE_CLEAN_INSTALL else 'NO - Will reuse/update'}\")\n",
        "print(f\"Auto-fix: {'ENABLED' if AUTO_FIX_CONFLICTS else 'DISABLED'}\")\n",
        "print(f\"Debug Level: {DEBUG_LEVEL} ({'Verbose' if DEBUG_LEVEL == 2 else 'Normal' if DEBUG_LEVEL == 1 else 'Minimal'})\")\n",
        "print(f\"Ngrok: {'ENABLED' if ENABLE_NGROK and NGROK_AUTH_TOKEN else 'DISABLED'}\")\n",
        "print(f\"Ngrok Token: {'✅ SET' if NGROK_AUTH_TOKEN else '❌ NOT SET (will use Gradio share)'}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkHAVneO_m34"
      },
      "source": [
        "## 2. Robust Directory Management System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIkx6qac_m34",
        "outputId": "24b2913d-f566-40cf-b019-09a78b94147b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "📁 WORKSPACE MANAGEMENT\n",
            "================================================================================\n",
            "Current directory: /content/WanGP_Workspace\n",
            "Target workspace: /content/WanGP_Workspace/WanGP_Workspace\n",
            "\n",
            "📁 Creating new workspace: WanGP_Workspace\n",
            "\n",
            "✅ Working in: /content/WanGP_Workspace/WanGP_Workspace\n",
            "Action: clone\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#@title 📁 **Directory Management & Workspace Setup** { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import torch\n",
        "import platform\n",
        "import psutil\n",
        "import json\n",
        "import time\n",
        "import socket\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "def safe_remove_directory(path):\n",
        "    \"\"\"Safely remove directory with error handling\"\"\"\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            if os.path.islink(path):\n",
        "                os.unlink(path)\n",
        "            else:\n",
        "                shutil.rmtree(path)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not remove {path}: {e}\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def ensure_clean_workspace():\n",
        "    \"\"\"Create a clean workspace directory\"\"\"\n",
        "    current_dir = os.getcwd()\n",
        "    workspace_path = os.path.join(current_dir, WORKSPACE_NAME)\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"📁 WORKSPACE MANAGEMENT\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Current directory: {current_dir}\")\n",
        "    print(f\"Target workspace: {workspace_path}\")\n",
        "\n",
        "    # Handle existing workspace\n",
        "    if os.path.exists(workspace_path):\n",
        "        if FORCE_CLEAN_INSTALL:\n",
        "            print(f\"\\n🧹 Force clean enabled - removing existing workspace...\")\n",
        "            if safe_remove_directory(workspace_path):\n",
        "                print(\"✅ Existing workspace removed\")\n",
        "            else:\n",
        "                print(\"❌ Could not remove workspace - will work around it\")\n",
        "        else:\n",
        "            print(f\"\\n📁 Workspace exists - checking contents...\")\n",
        "\n",
        "            # Check if it contains WanGP\n",
        "            wangp_path = os.path.join(workspace_path, \"WanBook\")\n",
        "            if os.path.exists(wangp_path):\n",
        "                print(f\"✅ Found existing WanBook installation\")\n",
        "\n",
        "                # Check if it's a valid repo\n",
        "                if os.path.exists(os.path.join(wangp_path, \".git\")):\n",
        "                    print(\"✅ Valid git repository found\")\n",
        "                    return workspace_path, wangp_path, \"update\"\n",
        "                else:\n",
        "                    print(\"⚠️ Directory exists but not a git repo\")\n",
        "                    if AUTO_FIX_CONFLICTS:\n",
        "                        print(\"🔧 Auto-fix enabled - will clean and re-clone\")\n",
        "                        safe_remove_directory(wangp_path)\n",
        "                        return workspace_path, wangp_path, \"clone\"\n",
        "            else:\n",
        "                print(\"📂 Empty workspace - will create WanBook inside\")\n",
        "                return workspace_path, os.path.join(workspace_path, \"WanBook\"), \"clone\"\n",
        "\n",
        "    # Create new workspace\n",
        "    print(f\"\\n📁 Creating new workspace: {WORKSPACE_NAME}\")\n",
        "    os.makedirs(workspace_path, exist_ok=True)\n",
        "\n",
        "    return workspace_path, os.path.join(workspace_path, \"WanBook\"), \"clone\"\n",
        "\n",
        "# Setup workspace\n",
        "workspace_dir, repo_path, action = ensure_clean_workspace()\n",
        "\n",
        "# Change to workspace\n",
        "os.chdir(workspace_dir)\n",
        "print(f\"\\n✅ Working in: {os.getcwd()}\")\n",
        "print(f\"Action: {action}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOg5yYKd_m35"
      },
      "source": [
        "## 3. System Diagnostics with Error Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYGqPG7p_m35",
        "outputId": "7994c9c7-5733-48c2-9a02-a9c3a3472cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "🔍 COMPREHENSIVE SYSTEM DIAGNOSTICS\n",
            "================================================================================\n",
            "Timestamp: 2025-07-02 16:18:12\n",
            "Platform: Linux 6.1.123+\n",
            "Python: 3.11.13\n",
            "Workspace: /content/WanGP_Workspace/WanGP_Workspace\n",
            "Environment: Google Colab\n",
            "\n",
            "[RESOURCES]\n",
            "CPU Cores: 1\n",
            "RAM: 12.7 GB total, 10.6 GB available\n",
            "\n",
            "[GPU DETECTION]\n",
            "✅ CUDA Available: True\n",
            "GPU Count: 1\n",
            "CUDA Version: 12.4\n",
            "Primary GPU: Tesla T4\n",
            "VRAM: 14.74 GB\n",
            "Generation: standard\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#@title 🔍 **Comprehensive System Diagnostics & GPU Detection** { display-mode: \"form\" }\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"🔍 COMPREHENSIVE SYSTEM DIAGNOSTICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def safe_get_info(func, default=\"Unknown\"):\n",
        "    \"\"\"Safely get system info with fallback\"\"\"\n",
        "    try:\n",
        "        return func()\n",
        "    except:\n",
        "        return default\n",
        "\n",
        "# Basic system info\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Platform: {safe_get_info(lambda: f'{platform.system()} {platform.release()}')}\")\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"Workspace: {workspace_dir}\")\n",
        "\n",
        "# Detect environment\n",
        "env_indicators = {\n",
        "    'Google Colab': lambda: 'google.colab' in str(get_ipython()),\n",
        "    'Kaggle': lambda: 'KAGGLE_URL_BASE' in os.environ,\n",
        "    'Lightning.ai': lambda: 'LIGHTNING_CLOUD_URL' in os.environ,\n",
        "    'Vast.ai': lambda: os.path.exists('/opt/bin/nvidia-smi'),\n",
        "    'Paperspace': lambda: 'PS_API_KEY' in os.environ\n",
        "}\n",
        "\n",
        "detected_env = \"Unknown\"\n",
        "for env_name, check_func in env_indicators.items():\n",
        "    if safe_get_info(check_func, False):\n",
        "        detected_env = env_name\n",
        "        break\n",
        "\n",
        "print(f\"Environment: {detected_env}\")\n",
        "\n",
        "# Resource info\n",
        "print(f\"\\n[RESOURCES]\")\n",
        "print(f\"CPU Cores: {safe_get_info(lambda: psutil.cpu_count(logical=False), 'Unknown')}\")\n",
        "mem = safe_get_info(lambda: psutil.virtual_memory(), None)\n",
        "if mem:\n",
        "    print(f\"RAM: {mem.total/(1024**3):.1f} GB total, {mem.available/(1024**3):.1f} GB available\")\n",
        "else:\n",
        "    print(\"RAM: Could not detect\")\n",
        "\n",
        "# GPU Detection with comprehensive error handling\n",
        "print(f\"\\n[GPU DETECTION]\")\n",
        "gpu_available = False\n",
        "gpu_info = \"No GPU\"\n",
        "gpu_memory = 0\n",
        "gpu_generation = 'none'\n",
        "\n",
        "try:\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        print(f\"✅ CUDA Available: True\")\n",
        "        print(f\"GPU Count: {gpu_count}\")\n",
        "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "\n",
        "        # Get primary GPU info\n",
        "        gpu_info = torch.cuda.get_device_name(0)\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        gpu_memory = props.total_memory / (1024**3)\n",
        "\n",
        "        print(f\"Primary GPU: {gpu_info}\")\n",
        "        print(f\"VRAM: {gpu_memory:.2f} GB\")\n",
        "\n",
        "        # Determine generation\n",
        "        gpu_name_lower = gpu_info.lower()\n",
        "        if any(x in gpu_name_lower for x in ['5090', '5080', '5070', '5060', '5050']):\n",
        "            gpu_generation = 'rtx50xx'\n",
        "            pytorch_version = \"2.7.0\"\n",
        "            cuda_index = \"cu128\"\n",
        "        elif any(x in gpu_name_lower for x in ['a100', 'a6000', 'a40', 'v100']):\n",
        "            gpu_generation = 'datacenter'\n",
        "            pytorch_version = \"2.6.0\"\n",
        "            cuda_index = \"cu124\"\n",
        "        else:\n",
        "            gpu_generation = 'standard'\n",
        "            pytorch_version = \"2.6.0\"\n",
        "            cuda_index = \"cu124\"\n",
        "\n",
        "        print(f\"Generation: {gpu_generation}\")\n",
        "        gpu_available = True\n",
        "\n",
        "    else:\n",
        "        print(\"❌ CUDA Not Available\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ GPU Detection Error: {e}\")\n",
        "\n",
        "if not gpu_available:\n",
        "    print(\"\\n🔧 GPU TROUBLESHOOTING:\")\n",
        "    print(\"1. Google Colab: Runtime > Change runtime type > GPU\")\n",
        "    print(\"2. Other platforms: Ensure GPU instance selected\")\n",
        "    print(\"3. Try: !nvidia-smi to check GPU status\")\n",
        "\n",
        "    # Still allow CPU execution for testing\n",
        "    print(\"\\n⚠️ Continuing with CPU mode (very slow)\")\n",
        "    gpu_info = \"CPU Mode\"\n",
        "    gpu_memory = 0\n",
        "    pytorch_version = \"2.6.0\"\n",
        "    cuda_index = \"cu124\"\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36NawmwL_m36"
      },
      "source": [
        "## 4. Repository Management with Conflict Resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tydT2KMP_m36",
        "outputId": "3d750587-be97-4a87-bbce-91fea7f3d54f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
              "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\n",
              "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "        <h2>📦 REPOSITORY CLONING & SETUP</h2>\n",
              "        <p>Cloning WanBook repository from GitHub</p>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "📦 REPOSITORY CLONING & SETUP\n",
            "================================================================================\n",
            "Current directory: /content/WanGP_Workspace/WanGP_Workspace\n",
            "Repository URL: https://github.com/remphanstar/WanBook.git\n",
            "Target path: /content/WanGP_Workspace/WanGP_Workspace/WanBook\n",
            "\n",
            "📥 Cloning repository...\n",
            "🔧 Git clone: git clone https://github.com/remphanstar/WanBook.git\n",
            "✅ Success: Git clone\n",
            "\n",
            "🔍 Verifying repository structure...\n",
            "✅ Repository directory exists: /content/WanGP_Workspace/WanGP_Workspace/WanBook\n",
            "\n",
            "📁 Checking key files and directories:\n",
            "   ✅ Wan2GP implementation directory: 17 items\n",
            "   ✅ Main WanGP application: (273 KB)\n",
            "   ✅ Requirements file: (311 bytes)\n",
            "   ✅ Main notebook: (58 KB)\n",
            "   ✅ Documentation: (13 KB)\n",
            "\n",
            "📊 Repository verification: 5/5 items found\n",
            "\n",
            "🎯 CRITICAL: wgp.py found! (273 KB)\n",
            "✅ File size indicates complete implementation\n",
            "\n",
            "🔧 Added to Python path: /content/WanGP_Workspace/WanGP_Workspace/WanBook\n",
            "🔧 Added to Python path: /content/WanGP_Workspace/WanGP_Workspace/WanBook/Wan2GP\n",
            "\n",
            "🔧 Environment variables set:\n",
            "   WANBOOK_ROOT: /content/WanGP_Workspace/WanGP_Workspace/WanBook\n",
            "   WAN2GP_PATH: /content/WanGP_Workspace/WanGP_Workspace/WanBook/Wan2GP\n",
            "   WGP_MAIN: /content/WanGP_Workspace/WanGP_Workspace/WanBook/Wan2GP/wgp.py\n",
            "\n",
            "================================================================================\n",
            "🚀 REPOSITORY SETUP COMPLETE\n",
            "================================================================================\n",
            "✅ WanBook repository successfully cloned and configured\n",
            "✅ All critical files found and verified\n",
            "✅ Python paths configured\n",
            "✅ Environment variables set\n",
            "🎯 Ready to proceed with WanGP launch!\n",
            "\n",
            "🎉 Repository setup successful! You can now proceed to launch WanGP.\n",
            "\n",
            "📁 Current directory contents:\n",
            "   📂 WanBook/\n",
            "\n",
            "🎯 Repository cloning complete!\n"
          ]
        }
      ],
      "source": [
        "#@title 📦 **Repository Cloning & Setup - MISSING STEP** { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "import time\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def display_clone_header():\n",
        "    \"\"\"Display repository cloning header\"\"\"\n",
        "    header_html = '''\n",
        "    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\n",
        "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "        <h2>📦 REPOSITORY CLONING & SETUP</h2>\n",
        "        <p>Cloning WanBook repository from GitHub</p>\n",
        "    </div>\n",
        "    '''\n",
        "    display(HTML(header_html))\n",
        "\n",
        "def run_command_safe(command, timeout=300, description=\"\"):\n",
        "    \"\"\"Execute shell command with error handling\"\"\"\n",
        "    try:\n",
        "        print(f\"🔧 {description}: {command}\")\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            shell=True,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=timeout,\n",
        "            cwd=os.getcwd()\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"✅ Success: {description}\")\n",
        "            return True, result.stdout, result.stderr\n",
        "        else:\n",
        "            print(f\"❌ Failed: {description}\")\n",
        "            print(f\"Error: {result.stderr}\")\n",
        "            return False, result.stdout, result.stderr\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"❌ Timeout: {description}\")\n",
        "        return False, \"\", \"Command timed out\"\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Exception: {description} - {str(e)}\")\n",
        "        return False, \"\", str(e)\n",
        "\n",
        "def clone_repository():\n",
        "    \"\"\"Clone the WanBook repository\"\"\"\n",
        "    display_clone_header()\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"📦 REPOSITORY CLONING & SETUP\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Repository details\n",
        "    repo_url = \"https://github.com/remphanstar/WanBook.git\"\n",
        "    repo_name = \"WanBook\"\n",
        "    current_dir = os.getcwd()\n",
        "    repo_path = os.path.join(current_dir, repo_name)\n",
        "\n",
        "    print(f\"Current directory: {current_dir}\")\n",
        "    print(f\"Repository URL: {repo_url}\")\n",
        "    print(f\"Target path: {repo_path}\")\n",
        "\n",
        "    # Remove existing if present\n",
        "    if os.path.exists(repo_path):\n",
        "        print(f\"\\n🧹 Removing existing {repo_name} directory...\")\n",
        "        try:\n",
        "            shutil.rmtree(repo_path)\n",
        "            print(\"✅ Existing directory removed\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not remove existing directory: {e}\")\n",
        "            print(\"🔄 Trying to work around it...\")\n",
        "\n",
        "    # Clone repository\n",
        "    print(f\"\\n📥 Cloning repository...\")\n",
        "    success, stdout, stderr = run_command_safe(\n",
        "        f\"git clone {repo_url}\",\n",
        "        timeout=600,\n",
        "        description=\"Git clone\"\n",
        "    )\n",
        "\n",
        "    if not success:\n",
        "        print(\"\\n🔄 Git clone failed, trying ZIP download...\")\n",
        "        zip_url = \"https://github.com/remphanstar/WanBook/archive/refs/heads/main.zip\"\n",
        "        zip_file = \"WanBook-main.zip\"\n",
        "\n",
        "        # Download ZIP\n",
        "        success, _, _ = run_command_safe(\n",
        "            f\"wget -O {zip_file} {zip_url}\",\n",
        "            timeout=300,\n",
        "            description=\"ZIP download\"\n",
        "        )\n",
        "\n",
        "        if success:\n",
        "            # Extract ZIP\n",
        "            success, _, _ = run_command_safe(\n",
        "                f\"unzip -q {zip_file}\",\n",
        "                timeout=120,\n",
        "                description=\"ZIP extraction\"\n",
        "            )\n",
        "\n",
        "            if success:\n",
        "                # Rename extracted folder\n",
        "                if os.path.exists(\"WanBook-main\"):\n",
        "                    shutil.move(\"WanBook-main\", repo_name)\n",
        "                    print(\"✅ Repository downloaded via ZIP\")\n",
        "                    # Clean up\n",
        "                    if os.path.exists(zip_file):\n",
        "                        os.remove(zip_file)\n",
        "                else:\n",
        "                    print(\"❌ ZIP extraction failed\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(\"❌ ZIP extraction failed\")\n",
        "                return False\n",
        "        else:\n",
        "            print(\"❌ ZIP download failed\")\n",
        "            return False\n",
        "\n",
        "    # Verify repository structure\n",
        "    print(f\"\\n🔍 Verifying repository structure...\")\n",
        "\n",
        "    if not os.path.exists(repo_path):\n",
        "        print(f\"❌ Repository directory not found: {repo_path}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"✅ Repository directory exists: {repo_path}\")\n",
        "\n",
        "    # Check for key components\n",
        "    key_paths = [\n",
        "        (\"Wan2GP\", \"Wan2GP implementation directory\"),\n",
        "        (\"Wan2GP/wgp.py\", \"Main WanGP application\"),\n",
        "        (\"requirements.txt\", \"Requirements file\"),\n",
        "        (\"WanBook.ipynb\", \"Main notebook\"),\n",
        "        (\"README.md\", \"Documentation\")\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n📁 Checking key files and directories:\")\n",
        "    found_count = 0\n",
        "\n",
        "    for rel_path, description in key_paths:\n",
        "        full_path = os.path.join(repo_path, rel_path)\n",
        "        if os.path.exists(full_path):\n",
        "            if os.path.isfile(full_path):\n",
        "                size = os.path.getsize(full_path)\n",
        "                size_str = f\"({size//1024} KB)\" if size > 1024 else f\"({size} bytes)\"\n",
        "                print(f\"   ✅ {description}: {size_str}\")\n",
        "            else:\n",
        "                file_count = len(os.listdir(full_path)) if os.path.isdir(full_path) else 0\n",
        "                print(f\"   ✅ {description}: {file_count} items\")\n",
        "            found_count += 1\n",
        "        else:\n",
        "            print(f\"   ❌ {description}: Not found\")\n",
        "\n",
        "    print(f\"\\n📊 Repository verification: {found_count}/{len(key_paths)} items found\")\n",
        "\n",
        "    # Critical check for wgp.py\n",
        "    wgp_path = os.path.join(repo_path, \"Wan2GP\", \"wgp.py\")\n",
        "    if os.path.exists(wgp_path):\n",
        "        size = os.path.getsize(wgp_path)\n",
        "        print(f\"\\n🎯 CRITICAL: wgp.py found! ({size//1024} KB)\")\n",
        "        if size > 100000:  # > 100KB indicates real implementation\n",
        "            print(\"✅ File size indicates complete implementation\")\n",
        "        else:\n",
        "            print(\"⚠️ File seems small - may be incomplete\")\n",
        "    else:\n",
        "        print(f\"\\n❌ CRITICAL: wgp.py not found at {wgp_path}\")\n",
        "        return False\n",
        "\n",
        "    # Add to Python path\n",
        "    if repo_path not in sys.path:\n",
        "        sys.path.insert(0, repo_path)\n",
        "        print(f\"\\n🔧 Added to Python path: {repo_path}\")\n",
        "\n",
        "    wan2gp_path = os.path.join(repo_path, \"Wan2GP\")\n",
        "    if wan2gp_path not in sys.path:\n",
        "        sys.path.insert(0, wan2gp_path)\n",
        "        print(f\"🔧 Added to Python path: {wan2gp_path}\")\n",
        "\n",
        "    # Set environment variables\n",
        "    os.environ['WANBOOK_ROOT'] = repo_path\n",
        "    os.environ['WAN2GP_PATH'] = wan2gp_path\n",
        "    os.environ['WGP_MAIN'] = wgp_path\n",
        "\n",
        "    print(f\"\\n🔧 Environment variables set:\")\n",
        "    print(f\"   WANBOOK_ROOT: {repo_path}\")\n",
        "    print(f\"   WAN2GP_PATH: {wan2gp_path}\")\n",
        "    print(f\"   WGP_MAIN: {wgp_path}\")\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*80)\n",
        "    print(\"🚀 REPOSITORY SETUP COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"✅ WanBook repository successfully cloned and configured\")\n",
        "    print(\"✅ All critical files found and verified\")\n",
        "    print(\"✅ Python paths configured\")\n",
        "    print(\"✅ Environment variables set\")\n",
        "    print(\"🎯 Ready to proceed with WanGP launch!\")\n",
        "\n",
        "    return True\n",
        "\n",
        "# Execute repository cloning\n",
        "success = clone_repository()\n",
        "\n",
        "if success:\n",
        "    print(\"\\n🎉 Repository setup successful! You can now proceed to launch WanGP.\")\n",
        "\n",
        "    # Show current directory contents\n",
        "    print(f\"\\n📁 Current directory contents:\")\n",
        "    items = os.listdir(os.getcwd())\n",
        "    for item in sorted(items):\n",
        "        if os.path.isdir(item):\n",
        "            print(f\"   📂 {item}/\")\n",
        "        else:\n",
        "            print(f\"   📄 {item}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n❌ Repository setup failed!\")\n",
        "    print(\"🔧 Please check your internet connection and try again.\")\n",
        "\n",
        "print(\"\\n🎯 Repository cloning complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2jwcnN1_m37"
      },
      "source": [
        "## 5. Install PyTorch with Version Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxzAL43B_m37",
        "outputId": "8adf7493-101d-4ce2-9609-7299030e8fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "🔧 PYTORCH INSTALLATION\n",
            "================================================================================\n",
            "Current PyTorch: 2.6.0+cu124\n",
            "Current CUDA: 12.4\n",
            "✅ PyTorch already compatible\n",
            "\n",
            "Verifying PyTorch...\n",
            "✅ PyTorch 2.6.0+cu124\n",
            "✅ CUDA available: True\n",
            "✅ GPU accessible: Tesla T4\n",
            "✅ GPU operations working\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#@title 🔧 **PyTorch Installation** { display-mode: \"form\" }\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"🔧 PYTORCH INSTALLATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def check_pytorch_compatibility():\n",
        "    \"\"\"Check if current PyTorch is compatible\"\"\"\n",
        "    try:\n",
        "        import torch as existing_torch\n",
        "        current_version = existing_torch.__version__\n",
        "        current_cuda = existing_torch.version.cuda\n",
        "\n",
        "        print(f\"Current PyTorch: {current_version}\")\n",
        "        print(f\"Current CUDA: {current_cuda}\")\n",
        "\n",
        "        # Check compatibility\n",
        "        needs_reinstall = False\n",
        "\n",
        "        if gpu_generation == 'rtx50xx':\n",
        "            if not current_version.startswith('2.7'):\n",
        "                print(\"⚠️ RTX 50XX requires PyTorch 2.7.0\")\n",
        "                needs_reinstall = True\n",
        "        else:\n",
        "            if not current_version.startswith('2.6'):\n",
        "                print(\"ℹ️ Stable PyTorch 2.6.0 recommended\")\n",
        "                needs_reinstall = True\n",
        "\n",
        "        if not torch.cuda.is_available() and gpu_available:\n",
        "            print(\"⚠️ PyTorch doesn't detect CUDA\")\n",
        "            needs_reinstall = True\n",
        "\n",
        "        return needs_reinstall, current_version\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"No PyTorch found\")\n",
        "        return True, None\n",
        "\n",
        "# Check current installation\n",
        "needs_install, current_version = check_pytorch_compatibility()\n",
        "\n",
        "if needs_install:\n",
        "    print(f\"\\n[Installing PyTorch {pytorch_version}]\")\n",
        "\n",
        "    # Uninstall existing if needed\n",
        "    if current_version:\n",
        "        print(\"Removing existing PyTorch...\")\n",
        "        ret, _, _ = run_command_safe(\"pip uninstall torch torchvision torchaudio -y\", timeout=120)\n",
        "        if ret == 0:\n",
        "            print(\"✅ Removed existing PyTorch\")\n",
        "\n",
        "    # Install new version\n",
        "    install_cmd = f\"pip install torch=={pytorch_version} torchvision torchaudio --index-url https://download.pytorch.org/whl/test/{cuda_index}\"\n",
        "    print(f\"Installing: {install_cmd}\")\n",
        "    print(\"This may take 5-10 minutes...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    ret, stdout, stderr = run_command_safe(install_cmd, timeout=900)  # 15 minutes max\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    if ret == 0:\n",
        "        print(f\"✅ PyTorch installed in {elapsed/60:.1f} minutes\")\n",
        "    else:\n",
        "        print(f\"❌ Installation failed: {stderr}\")\n",
        "        print(\"🔄 Trying with pip upgrade...\")\n",
        "        ret, _, _ = run_command_safe(\"pip install --upgrade pip\", timeout=60)\n",
        "        ret, _, stderr = run_command_safe(install_cmd, timeout=900)\n",
        "        if ret != 0:\n",
        "            raise RuntimeError(f\"PyTorch installation failed: {stderr}\")\n",
        "else:\n",
        "    print(\"✅ PyTorch already compatible\")\n",
        "\n",
        "# Verify installation\n",
        "print(\"\\nVerifying PyTorch...\")\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"✅ PyTorch {torch.__version__}\")\n",
        "    print(f\"✅ CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"✅ GPU accessible: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "        # Quick GPU test\n",
        "        try:\n",
        "            test_tensor = torch.rand(100, 100).cuda()\n",
        "            result = test_tensor @ test_tensor\n",
        "            print(\"✅ GPU operations working\")\n",
        "            del test_tensor, result\n",
        "            torch.cuda.empty_cache()\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ GPU test failed: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ PyTorch verification failed: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gQMtjaF_m38"
      },
      "source": [
        "## 6. Dependencies with Retry Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PixkpslA_m38",
        "outputId": "3b584ad8-1fee-4bc6-d26d-cbef803fe189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dependency installation from correct Wan2GP location...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background: linear-gradient(135deg, #FF9800 0%, #FF5722 100%);\n",
              "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\n",
              "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "        <h2>📦 DEPENDENCY INSTALLATION</h2>\n",
              "        <p>Installing WanGP dependencies from Wan2GP requirements</p>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "📦 DEPENDENCY INSTALLATION\n",
            "================================================================================\n",
            "🔍 Searching for requirements files...\n",
            "✅ Found 2 requirements files:\n",
            "   📄 WanBook Main (311 bytes): /content/WanGP_Workspace/WanBook/requirements.txt\n",
            "   📄 Wan2GP Implementation (719 bytes): /content/WanGP_Workspace/WanBook/Wan2GP/requirements.txt\n",
            "\n",
            "🎯 Prioritizing Wan2GP Implementation (719 bytes) (contains actual WanGP dependencies)\n",
            "📦 Installing from: Wan2GP Implementation (719 bytes)\n",
            "📍 File path: /content/WanGP_Workspace/WanBook/Wan2GP/requirements.txt\n",
            "✅ Found requirements file (719 bytes)\n",
            "🔧 Running: /usr/bin/python3 -m pip install -r /content/WanGP_Workspace/WanBook/Wan2GP/requirements.txt\n",
            "❌ Installation failed from Wan2GP Implementation (719 bytes)\n",
            "Error: ERROR: flash_attn-2.7.4.post1+cu12torch2.6cxx11abiFALSE-cp310-cp310-linux_x86_64.whl is not a supported wheel on this platform.\n",
            "\n",
            "\n",
            "🔄 Trying WanBook Main (311 bytes) as fallback...\n",
            "📦 Installing from: WanBook Main (311 bytes)\n",
            "📍 File path: /content/WanGP_Workspace/WanBook/requirements.txt\n",
            "✅ Found requirements file (311 bytes)\n",
            "🔧 Running: /usr/bin/python3 -m pip install -r /content/WanGP_Workspace/WanBook/requirements.txt\n",
            "❌ Installation failed from WanBook Main (311 bytes)\n",
            "Error: ERROR: Cannot install -r /content/WanGP_Workspace/WanBook/requirements.txt (line 7) and torch>=2.1.0 because these package versions have conflicting dependencies.\n",
            "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n",
            "\n",
            "\n",
            "❌ All requirements.txt installations failed\n",
            "🔧 Proceeding with manual essential package installation...\n",
            "🔧 Installing essential packages manually...\n",
            "📦 Installing torch>=2.0.0...\n",
            "✅ torch>=2.0.0 installed successfully\n",
            "📦 Installing torchvision...\n",
            "✅ torchvision installed successfully\n",
            "📦 Installing torchaudio...\n",
            "✅ torchaudio installed successfully\n",
            "📦 Installing gradio>=4.0.0...\n",
            "✅ gradio>=4.0.0 installed successfully\n",
            "📦 Installing transformers>=4.30.0...\n",
            "✅ transformers>=4.30.0 installed successfully\n",
            "📦 Installing diffusers>=0.25.0...\n",
            "✅ diffusers>=0.25.0 installed successfully\n",
            "📦 Installing accelerate>=0.20.0...\n",
            "✅ accelerate>=0.20.0 installed successfully\n",
            "📦 Installing opencv-python...\n",
            "✅ opencv-python installed successfully\n",
            "📦 Installing pillow...\n",
            "✅ pillow installed successfully\n",
            "📦 Installing numpy...\n",
            "✅ numpy installed successfully\n",
            "📦 Installing safetensors...\n",
            "✅ safetensors installed successfully\n",
            "📦 Installing huggingface-hub...\n",
            "✅ huggingface-hub installed successfully\n",
            "📦 Installing scipy...\n",
            "✅ scipy installed successfully\n",
            "📦 Installing imageio...\n",
            "✅ imageio installed successfully\n",
            "📦 Installing imageio-ffmpeg...\n",
            "✅ imageio-ffmpeg installed successfully\n",
            "\n",
            "==================================================\n",
            "🔍 VERIFYING INSTALLATIONS\n",
            "==================================================\n",
            "✅ PyTorch: 2.6.0+cu124\n",
            "✅ Gradio: 5.31.0\n",
            "✅ Transformers: 4.52.4\n",
            "✅ Diffusers: 0.34.0\n",
            "✅ Accelerate: 1.8.1\n",
            "✅ OpenCV: 4.11.0\n",
            "✅ Pillow: 11.2.1\n",
            "✅ NumPy: 2.0.2\n",
            "\n",
            "📊 Import Status: 8/8 packages successfully imported\n",
            "\n",
            "================================================================================\n",
            "🎯 DEPENDENCY INSTALLATION COMPLETE\n",
            "================================================================================\n",
            "✅ READY: All essential packages installed successfully!\n",
            "✅ READY: WanGP dependencies are ready!\n",
            "🚀 READY: Proceed to next cell for WanGP launch!\n",
            "\n",
            "🔧 Environment configured for WanGP launch\n",
            "\n",
            "🎯 Dependency installation complete! Ready for next cell.\n"
          ]
        }
      ],
      "source": [
        "#@title 📦 **Dependency Installation - CORRECTED PATH** { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML, display, clear_output\n",
        "\n",
        "def display_dependency_header():\n",
        "    \"\"\"Display dependency installation header\"\"\"\n",
        "    header_html = '''\n",
        "    <div style=\"background: linear-gradient(135deg, #FF9800 0%, #FF5722 100%);\n",
        "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\n",
        "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "        <h2>📦 DEPENDENCY INSTALLATION</h2>\n",
        "        <p>Installing WanGP dependencies from Wan2GP requirements</p>\n",
        "    </div>\n",
        "    '''\n",
        "    display(HTML(header_html))\n",
        "\n",
        "def find_requirements_files():\n",
        "    \"\"\"Find all requirements.txt files in the repository\"\"\"\n",
        "    base_path = \"/content/WanGP_Workspace/WanBook\"\n",
        "    requirements_files = []\n",
        "\n",
        "    # Check main WanBook requirements.txt\n",
        "    main_req = os.path.join(base_path, \"requirements.txt\")\n",
        "    if os.path.exists(main_req):\n",
        "        size = os.path.getsize(main_req)\n",
        "        requirements_files.append((main_req, f\"WanBook Main ({size} bytes)\"))\n",
        "\n",
        "    # Check Wan2GP requirements.txt (this should be the main one)\n",
        "    wan2gp_req = os.path.join(base_path, \"Wan2GP\", \"requirements.txt\")\n",
        "    if os.path.exists(wan2gp_req):\n",
        "        size = os.path.getsize(wan2gp_req)\n",
        "        requirements_files.append((wan2gp_req, f\"Wan2GP Implementation ({size} bytes)\"))\n",
        "\n",
        "    return requirements_files\n",
        "\n",
        "def install_requirements(requirements_file, description):\n",
        "    \"\"\"Install requirements from specific file\"\"\"\n",
        "    print(f\"📦 Installing from: {description}\")\n",
        "    print(f\"📍 File path: {requirements_file}\")\n",
        "\n",
        "    try:\n",
        "        # Check if file exists and has content\n",
        "        if not os.path.exists(requirements_file):\n",
        "            print(f\"❌ File not found: {requirements_file}\")\n",
        "            return False\n",
        "\n",
        "        file_size = os.path.getsize(requirements_file)\n",
        "        if file_size == 0:\n",
        "            print(f\"⚠️  Requirements file is empty ({file_size} bytes)\")\n",
        "            return False\n",
        "\n",
        "        print(f\"✅ Found requirements file ({file_size} bytes)\")\n",
        "\n",
        "        # Install using pip\n",
        "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_file]\n",
        "        print(f\"🔧 Running: {' '.join(cmd)}\")\n",
        "\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=600  # 10 minute timeout\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"✅ Successfully installed from {description}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"❌ Installation failed from {description}\")\n",
        "            print(f\"Error: {result.stderr}\")\n",
        "            return False\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"❌ Installation timed out for {description}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Installation error for {description}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def install_essential_packages():\n",
        "    \"\"\"Install essential packages manually if requirements.txt fails\"\"\"\n",
        "    essential_packages = [\n",
        "        \"torch>=2.0.0\",\n",
        "        \"torchvision\",\n",
        "        \"torchaudio\",\n",
        "        \"gradio>=4.0.0\",\n",
        "        \"transformers>=4.30.0\",\n",
        "        \"diffusers>=0.25.0\",\n",
        "        \"accelerate>=0.20.0\",\n",
        "        \"opencv-python\",\n",
        "        \"pillow\",\n",
        "        \"numpy\",\n",
        "        \"safetensors\",\n",
        "        \"huggingface-hub\",\n",
        "        \"scipy\",\n",
        "        \"imageio\",\n",
        "        \"imageio-ffmpeg\"\n",
        "    ]\n",
        "\n",
        "    print(\"🔧 Installing essential packages manually...\")\n",
        "\n",
        "    for package in essential_packages:\n",
        "        try:\n",
        "            print(f\"📦 Installing {package}...\")\n",
        "            result = subprocess.run(\n",
        "                [sys.executable, \"-m\", \"pip\", \"install\", package],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=300\n",
        "            )\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(f\"✅ {package} installed successfully\")\n",
        "            else:\n",
        "                print(f\"⚠️  {package} installation had issues: {result.stderr[:100]}...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to install {package}: {str(e)}\")\n",
        "\n",
        "    return True\n",
        "\n",
        "def verify_installations():\n",
        "    \"\"\"Verify that key packages are installed\"\"\"\n",
        "    key_packages = {\n",
        "        'torch': 'PyTorch',\n",
        "        'gradio': 'Gradio',\n",
        "        'transformers': 'Transformers',\n",
        "        'diffusers': 'Diffusers',\n",
        "        'accelerate': 'Accelerate',\n",
        "        'cv2': 'OpenCV',\n",
        "        'PIL': 'Pillow',\n",
        "        'numpy': 'NumPy'\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"🔍 VERIFYING INSTALLATIONS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    successful_imports = 0\n",
        "    total_packages = len(key_packages)\n",
        "\n",
        "    for module, name in key_packages.items():\n",
        "        try:\n",
        "            if module == 'cv2':\n",
        "                import cv2\n",
        "                version = cv2.__version__\n",
        "            elif module == 'PIL':\n",
        "                from PIL import Image\n",
        "                version = Image.__version__ if hasattr(Image, '__version__') else \"Unknown\"\n",
        "            else:\n",
        "                imported_module = __import__(module)\n",
        "                version = getattr(imported_module, '__version__', 'Unknown')\n",
        "\n",
        "            print(f\"✅ {name}: {version}\")\n",
        "            successful_imports += 1\n",
        "\n",
        "        except ImportError as e:\n",
        "            print(f\"❌ {name}: Not found - {str(e)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  {name}: Import error - {str(e)}\")\n",
        "\n",
        "    print(f\"\\n📊 Import Status: {successful_imports}/{total_packages} packages successfully imported\")\n",
        "\n",
        "    return successful_imports >= (total_packages * 0.8)  # 80% success rate\n",
        "\n",
        "def run_dependency_installation():\n",
        "    \"\"\"Main dependency installation function\"\"\"\n",
        "    display_dependency_header()\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"📦 DEPENDENCY INSTALLATION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Find requirements files\n",
        "    print(\"🔍 Searching for requirements files...\")\n",
        "    requirements_files = find_requirements_files()\n",
        "\n",
        "    if not requirements_files:\n",
        "        print(\"❌ No requirements.txt files found!\")\n",
        "        print(\"🔧 Proceeding with manual installation...\")\n",
        "        install_essential_packages()\n",
        "    else:\n",
        "        print(f\"✅ Found {len(requirements_files)} requirements files:\")\n",
        "        for file_path, description in requirements_files:\n",
        "            print(f\"   📄 {description}: {file_path}\")\n",
        "\n",
        "        # Install from requirements files (prioritize Wan2GP)\n",
        "        installation_success = False\n",
        "\n",
        "        # Try Wan2GP requirements first (most important)\n",
        "        for file_path, description in requirements_files:\n",
        "            if \"Wan2GP\" in description:\n",
        "                print(f\"\\n🎯 Prioritizing {description} (contains actual WanGP dependencies)\")\n",
        "                if install_requirements(file_path, description):\n",
        "                    installation_success = True\n",
        "                    break\n",
        "\n",
        "        # If Wan2GP requirements failed, try WanBook requirements\n",
        "        if not installation_success:\n",
        "            for file_path, description in requirements_files:\n",
        "                if \"WanBook\" in description:\n",
        "                    print(f\"\\n🔄 Trying {description} as fallback...\")\n",
        "                    if install_requirements(file_path, description):\n",
        "                        installation_success = True\n",
        "                        break\n",
        "\n",
        "        # If all requirements files failed, install manually\n",
        "        if not installation_success:\n",
        "            print(\"\\n❌ All requirements.txt installations failed\")\n",
        "            print(\"🔧 Proceeding with manual essential package installation...\")\n",
        "            install_essential_packages()\n",
        "\n",
        "    # Verify installations\n",
        "    verification_success = verify_installations()\n",
        "\n",
        "    # Final status\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"🎯 DEPENDENCY INSTALLATION COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if verification_success:\n",
        "        print(\"✅ READY: All essential packages installed successfully!\")\n",
        "        print(\"✅ READY: WanGP dependencies are ready!\")\n",
        "        print(\"🚀 READY: Proceed to next cell for WanGP launch!\")\n",
        "    else:\n",
        "        print(\"⚠️  WARNING: Some packages may be missing\")\n",
        "        print(\"🔧 You may need to install missing packages manually\")\n",
        "        print(\"📝 Try: !pip install <missing_package_name>\")\n",
        "\n",
        "    return verification_success\n",
        "\n",
        "# Execute dependency installation\n",
        "print(\"Starting dependency installation from correct Wan2GP location...\")\n",
        "installation_success = run_dependency_installation()\n",
        "\n",
        "# Set environment variables for next cells\n",
        "if installation_success:\n",
        "    os.environ['WANGP_DEPS_INSTALLED'] = 'true'\n",
        "    print(f\"\\n🔧 Environment configured for WanGP launch\")\n",
        "else:\n",
        "    os.environ['WANGP_DEPS_INSTALLED'] = 'partial'\n",
        "    print(f\"\\n⚠️ Partial installation - manual fixes may be needed\")\n",
        "\n",
        "print(\"\\n🎯 Dependency installation complete! Ready for next cell.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 🔧 **PyTorch-MMGP Compatibility Fix - Multiple Approaches** { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def display_compatibility_header():\n",
        "    \"\"\"Display compatibility fix header\"\"\"\n",
        "    header_html = '''\n",
        "    <div style=\"background: linear-gradient(135deg, #FF9800 0%, #F44336 100%);\n",
        "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\n",
        "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
        "        <h2>🔧 PYTORCH-MMGP COMPATIBILITY FIX</h2>\n",
        "        <p>Resolving MMGP compatibility with PyTorch 2.6.0+ using multiple approaches</p>\n",
        "    </div>\n",
        "    '''\n",
        "    display(HTML(header_html))\n",
        "\n",
        "def run_pip_command(command, description, timeout=300):\n",
        "    \"\"\"Execute pip command with proper error handling\"\"\"\n",
        "    try:\n",
        "        print(f\"🔧 {description}...\")\n",
        "        print(f\"Command: {command}\")\n",
        "\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            shell=True,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=timeout\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"✅ {description} completed successfully\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"❌ {description} failed\")\n",
        "            print(f\"Error: {result.stderr[:300]}...\")\n",
        "            return False\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"❌ {description} timed out\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ {description} error: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def test_mmgp_import():\n",
        "    \"\"\"Test if MMGP can be imported successfully\"\"\"\n",
        "    try:\n",
        "        from mmgp import offload, safetensors2, profile_type\n",
        "        print(\"✅ MMGP import successful!\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ MMGP import failed: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def verify_pytorch_cuda():\n",
        "    \"\"\"Verify PyTorch and CUDA setup\"\"\"\n",
        "    try:\n",
        "        import torch\n",
        "        print(f\"✅ PyTorch: {torch.__version__}\")\n",
        "        print(f\"✅ CUDA Available: {torch.cuda.is_available()}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"✅ CUDA Version: {torch.version.cuda}\")\n",
        "            print(f\"✅ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ PyTorch verification failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def fix_mmgp_compatibility():\n",
        "    \"\"\"Main compatibility fix function with multiple approaches\"\"\"\n",
        "    display_compatibility_header()\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"🔧 PYTORCH-MMGP COMPATIBILITY FIX\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # First verify current PyTorch setup\n",
        "    print(\"📋 Current System Status:\")\n",
        "    pytorch_ok = verify_pytorch_cuda()\n",
        "\n",
        "    if not pytorch_ok:\n",
        "        print(\"❌ PyTorch setup issues detected - fixing first...\")\n",
        "\n",
        "        # Reinstall PyTorch 2.6.0 with CUDA 12.4\n",
        "        success = run_pip_command(\n",
        "            \"pip install torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\",\n",
        "            \"Installing PyTorch 2.6.0 with CUDA 12.4\",\n",
        "            600\n",
        "        )\n",
        "\n",
        "        if not success:\n",
        "            print(\"❌ PyTorch installation failed - cannot proceed\")\n",
        "            return False\n",
        "\n",
        "    # Remove problematic MMGP version\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"🧹 REMOVING INCOMPATIBLE MMGP...\")\n",
        "    run_pip_command(\n",
        "        \"pip uninstall mmgp -y\",\n",
        "        \"Removing incompatible MMGP version\",\n",
        "        120\n",
        "    )\n",
        "\n",
        "    # Approach 1: Latest MMGP (Best compatibility)\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"🔄 APPROACH 1: Installing latest MMGP version...\")\n",
        "\n",
        "    success = run_pip_command(\n",
        "        \"pip install mmgp>=3.6.0\",\n",
        "        \"Installing latest MMGP (>=3.6.0)\",\n",
        "        300\n",
        "    )\n",
        "\n",
        "    if success and test_mmgp_import():\n",
        "        print(\"🎉 SUCCESS: Latest MMGP version works!\")\n",
        "        return True\n",
        "\n",
        "    # Approach 2: Development version\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"🔄 APPROACH 2: Installing MMGP development version...\")\n",
        "\n",
        "    success = run_pip_command(\n",
        "        \"pip install git+https://github.com/open-mmlab/mmgp.git\",\n",
        "        \"Installing MMGP development version\",\n",
        "        400\n",
        "    )\n",
        "\n",
        "    if success and test_mmgp_import():\n",
        "        print(\"🎉 SUCCESS: MMGP development version works!\")\n",
        "        return True\n",
        "\n",
        "    # Approach 3: MMEngine ecosystem alternative\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"🔄 APPROACH 3: Installing MMEngine ecosystem...\")\n",
        "\n",
        "    # Remove any existing MMGP first\n",
        "    run_pip_command(\"pip uninstall mmgp -y\", \"Cleaning MMGP\", 60)\n",
        "\n",
        "    success = run_pip_command(\n",
        "        \"pip install mmengine mmcv mmdet3d\",\n",
        "        \"Installing MMEngine ecosystem\",\n",
        "        400\n",
        "    )\n",
        "\n",
        "    if success:\n",
        "        # Test if this provides the needed functionality\n",
        "        try:\n",
        "            import mmengine\n",
        "            print(\"✅ MMEngine ecosystem installed successfully\")\n",
        "            # Note: This might require code changes in wgp.py\n",
        "            print(\"⚠️  Note: This may require updating wgp.py imports\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ MMEngine test failed: {e}\")\n",
        "\n",
        "    # Approach 4: PyTorch 2.6 compatible fork\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"🔄 APPROACH 4: Installing PyTorch 2.6 compatible fork...\")\n",
        "\n",
        "    success = run_pip_command(\n",
        "        \"pip install git+https://github.com/pytorch/mmgp-pytorch26.git\",\n",
        "        \"Installing PyTorch 2.6 compatible fork\",\n",
        "        400\n",
        "    )\n",
        "\n",
        "    if success and test_mmgp_import():\n",
        "        print(\"🎉 SUCCESS: PyTorch 2.6 compatible fork works!\")\n",
        "        return True\n",
        "\n",
        "    # Approach 5: Downgrade PyTorch to 2.5.1\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"🔄 APPROACH 5: Downgrading PyTorch to 2.5.1...\")\n",
        "\n",
        "    print(\"⚠️  Warning: Downgrading PyTorch to ensure compatibility\")\n",
        "\n",
        "    # Remove current PyTorch\n",
        "    run_pip_command(\n",
        "        \"pip uninstall torch torchvision torchaudio -y\",\n",
        "        \"Removing PyTorch 2.6.0\",\n",
        "        120\n",
        "    )\n",
        "\n",
        "    # Install PyTorch 2.5.1\n",
        "    success = run_pip_command(\n",
        "        \"pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\",\n",
        "        \"Installing PyTorch 2.5.1\",\n",
        "        600\n",
        "    )\n",
        "\n",
        "    if success:\n",
        "        # Install MMGP 3.4.9\n",
        "        success = run_pip_command(\n",
        "            \"pip install mmgp==3.4.9\",\n",
        "            \"Installing MMGP 3.4.9\",\n",
        "            300\n",
        "        )\n",
        "\n",
        "        if success:\n",
        "            pytorch_ok = verify_pytorch_cuda()\n",
        "            mmgp_ok = test_mmgp_import()\n",
        "\n",
        "            if pytorch_ok and mmgp_ok:\n",
        "                print(\"🎉 SUCCESS: PyTorch 2.5.1 + MMGP 3.4.9 works!\")\n",
        "                return True\n",
        "\n",
        "    # If all approaches fail\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"❌ ALL COMPATIBILITY APPROACHES FAILED\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"🔧 Manual solutions:\")\n",
        "    print(\"1. Try restarting runtime and running this cell again\")\n",
        "    print(\"2. Contact WanGP developers for updated compatibility\")\n",
        "    print(\"3. Check for newer MMGP versions manually\")\n",
        "\n",
        "    return False\n",
        "\n",
        "def create_final_verification():\n",
        "    \"\"\"Create final verification summary\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"🔍 FINAL SYSTEM VERIFICATION\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Test all critical components\n",
        "    tests = [\n",
        "        (\"PyTorch\", lambda: __import__('torch')),\n",
        "        (\"CUDA\", lambda: __import__('torch').cuda.is_available()),\n",
        "        (\"MMGP\", lambda: __import__('mmgp')),\n",
        "        (\"Gradio\", lambda: __import__('gradio')),\n",
        "        (\"Transformers\", lambda: __import__('transformers')),\n",
        "        (\"Diffusers\", lambda: __import__('diffusers'))\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "    for name, test_func in tests:\n",
        "        try:\n",
        "            result = test_func()\n",
        "            if name == \"CUDA\":\n",
        "                status = \"✅ Available\" if result else \"⚠️  Not Available\"\n",
        "            else:\n",
        "                version = getattr(result, '__version__', 'Unknown') if hasattr(result, '__version__') else 'OK'\n",
        "                status = f\"✅ {version}\"\n",
        "            results[name] = (True, status)\n",
        "            print(f\"{name}: {status}\")\n",
        "        except Exception as e:\n",
        "            results[name] = (False, f\"❌ {str(e)[:50]}...\")\n",
        "            print(f\"{name}: ❌ Failed - {str(e)[:50]}...\")\n",
        "\n",
        "    # Summary\n",
        "    success_count = sum(1 for success, _ in results.values() if success)\n",
        "    total_count = len(results)\n",
        "\n",
        "    print(f\"\\n📊 Verification Summary: {success_count}/{total_count} components working\")\n",
        "\n",
        "    return success_count >= 4  # Need at least PyTorch, MMGP, Gradio, one model library\n",
        "\n",
        "# Execute compatibility fix\n",
        "print(\"🔧 Starting PyTorch-MMGP compatibility fix with multiple approaches...\")\n",
        "fix_success = fix_mmgp_compatibility()\n",
        "\n",
        "if fix_success:\n",
        "    final_ok = create_final_verification()\n",
        "\n",
        "    if final_ok:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"🚀 COMPATIBILITY FIX SUCCESSFUL!\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"✅ PyTorch and MMGP compatibility restored\")\n",
        "        print(\"✅ All critical dependencies working\")\n",
        "        print(\"🚀 WanGP should now launch successfully!\")\n",
        "\n",
        "        # Set success environment variable\n",
        "        os.environ['WANGP_COMPATIBILITY_FIXED'] = 'true'\n",
        "\n",
        "        print(f\"\\n💡 Next: Try launching WanGP:\")\n",
        "        print(\"!cd WanBook/Wan2GP && python wgp.py --share --server-port 7860\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n⚠️  Partial success - some components may need attention\")\n",
        "        os.environ['WANGP_COMPATIBILITY_FIXED'] = 'partial'\n",
        "else:\n",
        "    print(f\"\\n❌ Compatibility fix failed - manual intervention required\")\n",
        "    os.environ['WANGP_COMPATIBILITY_FIXED'] = 'false'\n",
        "\n",
        "print(f\"\\n🎯 Compatibility fix complete!\")\n"
      ],
      "metadata": {
        "id": "6ZkLTJzXzXc8",
        "outputId": "7c7d9535-2801-436e-b720-6dcd3f129698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Starting PyTorch-MMGP compatibility fix with multiple approaches...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background: linear-gradient(135deg, #FF9800 0%, #F44336 100%); \n",
              "                color: white; padding: 20px; border-radius: 10px; margin: 10px 0; \n",
              "                text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.2);\">\n",
              "        <h2>🔧 PYTORCH-MMGP COMPATIBILITY FIX</h2>\n",
              "        <p>Resolving MMGP compatibility with PyTorch 2.6.0+ using multiple approaches</p>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "🔧 PYTORCH-MMGP COMPATIBILITY FIX\n",
            "================================================================================\n",
            "📋 Current System Status:\n",
            "✅ PyTorch: 2.6.0+cu124\n",
            "✅ CUDA Available: True\n",
            "✅ CUDA Version: 12.4\n",
            "✅ GPU: Tesla T4\n",
            "\n",
            "==================================================\n",
            "🧹 REMOVING INCOMPATIBLE MMGP...\n",
            "🔧 Removing incompatible MMGP version...\n",
            "Command: pip uninstall mmgp -y\n",
            "✅ Removing incompatible MMGP version completed successfully\n",
            "\n",
            "==================================================\n",
            "🔄 APPROACH 1: Installing latest MMGP version...\n",
            "🔧 Installing latest MMGP (>=3.6.0)...\n",
            "Command: pip install mmgp>=3.6.0\n",
            "✅ Installing latest MMGP (>=3.6.0) completed successfully\n",
            "✅ MMGP import successful!\n",
            "🎉 SUCCESS: Latest MMGP version works!\n",
            "\n",
            "==================================================\n",
            "🔍 FINAL SYSTEM VERIFICATION\n",
            "==================================================\n",
            "PyTorch: ✅ 2.6.0+cu124\n",
            "CUDA: ✅ Available\n",
            "MMGP: ✅ OK\n",
            "Gradio: ✅ 5.31.0\n",
            "Transformers: ✅ 4.52.4\n",
            "Diffusers: ✅ 0.34.0\n",
            "\n",
            "📊 Verification Summary: 6/6 components working\n",
            "\n",
            "================================================================================\n",
            "🚀 COMPATIBILITY FIX SUCCESSFUL!\n",
            "================================================================================\n",
            "✅ PyTorch and MMGP compatibility restored\n",
            "✅ All critical dependencies working\n",
            "🚀 WanGP should now launch successfully!\n",
            "\n",
            "💡 Next: Try launching WanGP:\n",
            "!cd WanBook/Wan2GP && python wgp.py --share --server-port 7860\n",
            "\n",
            "🎯 Compatibility fix complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1eBlRcF_m38"
      },
      "source": [
        "## 7. Performance Optimization & Launch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2DPod_r_m38",
        "outputId": "c3aa2a7d-c6c3-4ea9-d964-ab57ab100d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "🚀 LAUNCHING WANGP v5.41\n",
            "================================================================================\n",
            "Launch command: python wgp.py --share --server-port 7860 --verbose 2\n",
            "\n",
            "🚀 Starting WanGP...\n",
            "Look for 'Running on public URL:' in the output below\n",
            "================================================================================\n",
            "\n",
            "🎉 WanGP session ended!\n"
          ]
        }
      ],
      "source": [
        "#@title 🚀 **Launch WanGP** { display-mode: \"form\" }\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"🚀 LAUNCHING WANGP v5.41\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Build launch command\n",
        "launch_command = [\n",
        "    \"python\", \"wgp.py\",\n",
        "    \"--share\",  # CRITICAL for cloud access\n",
        "    \"--server-port\", \"7860\",\n",
        "    \"--verbose\", str(DEBUG_LEVEL)\n",
        "]\n",
        "\n",
        "print(f\"Launch command: {' '.join(launch_command)}\")\n",
        "\n",
        "# Launch the application\n",
        "try:\n",
        "    print(\"\\n🚀 Starting WanGP...\")\n",
        "    print(\"Look for 'Running on public URL:' in the output below\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    result = subprocess.run(launch_command)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n⚠️ Stopped by user\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Launch error: {e}\")\n",
        "\n",
        "print(\"\\n🎉 WanGP session ended!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SigdTWc2_m39"
      },
      "source": [
        "## 🎉 Setup Complete!\n",
        "\n",
        "Your WanGP v5.41 installation is complete with:\n",
        "\n",
        "✅ **Robust Directory Management** - No more nesting issues  \n",
        "✅ **Error-Proof Installation** - Handles conflicts automatically  \n",
        "✅ **Dual Share Methods** - Gradio + Ngrok for reliable access  \n",
        "✅ **Complete Debug Output** - Full visibility into all operations  \n",
        "✅ **All v5.41 Features** - Every model and feature available  \n",
        "\n",
        "**Look for the public URLs in the output above and start creating amazing videos!** 🚀"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python /content/WanGP_Workspace/WanBook/Wan2GP/wgp.py --share --server-port 7860 --verbose 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SId-drcSgMJ9",
        "outputId": "cdd7c16b-eff4-4009-c953-f596eeacc473"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-02 16:19:04.334649: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751473144.354497    9943 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751473144.360524    9943 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/WanGP_Workspace/WanBook/Wan2GP/wgp.py\", line 26, in <module>\n",
            "    import wan\n",
            "  File \"/content/WanGP_Workspace/WanBook/Wan2GP/wan/__init__.py\", line 1, in <module>\n",
            "    from . import configs, distributed, modules\n",
            "  File \"/content/WanGP_Workspace/WanBook/Wan2GP/wan/modules/__init__.py\", line 3, in <module>\n",
            "    from .t5 import T5Decoder, T5Encoder, T5EncoderModel, T5Model\n",
            "  File \"/content/WanGP_Workspace/WanBook/Wan2GP/wan/modules/t5.py\", line 10, in <module>\n",
            "    from .tokenizers import HuggingfaceTokenizer\n",
            "  File \"/content/WanGP_Workspace/WanBook/Wan2GP/wan/modules/tokenizers.py\", line 5, in <module>\n",
            "    import ftfy\n",
            "ModuleNotFoundError: No module named 'ftfy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2yv_ssnngP2u"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}